{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ResNet-9_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimum-tribe"
      },
      "source": [
        "# ResNet-9: CIFAR-10"
      ],
      "id": "optimum-tribe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tested-offense"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# import tensorflow_model_optimization as tfmot\n",
        "# from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "# from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, MaxPooling2D, ReLU, BatchNormalization\n",
        "from tensorflow.keras import models, layers, datasets\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, InputLayer, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "# import math\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "id": "tested-offense",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "available-poverty"
      },
      "source": [
        ""
      ],
      "id": "available-poverty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "polar-runner",
        "outputId": "8c8692fc-380a-4cb6-a9f1-b2c895f97e63"
      },
      "source": [
        "tf.__version__"
      ],
      "id": "polar-runner",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conventional-hands"
      },
      "source": [
        ""
      ],
      "id": "conventional-hands",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "constitutional-thunder"
      },
      "source": [
        "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
        "# %env CUDA_VISIBLE_DEVICES=2"
      ],
      "id": "constitutional-thunder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "essential-communist",
        "outputId": "137c7afb-6f90-4a0e-a549-c51ad06f9e91"
      },
      "source": [
        "# Check GPU availibility-\n",
        "'''\n",
        "This API allows querying the physical hardware resources prior to runtime\n",
        "initialization. Thus, giving an opportunity to call any additional\n",
        "configuration APIs.\n",
        "The following code lists the number of visible GPUs on the host-\n",
        "'''\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f\"Number of physical GPUs available: {len(physical_gpus)}\")"
      ],
      "id": "essential-communist",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of physical GPUs available: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "given-warehouse"
      },
      "source": [
        ""
      ],
      "id": "given-warehouse",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "direct-charlotte"
      },
      "source": [
        ""
      ],
      "id": "direct-charlotte",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "convenient-footwear"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "num_epochs = 200"
      ],
      "id": "convenient-footwear",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skilled-advisory",
        "outputId": "73c729ac-c51e-4878-af89-861c8efbeb72"
      },
      "source": [
        "# Data preprocessing and cleaning:\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "\n",
        "# Load CIFAR-10 dataset-\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Load CIFAR-100 dataset-\n",
        "# (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "id": "skilled-advisory",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prescribed-scott",
        "outputId": "da520c4b-5c6e-4bf2-8330-01c5d977b821"
      },
      "source": [
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (3, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "print(\"\\n'input_shape' which will be used = {0}\\n\".format(input_shape))"
      ],
      "id": "prescribed-scott",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "'input_shape' which will be used = (32, 32, 3)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compliant-triple"
      },
      "source": [
        "# convert class vectors/target to binary class matrices or one-hot encoded values-\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "id": "compliant-triple",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "behavioral-backup",
        "outputId": "e5f00871-5622-4aa3-c29a-c7e64a3b8d2e"
      },
      "source": [
        "print(\"\\nDimensions of training and testing sets are:\")\n",
        "print(\"X_train.shape = {0}, y_train.shape = {1}\".format(X_train.shape, y_train.shape))\n",
        "print(\"X_test.shape = {0}, y_test.shape = {1}\".format(X_test.shape, y_test.shape))"
      ],
      "id": "behavioral-backup",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dimensions of training and testing sets are:\n",
            "X_train.shape = (50000, 32, 32, 3), y_train.shape = (50000, 10)\n",
            "X_test.shape = (10000, 32, 32, 3), y_test.shape = (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "breathing-harbor"
      },
      "source": [
        ""
      ],
      "id": "breathing-harbor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accepting-conditions"
      },
      "source": [
        "# Instantiate TensorFlow's Dataset class for creating training and testing datasets-\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "id": "accepting-conditions",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-habitat"
      },
      "source": [
        ""
      ],
      "id": "senior-habitat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korean-superintendent"
      },
      "source": [
        ""
      ],
      "id": "korean-superintendent",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "light-resident"
      },
      "source": [
        "### Data Augmentation:\n",
        "\n",
        "Augment CIFAR-10 dataset by performing the following steps on every image:\n",
        "\n",
        "- Pad the image with a black, four-pixel border.\n",
        "- Randomly crop a 32 x 32 region from the padded image.\n",
        "- Flip a coin to determine if the image should be horizontally flipped."
      ],
      "id": "light-resident"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adjacent-boxing"
      },
      "source": [
        "HEIGHT = 32\n",
        "WIDTH = 32\n",
        "NUM_CHANNELS = 3"
      ],
      "id": "adjacent-boxing",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assured-pakistan"
      },
      "source": [
        ""
      ],
      "id": "assured-pakistan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "studied-relay"
      },
      "source": [
        "def augmentation(x, y):\n",
        "    x = tf.image.resize_with_crop_or_pad(x, HEIGHT + 8, WIDTH + 8)\n",
        "    x = tf.image.random_crop(x, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "\n",
        "    return x, y"
      ],
      "id": "studied-relay",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indoor-phoenix"
      },
      "source": [
        "def normalize(x, y):\n",
        "    x = tf.image.per_image_standardization(x)\n",
        "    return x, y"
      ],
      "id": "indoor-phoenix",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "provincial-subdivision"
      },
      "source": [
        ""
      ],
      "id": "provincial-subdivision",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "further-modem"
      },
      "source": [
        "# Augment training dataset\n",
        "train_dataset = (train_dataset\n",
        "        .map(augmentation)\n",
        "        .shuffle(buffer_size = 50000)\n",
        "        .map(normalize)\n",
        "        .batch(batch_size = batch_size, drop_remainder = True))\n",
        "\n",
        "\n",
        "# NOTE: Do NOT augment the testing dataset!"
      ],
      "id": "further-modem",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-D6NpXOzOSt"
      },
      "source": [
        "test_dataset = (test_dataset\n",
        "                .map(normalize)\n",
        "                .batch(batch_size = batch_size, drop_remainder = True))"
      ],
      "id": "b-D6NpXOzOSt",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPq_TB4czXmJ"
      },
      "source": [
        ""
      ],
      "id": "DPq_TB4czXmJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plastic-secondary"
      },
      "source": [
        ""
      ],
      "id": "plastic-secondary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "destroyed-ability"
      },
      "source": [
        "# Obtain a batch size set of training images and labels-\n",
        "images, labels = next(iter(train_dataset))"
      ],
      "id": "destroyed-ability",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alpha-aruba",
        "outputId": "ee166ed5-af37-4ee6-a5dd-2f05d77db9a0"
      },
      "source": [
        "images.shape, images.shape"
      ],
      "id": "alpha-aruba",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 32, 32, 3]), TensorShape([128, 32, 32, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resistant-malaysia"
      },
      "source": [
        ""
      ],
      "id": "resistant-malaysia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "norwegian-mixture"
      },
      "source": [
        ""
      ],
      "id": "norwegian-mixture",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "universal-writing"
      },
      "source": [
        ""
      ],
      "id": "universal-writing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shared-token"
      },
      "source": [
        ""
      ],
      "id": "shared-token",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caroline-lincoln"
      },
      "source": [
        "### Prepare CIFAR10 dataset for GradientTape training:"
      ],
      "id": "caroline-lincoln"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unusual-defendant"
      },
      "source": [
        "# Choose an optimizer and loss function for training-\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.9)"
      ],
      "id": "unusual-defendant",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paperback-valuation"
      },
      "source": [
        "# Select metrics to measure the error & accuracy of model.\n",
        "# These metrics accumulate the values over epochs and then\n",
        "# print the overall result-\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')"
      ],
      "id": "paperback-valuation",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spectacular-youth"
      },
      "source": [
        ""
      ],
      "id": "spectacular-youth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dietary-replica"
      },
      "source": [
        ""
      ],
      "id": "dietary-replica",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "integrated-brazil"
      },
      "source": [
        "### ResNet-9 model experimentation:"
      ],
      "id": "integrated-brazil"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "alien-scott",
        "outputId": "7632819e-1645-4960-e0df-f194d40b0701"
      },
      "source": [
        "inputs = keras.Input(shape = (32, 32, 3))\n",
        "\n",
        "x = Conv2D(\n",
        "    filters = 32, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same')(inputs)\n",
        "\n",
        "'''\n",
        "x = Conv2D(\n",
        "    filters = 64, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size = (3, 3), strides = (1, 1))(x)\n",
        "'''"
      ],
      "id": "alien-scott",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nx = Conv2D(\\n    filters = 64, kernel_size = (3, 3),\\n    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\\n    strides = (1, 1), padding = 'same')(x)\\n\\nx = MaxPooling2D(pool_size = (3, 3), strides = (1, 1))(x)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "above-grant",
        "outputId": "81e23e24-dbdb-4345-a91c-dc892fb28099"
      },
      "source": [
        "x.shape"
      ],
      "id": "above-grant",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 32, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stainless-lodging"
      },
      "source": [
        ""
      ],
      "id": "stainless-lodging",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "light-chambers"
      },
      "source": [
        ""
      ],
      "id": "light-chambers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nonprofit-spain"
      },
      "source": [
        "def resnet_block(input_data, num_filters, stride_length, conv_1x1 = False):\n",
        "    '''\n",
        "    Function to implement ResNet block as defined in the research paper.\n",
        "    '''\n",
        "    \n",
        "    img = Conv2D(\n",
        "        filters = num_filters, kernel_size = (3, 3),\n",
        "        activation = None, kernel_initializer = tf.initializers.he_normal(),\n",
        "        strides = stride_length, padding = 'same')(input_data)\n",
        "    img = BatchNormalization()(img)\n",
        "    img = layers.Activation('relu')(img)\n",
        "    \n",
        "    img = Conv2D(\n",
        "        filters = num_filters, kernel_size = (3, 3),\n",
        "        activation = None, kernel_initializer = tf.initializers.he_normal(),\n",
        "        strides = stride_length, padding = 'same')(img)\n",
        "    img = BatchNormalization()(img)\n",
        "    \n",
        "    \n",
        "    # Adjust number of filters/channels using 1x1 conv layer-\n",
        "    if conv_1x1:\n",
        "        input_data = Conv2D(\n",
        "            filters = num_filters, kernel_size = (1, 1),\n",
        "            activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "            strides = (1, 1), padding = 'same'\n",
        "        )(input_data)\n",
        "        \n",
        "    \n",
        "    print(f\"ResNet block (before adding): img.shape (output of conv layers) = {img.shape} & input_data.shape = {input_data.shape}\")\n",
        "    img = layers.Add()([img, input_data])\n",
        "    \n",
        "    img = layers.Activation('relu')(img)\n",
        "    \n",
        "    return img\n",
        "    \n"
      ],
      "id": "nonprofit-spain",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brilliant-faith"
      },
      "source": [
        ""
      ],
      "id": "brilliant-faith",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awful-outreach",
        "outputId": "18cbf0f4-59b2-4f08-9290-215519290f42"
      },
      "source": [
        "inputs = keras.Input(shape = (32, 32, 3))\n",
        "\n",
        "x = Conv2D(\n",
        "    filters = 32, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same'\n",
        "    # input_shape = (32, 32, 3)\n",
        "    )(inputs)\n",
        "\n",
        "'''\n",
        "x = Conv2D(\n",
        "    filters = 64, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size = (3, 3), strides = (1, 1))(x)\n",
        "\n",
        "x.shape\n",
        "# TensorShape([None, 30, 30, 64])\n",
        "'''\n",
        "\n",
        "x.shape\n",
        "# TensorShape([None, 32, 32, 32])\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 64, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 64, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 128, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 128, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 256, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 256, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 512, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 512, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "# x.shape\n",
        "# TensorShape([None, 32, 32, 512])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = layers.Dense(\n",
        "    units = 256, activation='relu',\n",
        "    kernel_initializer = tf.initializers.he_normal()\n",
        ")(x)\n",
        "\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "\n",
        "outputs = layers.Dense(units = 10, activation='softmax')(x)"
      ],
      "id": "awful-outreach",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 64) & input_data.shape = (None, 32, 32, 64)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 64) & input_data.shape = (None, 32, 32, 64)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 128) & input_data.shape = (None, 32, 32, 128)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 128) & input_data.shape = (None, 32, 32, 128)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 256) & input_data.shape = (None, 32, 32, 256)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 256) & input_data.shape = (None, 32, 32, 256)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 512) & input_data.shape = (None, 32, 32, 512)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 512) & input_data.shape = (None, 32, 32, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unusual-millennium"
      },
      "source": [
        ""
      ],
      "id": "unusual-millennium",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expensive-appendix"
      },
      "source": [
        "# Define ResNet model-\n",
        "resnet_model = keras.Model(inputs, outputs)"
      ],
      "id": "expensive-appendix",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "attempted-relief"
      },
      "source": [
        "# model = Model(inputs, x)"
      ],
      "id": "attempted-relief",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "according-deviation",
        "outputId": "6140c399-93ed-4fa5-b1e1-62b29120533f"
      },
      "source": [
        "resnet_model.summary()"
      ],
      "id": "according-deviation",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   18496       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36928       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   2112        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 128)  73856       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  8320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           batch_normalization_5[0][0]      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  147584      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 256)  295168      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 256)  33024       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 512)  1180160     activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 512)  2359808     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 512)  131584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 512)  0           batch_normalization_13[0][0]     \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 512)  2359808     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 512)  2048        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 512)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 512)  2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 512)  2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          131328      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           2570        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 11,296,074\n",
            "Trainable params: 11,288,394\n",
            "Non-trainable params: 7,680\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "executive-subsection"
      },
      "source": [
        ""
      ],
      "id": "executive-subsection",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cosmetic-grant",
        "outputId": "ad269862-3075-4172-faf8-a60e9dd6e1f2"
      },
      "source": [
        "# Sanity check to see whether the defined model works-\n",
        "resnet_model.predict(images).shape"
      ],
      "id": "cosmetic-grant",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "turkish-floating"
      },
      "source": [
        ""
      ],
      "id": "turkish-floating",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unauthorized-morris"
      },
      "source": [
        ""
      ],
      "id": "unauthorized-morris",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-hotel"
      },
      "source": [
        "# Define callback-\n",
        "callback = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience = 3,\n",
        "        min_delta = 0.001\n",
        "    )\n",
        "]"
      ],
      "id": "anonymous-hotel",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twenty-heading"
      },
      "source": [
        ""
      ],
      "id": "twenty-heading",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brave-blood"
      },
      "source": [
        "# Compile defined model-\n",
        "resnet_model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss_fn,\n",
        "    metrics = ['acc']\n",
        ")"
      ],
      "id": "brave-blood",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "million-helicopter"
      },
      "source": [
        ""
      ],
      "id": "million-helicopter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defined-dominant",
        "outputId": "f90a2c3b-ef31-46d5-c1c0-7f5697502244"
      },
      "source": [
        "# Train model-\n",
        "resnet_history = resnet_model.fit(\n",
        "    train_dataset, epochs = num_epochs,\n",
        "    validation_data = test_dataset,\n",
        "    callbacks = callback\n",
        ")"
      ],
      "id": "defined-dominant",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "390/390 [==============================] - 200s 493ms/step - loss: nan - acc: 0.1020 - val_loss: nan - val_acc: 0.1000\n",
            "Epoch 2/200\n",
            "390/390 [==============================] - 195s 491ms/step - loss: nan - acc: 0.1014 - val_loss: nan - val_acc: 0.1000\n",
            "Epoch 3/200\n",
            "390/390 [==============================] - 196s 492ms/step - loss: nan - acc: 0.1010 - val_loss: nan - val_acc: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cellular-adoption"
      },
      "source": [
        ""
      ],
      "id": "cellular-adoption",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "threaded-aurora"
      },
      "source": [
        ""
      ],
      "id": "threaded-aurora",
      "execution_count": null,
      "outputs": []
    }
  ]
}