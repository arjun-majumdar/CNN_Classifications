{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ResNet-9_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimum-tribe"
      },
      "source": [
        "# ResNet-9: CIFAR-10"
      ],
      "id": "optimum-tribe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tested-offense"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# import tensorflow_model_optimization as tfmot\n",
        "# from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "# from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, MaxPooling2D, ReLU, BatchNormalization\n",
        "from tensorflow.keras import models, layers, datasets\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, InputLayer, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "# import math\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "id": "tested-offense",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "available-poverty"
      },
      "source": [
        ""
      ],
      "id": "available-poverty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "polar-runner",
        "outputId": "9458616a-4f3e-4abe-e7e3-7474f380dae4"
      },
      "source": [
        "tf.__version__"
      ],
      "id": "polar-runner",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conventional-hands"
      },
      "source": [
        ""
      ],
      "id": "conventional-hands",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "constitutional-thunder"
      },
      "source": [
        "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
        "# %env CUDA_VISIBLE_DEVICES=2"
      ],
      "id": "constitutional-thunder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "essential-communist",
        "outputId": "b9cd1771-9e6b-41a7-c0e3-6d7a78d86ba9"
      },
      "source": [
        "# Check GPU availibility-\n",
        "'''\n",
        "This API allows querying the physical hardware resources prior to runtime\n",
        "initialization. Thus, giving an opportunity to call any additional\n",
        "configuration APIs.\n",
        "The following code lists the number of visible GPUs on the host-\n",
        "'''\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f\"Number of physical GPUs available: {len(physical_gpus)}\")"
      ],
      "id": "essential-communist",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of physical GPUs available: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "given-warehouse"
      },
      "source": [
        ""
      ],
      "id": "given-warehouse",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "direct-charlotte"
      },
      "source": [
        ""
      ],
      "id": "direct-charlotte",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "convenient-footwear"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "num_epochs = 200"
      ],
      "id": "convenient-footwear",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skilled-advisory",
        "outputId": "af6b16ff-3b65-4d84-f586-c0783ddacc2b"
      },
      "source": [
        "# Data preprocessing and cleaning:\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "\n",
        "# Load CIFAR-10 dataset-\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Load CIFAR-100 dataset-\n",
        "# (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "id": "skilled-advisory",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prescribed-scott",
        "outputId": "bbf88233-426d-4944-a514-10289e2ca513"
      },
      "source": [
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (3, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "print(\"\\n'input_shape' which will be used = {0}\\n\".format(input_shape))"
      ],
      "id": "prescribed-scott",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "'input_shape' which will be used = (32, 32, 3)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compliant-triple"
      },
      "source": [
        "# convert class vectors/target to binary class matrices or one-hot encoded values-\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "id": "compliant-triple",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "behavioral-backup",
        "outputId": "dca584f7-e5b8-4375-eff5-fbeff364a642"
      },
      "source": [
        "print(\"\\nDimensions of training and testing sets are:\")\n",
        "print(\"X_train.shape = {0}, y_train.shape = {1}\".format(X_train.shape, y_train.shape))\n",
        "print(\"X_test.shape = {0}, y_test.shape = {1}\".format(X_test.shape, y_test.shape))"
      ],
      "id": "behavioral-backup",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dimensions of training and testing sets are:\n",
            "X_train.shape = (50000, 32, 32, 3), y_train.shape = (50000, 10)\n",
            "X_test.shape = (10000, 32, 32, 3), y_test.shape = (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "breathing-harbor"
      },
      "source": [
        ""
      ],
      "id": "breathing-harbor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accepting-conditions"
      },
      "source": [
        "# Instantiate TensorFlow's Dataset class for creating training and testing datasets-\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "id": "accepting-conditions",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-habitat"
      },
      "source": [
        ""
      ],
      "id": "senior-habitat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korean-superintendent"
      },
      "source": [
        ""
      ],
      "id": "korean-superintendent",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "light-resident"
      },
      "source": [
        "### Data Augmentation:\n",
        "\n",
        "Augment CIFAR-10 dataset by performing the following steps on every image:\n",
        "\n",
        "- Pad the image with a black, four-pixel border.\n",
        "- Randomly crop a 32 x 32 region from the padded image.\n",
        "- Flip a coin to determine if the image should be horizontally flipped."
      ],
      "id": "light-resident"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adjacent-boxing"
      },
      "source": [
        "HEIGHT = 32\n",
        "WIDTH = 32\n",
        "NUM_CHANNELS = 3"
      ],
      "id": "adjacent-boxing",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assured-pakistan"
      },
      "source": [
        ""
      ],
      "id": "assured-pakistan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "studied-relay"
      },
      "source": [
        "def augmentation(x, y):\n",
        "    x = tf.image.resize_with_crop_or_pad(x, HEIGHT + 8, WIDTH + 8)\n",
        "    x = tf.image.random_crop(x, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "\n",
        "    return x, y"
      ],
      "id": "studied-relay",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indoor-phoenix"
      },
      "source": [
        "def normalize(x, y):\n",
        "    x = tf.image.per_image_standardization(x)\n",
        "    return x, y"
      ],
      "id": "indoor-phoenix",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "provincial-subdivision"
      },
      "source": [
        ""
      ],
      "id": "provincial-subdivision",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "further-modem"
      },
      "source": [
        "# Augment training dataset\n",
        "train_dataset = (train_dataset\n",
        "        .map(augmentation)\n",
        "        .shuffle(buffer_size = 50000)\n",
        "        .map(normalize)\n",
        "        .batch(batch_size = batch_size, drop_remainder = True))\n",
        "\n",
        "\n",
        "# NOTE: Do NOT augment the testing dataset!"
      ],
      "id": "further-modem",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plastic-secondary"
      },
      "source": [
        ""
      ],
      "id": "plastic-secondary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "destroyed-ability"
      },
      "source": [
        "# Obtain a batch size set of training images and labels-\n",
        "images, labels = next(iter(train_dataset))"
      ],
      "id": "destroyed-ability",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alpha-aruba",
        "outputId": "863e1105-b753-4d46-97a7-0f8c730805df"
      },
      "source": [
        "images.shape, images.shape"
      ],
      "id": "alpha-aruba",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 32, 32, 3]), TensorShape([128, 32, 32, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resistant-malaysia"
      },
      "source": [
        ""
      ],
      "id": "resistant-malaysia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "norwegian-mixture"
      },
      "source": [
        ""
      ],
      "id": "norwegian-mixture",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "universal-writing"
      },
      "source": [
        ""
      ],
      "id": "universal-writing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shared-token"
      },
      "source": [
        ""
      ],
      "id": "shared-token",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caroline-lincoln"
      },
      "source": [
        "### Prepare CIFAR10 dataset for GradientTape training:"
      ],
      "id": "caroline-lincoln"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unusual-defendant"
      },
      "source": [
        "# Choose an optimizer and loss function for training-\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.9)"
      ],
      "id": "unusual-defendant",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paperback-valuation"
      },
      "source": [
        "# Select metrics to measure the error & accuracy of model.\n",
        "# These metrics accumulate the values over epochs and then\n",
        "# print the overall result-\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')"
      ],
      "id": "paperback-valuation",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spectacular-youth"
      },
      "source": [
        ""
      ],
      "id": "spectacular-youth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dietary-replica"
      },
      "source": [
        ""
      ],
      "id": "dietary-replica",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "integrated-brazil"
      },
      "source": [
        "### ResNet-9 model experimentation:"
      ],
      "id": "integrated-brazil"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "alien-scott",
        "outputId": "7632819e-1645-4960-e0df-f194d40b0701"
      },
      "source": [
        "inputs = keras.Input(shape = (32, 32, 3))\n",
        "\n",
        "x = Conv2D(\n",
        "    filters = 32, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same')(inputs)\n",
        "\n",
        "'''\n",
        "x = Conv2D(\n",
        "    filters = 64, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size = (3, 3), strides = (1, 1))(x)\n",
        "'''"
      ],
      "id": "alien-scott",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nx = Conv2D(\\n    filters = 64, kernel_size = (3, 3),\\n    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\\n    strides = (1, 1), padding = 'same')(x)\\n\\nx = MaxPooling2D(pool_size = (3, 3), strides = (1, 1))(x)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "above-grant",
        "outputId": "81e23e24-dbdb-4345-a91c-dc892fb28099"
      },
      "source": [
        "x.shape"
      ],
      "id": "above-grant",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 32, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stainless-lodging"
      },
      "source": [
        ""
      ],
      "id": "stainless-lodging",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "light-chambers"
      },
      "source": [
        ""
      ],
      "id": "light-chambers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nonprofit-spain"
      },
      "source": [
        "def resnet_block(input_data, num_filters, stride_length, conv_1x1 = False):\n",
        "    '''\n",
        "    Function to implement ResNet block as defined in the research paper.\n",
        "    '''\n",
        "    \n",
        "    img = Conv2D(\n",
        "        filters = num_filters, kernel_size = (3, 3),\n",
        "        activation = None, kernel_initializer = tf.initializers.he_normal(),\n",
        "        strides = stride_length, padding = 'same')(input_data)\n",
        "    img = BatchNormalization()(img)\n",
        "    img = layers.Activation('relu')(img)\n",
        "    \n",
        "    img = Conv2D(\n",
        "        filters = num_filters, kernel_size = (3, 3),\n",
        "        activation = None, kernel_initializer = tf.initializers.he_normal(),\n",
        "        strides = stride_length, padding = 'same')(img)\n",
        "    img = BatchNormalization()(img)\n",
        "    \n",
        "    \n",
        "    # Adjust number of filters/channels using 1x1 conv layer-\n",
        "    if conv_1x1:\n",
        "        input_data = Conv2D(\n",
        "            filters = num_filters, kernel_size = (1, 1),\n",
        "            activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "            strides = (1, 1), padding = 'same'\n",
        "        )(input_data)\n",
        "        \n",
        "    \n",
        "    print(f\"ResNet block (before adding): img.shape (output of conv layers) = {img.shape} & input_data.shape = {input_data.shape}\")\n",
        "    img = layers.Add()([img, input_data])\n",
        "    \n",
        "    img = layers.Activation('relu')(img)\n",
        "    \n",
        "    return img\n",
        "    \n"
      ],
      "id": "nonprofit-spain",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brilliant-faith"
      },
      "source": [
        ""
      ],
      "id": "brilliant-faith",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awful-outreach",
        "outputId": "5c1af800-b1d1-440e-eea2-7cfd945f90d8"
      },
      "source": [
        "# inputs = keras.Input(shape = (32, 32, 3))\n",
        "\n",
        "x = Conv2D(\n",
        "    filters = 32, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same',\n",
        "    input_shape = (32, 32, 3)\n",
        "    )(inputs)\n",
        "\n",
        "'''\n",
        "x = Conv2D(\n",
        "    filters = 64, kernel_size = (3, 3),\n",
        "    activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n",
        "    strides = (1, 1), padding = 'same')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size = (3, 3), strides = (1, 1))(x)\n",
        "\n",
        "x.shape\n",
        "# TensorShape([None, 30, 30, 64])\n",
        "'''\n",
        "\n",
        "x.shape\n",
        "# TensorShape([None, 32, 32, 32])\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 64, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 64, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 128, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 128, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 256, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 256, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "x = resnet_block(input_data = x, num_filters = 512, stride_length = 1, conv_1x1 = True)\n",
        "x = resnet_block(input_data = x, num_filters = 512, stride_length = 1, conv_1x1 = False)\n",
        "\n",
        "# x.shape\n",
        "# TensorShape([None, 32, 32, 512])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = layers.Dense(\n",
        "    units = 256, activation='relu',\n",
        "    kernel_initializer = tf.initializers.he_normal()\n",
        ")(x)\n",
        "\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "\n",
        "outputs = layers.Dense(units = 10, activation='softmax')(x)"
      ],
      "id": "awful-outreach",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 64) & input_data.shape = (None, 32, 32, 64)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 64) & input_data.shape = (None, 32, 32, 64)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 128) & input_data.shape = (None, 32, 32, 128)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 128) & input_data.shape = (None, 32, 32, 128)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 256) & input_data.shape = (None, 32, 32, 256)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 256) & input_data.shape = (None, 32, 32, 256)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 512) & input_data.shape = (None, 32, 32, 512)\n",
            "ResNet block (before adding): img.shape (output of conv layers) = (None, 32, 32, 512) & input_data.shape = (None, 32, 32, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unusual-millennium"
      },
      "source": [
        ""
      ],
      "id": "unusual-millennium",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expensive-appendix"
      },
      "source": [
        "# Define ResNet model-\n",
        "resnet_model = keras.Model(inputs, outputs)"
      ],
      "id": "expensive-appendix",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "attempted-relief"
      },
      "source": [
        "# model = Model(inputs, x)"
      ],
      "id": "attempted-relief",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "according-deviation",
        "outputId": "f771c171-5a6e-4f9f-a58d-97f42314700f"
      },
      "source": [
        "resnet_model.summary()"
      ],
      "id": "according-deviation",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   18496       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36928       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   2112        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  8320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           batch_normalization_5[0][0]      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  295168      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 256)  33024       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 512)  1180160     activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 512)  2359808     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 512)  2048        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 512)  131584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 512)  0           batch_normalization_13[0][0]     \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 512)  2359808     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 512)  2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 512)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 512)  2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 512)  2048        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          131328      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           2570        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 11,296,074\n",
            "Trainable params: 11,288,394\n",
            "Non-trainable params: 7,680\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "executive-subsection"
      },
      "source": [
        ""
      ],
      "id": "executive-subsection",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cosmetic-grant",
        "outputId": "796b79da-6bfb-42c6-b5da-6fb5b9bfd112"
      },
      "source": [
        "# Sanity check to see whether the defined model works-\n",
        "resnet_model.predict(images).shape"
      ],
      "id": "cosmetic-grant",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "turkish-floating"
      },
      "source": [
        ""
      ],
      "id": "turkish-floating",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unauthorized-morris"
      },
      "source": [
        ""
      ],
      "id": "unauthorized-morris",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-hotel"
      },
      "source": [
        "# Define callback-\n",
        "callback = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience = 3,\n",
        "        min_delta = 0.001\n",
        "    )\n",
        "]"
      ],
      "id": "anonymous-hotel",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twenty-heading"
      },
      "source": [
        ""
      ],
      "id": "twenty-heading",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brave-blood"
      },
      "source": [
        "# Compile defined model-\n",
        "resnet_model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss_fn,\n",
        "    metrics = ['acc']\n",
        ")"
      ],
      "id": "brave-blood",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "million-helicopter"
      },
      "source": [
        ""
      ],
      "id": "million-helicopter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "defined-dominant",
        "outputId": "a7a37113-c23e-45e5-da6b-8c52181ef028"
      },
      "source": [
        "# Train model-\n",
        "resnet_history = resnet_model.fit(\n",
        "    train_dataset, epochs = num_epochs,\n",
        "    validation_data = test_dataset,\n",
        "    callbacks = callback\n",
        ")"
      ],
      "id": "defined-dominant",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "390/390 [==============================] - ETA: 0s - loss: nan - acc: 0.1031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-433cb05c2f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 32, 32, 3), found shape=(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cellular-adoption"
      },
      "source": [
        ""
      ],
      "id": "cellular-adoption",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "threaded-aurora"
      },
      "source": [
        ""
      ],
      "id": "threaded-aurora",
      "execution_count": null,
      "outputs": []
    }
  ]
}