{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZOD2mGIeyEJ"
   },
   "source": [
    "# ResNet-34 CNN: PyTorch & CIFAR-10\n",
    "\n",
    "End-to-end programming tutorial including:\n",
    "\n",
    "1. Progress bar - training model\n",
    "1. Train model with _early stopping criterion_\n",
    "1. Learning rate scheduler\n",
    "1. Compare between learning rate scheduler and early stopping criterion\n",
    "\n",
    "[Reference](https://d2l.ai/chapter_convolutional-modern/resnet.html#fig-residual-block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7hpnDY7Mfb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# Specify GPU to be used-\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cM6Ih3nVq0Gh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DvYMsqNezdm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha-v5IiWezqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_H9KbTonq0Q9",
    "outputId": "41b72a44-64e1-44c2-a917-615e9adafb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently available device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration-\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"currently available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of available GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "# Get number of multiple GPUs (if any)-\n",
    "print(f\"number of available GPUs = {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU = 0\n"
     ]
    }
   ],
   "source": [
    "# Get current GPU-\n",
    "print(f\"Current GPU = {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of current GPU being used = Quadro M6000\n"
     ]
    }
   ],
   "source": [
    "# Get name of current GPU-\n",
    "print(f\"Name of current GPU being used = {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2CJ2XyNq9Nd",
    "outputId": "3e5961db-ccb3-4be4-9207-21d280f44beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6rTKbcZrBN0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uV1m3vD0rBee"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters-\n",
    "num_epochs = 65\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QGc3oYHrDzL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9R6Sc5v6rD8M"
   },
   "outputs": [],
   "source": [
    "# Define transformations for training and test sets-\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomCrop(32, padding = 4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "4ddOxdkirHPN",
    "outputId": "764e40cc-2f3c-482f-bbb1-542c39d0d1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset-\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = True,\n",
    "        download = True, transform = transform_train\n",
    "        )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = False,\n",
    "        download = True, transform = transform_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW8h3ztJrU5_",
    "outputId": "643be603-0775-412b-9a3d-7dfbe5df1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) = 50000 & len(test_dataset) = 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_dataset) = {len(train_dataset)} & len(test_dataset) = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cydrwaW7rbnV"
   },
   "outputs": [],
   "source": [
    "# Create training and testing loaders-\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size = batch_size,\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size = batch_size,\n",
    "        shuffle = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62AgWl9jrfzW",
    "outputId": "0972fead-2556-4cea-9ff4-8f50eabf6cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 391 & len(test_loader) = 79\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_loader) = {len(train_loader)} & len(test_loader) = {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjGADCMfrhAl",
    "outputId": "e3bb3177-720d-48ce-ef5a-b0e61c5ac9bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390.625, 78.125)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "len(train_dataset) / batch_size, len(test_dataset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEBunYxErhh8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhwdHTu0rsf8",
    "outputId": "c84eaa78-265f-4af7-dbdf-f45370c2bb4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 32, 32]), torch.Size([128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "len(train_dataset) / batch_size, len(test_dataset) / batch_size\n",
    "\n",
    "# Sanity check-\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "images.size(), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOgym6Ffrtds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ln5CjwJhrtqc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdWaY-5NruCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlFoyg5Hruqn"
   },
   "source": [
    "### Define _ResNet-34_ architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    '''\n",
    "    Residual Block within a ResNet CNN model\n",
    "    '''\n",
    "    def __init__(self, input_channels, num_channels, \n",
    "                 use_1x1_conv = False, strides = 1):\n",
    "        # super(ResidualBlock, self).__init__()\n",
    "        super().__init__()\n",
    "     \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = input_channels, out_channels = num_channels,\n",
    "            kernel_size = 3, padding = 1, stride = strides,\n",
    "            bias = False\n",
    "            )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = num_channels, out_channels = num_channels,\n",
    "            kernel_size = 3, padding = 1, stride = 1,\n",
    "            bias = False\n",
    "            )\n",
    "        \n",
    "        if use_1x1_conv:\n",
    "            self.conv3 = nn.Conv2d(\n",
    "                in_channels = input_channels, out_channels = num_channels,\n",
    "                kernel_size = 1, stride = strides\n",
    "                )\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features = num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features = num_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        \n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "            # print(f\"X.shape due to 1x1: {X.shape} & Y.shape = {Y.shape}\")\n",
    "        else:\n",
    "            # print(f\"X.shape without 1x1: {X.shape} & Y.shape = {Y.shape}\")\n",
    "            pass\n",
    "        \n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "    \n",
    "    \n",
    "    def shape_computation(self, X):\n",
    "        Y = self.conv1(X)\n",
    "        print(f\"self.conv1(X).shape: {Y.shape}\")\n",
    "        Y = self.conv2(Y)\n",
    "        print(f\"self.conv2(X).shape: {Y.shape}\")\n",
    "        \n",
    "        if self.conv3:\n",
    "            h = self.conv3(X)\n",
    "            print(f\"self.conv3(X).shape: {h.shape}\")\n",
    "    \n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            # print(m)\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "\n",
    "                '''\n",
    "                # Do not initialize bias (due to batchnorm)-\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                '''\n",
    "            \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                # Standard initialization for batch normalization-\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.BatchNorm2d(num_features = 64),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "b0(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet_block(input_filters, output_filters, num_residuals, first_block = False):\n",
    "    # Python list to hold the created ResNet blocks-\n",
    "    resnet_blk = []\n",
    "    \n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and first_block:\n",
    "            resnet_blk.append(ResidualBlock(input_channels = input_filters, num_channels = output_filters, use_1x1_conv = True, strides = 2))\n",
    "        else:\n",
    "            resnet_blk.append(ResidualBlock(input_channels = output_filters, num_channels = output_filters, use_1x1_conv = False, strides = 1))\n",
    "    \n",
    "    return resnet_blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet34():\n",
    "    b1 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 64, num_residuals = 3, first_block = True))\n",
    "    b2 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 128, num_residuals = 4, first_block = True))\n",
    "    b3 = nn.Sequential(*create_resnet_block(input_filters = 128, output_filters = 256, num_residuals = 6, first_block = True))\n",
    "    b4 = nn.Sequential(*create_resnet_block(input_filters = 256, output_filters = 512, num_residuals = 3, first_block = True))\n",
    "    \n",
    "        \n",
    "    model = nn.Sequential(\n",
    "        b0, b1, b2, b3, b4,\n",
    "        nn.AdaptiveAvgPool2d(output_size = (1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features = 512, out_features = 256),\n",
    "        nn.Linear(in_features = 256, out_features = 10)\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet-34 model-\n",
    "model = create_resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "v_NeRxjgbOGE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "model(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9aSBydxsD27",
    "outputId": "79ba1ecd-97d6-4c18-fea7-2acb2cbe66f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (8): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU-\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SnL7fjksJLh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9A-AfIXwcE6u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8zux0jjsHq0",
    "outputId": "e986b7ad-171b-474c-cb60-2097fdecc112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.shape = torch.Size([64, 3, 3, 3]) has 1728 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 1, 1]) has 4096 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([128, 64, 3, 3]) has 73728 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128, 64, 1, 1]) has 8192 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([256, 128, 3, 3]) has 294912 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 128, 1, 1]) has 32768 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([512, 256, 3, 3]) has 1179648 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512, 256, 1, 1]) has 131072 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([256, 512]) has 131072 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([10, 256]) has 2560 parameters\n",
      "layer.shape = torch.Size([10]) has 10 parameters\n"
     ]
    }
   ],
   "source": [
    "# Count number of layer-wise parameters and total parameters-\n",
    "tot_params = 0\n",
    "for param in model.parameters():\n",
    "    print(f\"layer.shape = {param.shape} has {param.nelement()} parameters\")\n",
    "    tot_params += param.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp9X8qnOsY1t",
    "outputId": "161ec2b1-37d8-4676-dcf8-aa96cf9bfc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in ResNet-34 CNN = 21414218\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of parameters in ResNet-34 CNN = {tot_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WdKiWsLsZYN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Print layer names-\n",
    "for layer in model.state_dict().keys():\n",
    "    print(f\"{layer} has dimension = {model.state_dict()[layer].shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1jFfuJiscmN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "O_WUBfzFscrc"
   },
   "outputs": [],
   "source": [
    "# Save random initial weights-\n",
    "torch.save(model.state_dict(), 'ResNet34_random_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gdgada5J5mIR",
    "outputId": "4ad9e79d-a499-4831-c030-219544802967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "# model.load_state_dict(torch.load('ResNet34_random_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGUR1m04stvU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "OozQ7SF4st4U"
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer-\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NXRjN5is4eF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "stjVD5uus0xW"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def train_step(model, train_loader):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    for batch, (images, labels) in enumerate(train_loader):\n",
    "        # Attempt to push to GPU if available\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # print(f\"batch # = {batch}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass-\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss-\n",
    "        J = loss(outputs, labels)\n",
    "\n",
    "        # Backward pass-\n",
    "        optimizer.zero_grad()   # empty accumulated gradients\n",
    "\n",
    "        J.backward()    # perform backpropagation\n",
    "\n",
    "        # Updates parameters-\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute model's performance statistics-\n",
    "        running_loss += J.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "        '''\n",
    "        # Print information every 100 steps-\n",
    "        if (batch + 1) % 100 == 0:\n",
    "            print(f\"epoch {epoch + 1}/{num_epochs}, step {batch + 1}/{num_training_steps}, loss = {J.item():.4f}\")\n",
    "        '''\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "    return epoch_loss, epoch_acc.cpu().numpy()\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0DyTwwRhcOeY"
   },
   "outputs": [],
   "source": [
    "def train_model_progress(model, train_loader):\n",
    "    '''\n",
    "    Function to perform one epoch of training by using 'train_loader'.\n",
    "    Returns loss and number of correct predictions for this epoch.\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Training: \")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions-\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss-\n",
    "            J = loss(outputs, labels)\n",
    "            \n",
    "            # Empty accumulated gradients-\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform backprop-\n",
    "            J.backward()\n",
    "            \n",
    "            # Update parameters-\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute model's performance statistics-\n",
    "            running_loss += J.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "            tepoch.set_postfix(\n",
    "                loss = running_loss / len(train_dataset),\n",
    "                accuracy = (running_corrects.double().cpu().numpy() / len(train_dataset)) * 100\n",
    "            )\n",
    "            \n",
    "    \n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "\n",
    "    # return running_loss, running_corrects\n",
    "    return train_loss, train_acc.cpu().numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCq8FAdOckD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lHUDSkX8s8Od"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def validate_step(model, test_loader):\n",
    "    total, correct = 0, 0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            # Place features (images) and targets (labels) to GPU-\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Set model to evaluation mode-\n",
    "            model.eval()\n",
    "    \n",
    "            # Make predictions using trained model-\n",
    "            outputs = model(images)\n",
    "            _, y_pred = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute validation loss-\n",
    "            J_val = loss(outputs, labels)\n",
    "\n",
    "            running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "            # Total number of labels-\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Total number of correct predictions-\n",
    "            correct += (y_pred == labels).sum()\n",
    "\n",
    "    epoch_val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = 100 * (correct / total)\n",
    "\n",
    "    return epoch_val_loss, val_acc.cpu().numpy()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "YymBc1UtcnEA"
   },
   "outputs": [],
   "source": [
    "def test_model_progress(model, test_loader):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit = 'batch') as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                tepoch.set_description(f\"Validation: \")\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Set model to evaluation mode-\n",
    "                model.eval()\n",
    "            \n",
    "                # Predict using trained model-\n",
    "                outputs = model(images)\n",
    "                _, y_pred = torch.max(outputs, 1)\n",
    "                \n",
    "                # Compute validation loss-\n",
    "                J_val = loss(outputs, labels)\n",
    "                \n",
    "                running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "                # Total number of labels-\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total number of correct predictions-\n",
    "                correct += (y_pred == labels).sum()\n",
    "                \n",
    "                tepoch.set_postfix(\n",
    "                    val_loss = running_loss_val / len(test_dataset),\n",
    "                    val_acc = 100 * (correct.cpu().numpy() / total)\n",
    "                )\n",
    "            \n",
    "        \n",
    "    # return (running_loss_val, correct, total)\n",
    "    val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = (correct / total) * 100\n",
    "\n",
    "    return val_loss, val_acc.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3BGHQY9YcuqJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5OVpgCicu1i",
    "outputId": "20d63dcf-26b5-4958-96f7-c134ef794420"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:08<00:00,  1.57batch/s, accuracy=45.5, loss=1.47]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check-\n",
    "train_loss, train_acc = train_model_progress(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AP1HjJC6c7nS",
    "outputId": "44c7dcd7-c693-4904-9328-d6cf916ab75f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: : 100%|██████████| 79/79 [00:08<00:00,  9.06batch/s, val_acc=56.6, val_loss=1.21]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check-\n",
    "val_loss, val_acc = test_model_progress(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgTblttjdFXu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gw4-9h2vibj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDIK4_3W8L95"
   },
   "source": [
    "### Train model _without_ learning rate scheduler, using early-stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NOytz_v9tPxV"
   },
   "outputs": [],
   "source": [
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "SbXa8wiR6OHv"
   },
   "outputs": [],
   "source": [
    "# User input parameters for Early Stopping in manual implementation-\n",
    "minimum_delta = 0.001\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "K1oqH6x25YFS"
   },
   "outputs": [],
   "source": [
    "training_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qYVpzJ0_h97Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "G7E2MwUJh-Dv",
    "outputId": "e29a407f-e25c-4b77-9ee2-3bd839eb7952"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:18<00:00,  4.97batch/s, accuracy=39, loss=1.64]    \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.80batch/s, val_acc=48.8, val_loss=1.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 training loss = 1.6414, training accuracy = 39.00%, val_loss = 1.3950, val_accuracy = 48.83% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.3950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.44batch/s, accuracy=52.2, loss=1.31]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.12batch/s, val_acc=58, val_loss=1.16]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 training loss = 1.3080, training accuracy = 52.17%, val_loss = 1.1558, val_accuracy = 57.96% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.1558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:09<00:00,  5.59batch/s, accuracy=60.1, loss=1.12]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.65batch/s, val_acc=63.7, val_loss=1.02] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 training loss = 1.1163, training accuracy = 60.13%, val_loss = 1.0176, val_accuracy = 63.73% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.0176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.44batch/s, accuracy=64.9, loss=0.986] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.93batch/s, val_acc=66.8, val_loss=0.943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 training loss = 0.9861, training accuracy = 64.88%, val_loss = 0.9426, val_accuracy = 66.77% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.9426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=68.7, loss=0.886] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.52batch/s, val_acc=69.9, val_loss=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5 training loss = 0.8857, training accuracy = 68.71%, val_loss = 0.8669, val_accuracy = 69.86% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.8669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.43batch/s, accuracy=71.5, loss=0.807] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.43batch/s, val_acc=71.2, val_loss=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6 training loss = 0.8071, training accuracy = 71.50%, val_loss = 0.8251, val_accuracy = 71.19% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.8251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:16<00:00,  5.13batch/s, accuracy=74.1, loss=0.738] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.24batch/s, val_acc=74.4, val_loss=0.748] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7 training loss = 0.7380, training accuracy = 74.13%, val_loss = 0.7479, val_accuracy = 74.35% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.7479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.36batch/s, accuracy=76, loss=0.68]    \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.90batch/s, val_acc=75.8, val_loss=0.698] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8 training loss = 0.6796, training accuracy = 76.05%, val_loss = 0.6981, val_accuracy = 75.84% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:16<00:00,  5.14batch/s, accuracy=77.9, loss=0.633] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.18batch/s, val_acc=77.4, val_loss=0.685] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9 training loss = 0.6334, training accuracy = 77.95%, val_loss = 0.6847, val_accuracy = 77.42% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.40batch/s, accuracy=79.3, loss=0.591] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.98batch/s, val_acc=78.7, val_loss=0.634] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10 training loss = 0.5910, training accuracy = 79.28%, val_loss = 0.6341, val_accuracy = 78.66% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.21batch/s, accuracy=80.7, loss=0.558] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.23batch/s, val_acc=80.4, val_loss=0.584] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 11 training loss = 0.5583, training accuracy = 80.72%, val_loss = 0.5836, val_accuracy = 80.36% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.5836\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.49batch/s, accuracy=81.8, loss=0.525] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.76batch/s, val_acc=80.9, val_loss=0.565] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 12 training loss = 0.5248, training accuracy = 81.81%, val_loss = 0.5650, val_accuracy = 80.88% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.5650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.19batch/s, accuracy=82.4, loss=0.503] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.97batch/s, val_acc=80.6, val_loss=0.579] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 13 training loss = 0.5033, training accuracy = 82.42%, val_loss = 0.5793, val_accuracy = 80.59% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:08<00:00,  5.75batch/s, accuracy=83.9, loss=0.466]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.06batch/s, val_acc=81.2, val_loss=0.569] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 14 training loss = 0.4663, training accuracy = 83.87%, val_loss = 0.5689, val_accuracy = 81.17% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.47batch/s, accuracy=84.6, loss=0.446]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.21batch/s, val_acc=81.7, val_loss=0.539] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 15 training loss = 0.4458, training accuracy = 84.59%, val_loss = 0.5394, val_accuracy = 81.66% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.5394\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.24batch/s, accuracy=85.1, loss=0.43]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.21batch/s, val_acc=81.8, val_loss=0.543] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 16 training loss = 0.4303, training accuracy = 85.08%, val_loss = 0.5429, val_accuracy = 81.82% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.47batch/s, accuracy=85.7, loss=0.413] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.61batch/s, val_acc=82, val_loss=0.543]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 17 training loss = 0.4133, training accuracy = 85.68%, val_loss = 0.5428, val_accuracy = 82.03% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.25batch/s, accuracy=86.4, loss=0.388] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.57batch/s, val_acc=83.5, val_loss=0.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 18 training loss = 0.3877, training accuracy = 86.43%, val_loss = 0.5002, val_accuracy = 83.50% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.5002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.20batch/s, accuracy=87.1, loss=0.376]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.78batch/s, val_acc=82.6, val_loss=0.536] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 19 training loss = 0.3758, training accuracy = 87.12%, val_loss = 0.5364, val_accuracy = 82.60% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=87.2, loss=0.367] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.72batch/s, val_acc=85.1, val_loss=0.45]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20 training loss = 0.3668, training accuracy = 87.22%, val_loss = 0.4496, val_accuracy = 85.06% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.43batch/s, accuracy=88, loss=0.35]    \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.05batch/s, val_acc=83.7, val_loss=0.524] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 training loss = 0.3500, training accuracy = 88.02%, val_loss = 0.5240, val_accuracy = 83.67% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.21batch/s, accuracy=88.2, loss=0.336]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 13.10batch/s, val_acc=84.2, val_loss=0.471] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 22 training loss = 0.3365, training accuracy = 88.24%, val_loss = 0.4706, val_accuracy = 84.22% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.46batch/s, accuracy=88.9, loss=0.321] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.16batch/s, val_acc=84.7, val_loss=0.488] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 23 training loss = 0.3212, training accuracy = 88.87%, val_loss = 0.4877, val_accuracy = 84.72% & LR = 0.0100\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    if loc_patience >= patience:\n",
    "        print(\"\\n'EarlyStopping' called!\\n\")\n",
    "        break\n",
    "\n",
    "    train_loss, train_acc = train_model_progress(model, train_loader)\n",
    "    val_loss, val_acc = test_model_progress(model, test_loader)\n",
    "    \n",
    "    print(f\"\\nepoch: {epoch + 1} training loss = {train_loss:.4f}, \"\n",
    "          f\"training accuracy = {train_acc:.2f}%, val_loss = {val_loss:.4f}\"\n",
    "          f\", val_accuracy = {val_acc:.2f}% & \"\n",
    "          f\"LR = {optimizer.param_groups[0]['lr']:.4f}\\n\")\n",
    "    \n",
    "    training_history[epoch + 1] = {\n",
    "        'loss': train_loss, 'acc': train_acc,\n",
    "        'val_loss': val_loss, 'val_acc': val_acc,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    # Save best weights achieved until now-\n",
    "    if (val_loss < best_val_loss):    \n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"ResNet34_best_model.pth\")\n",
    "    '''\n",
    "\n",
    "    # Code for manual Early Stopping:\n",
    "    # if np.abs(val_loss < best_val_loss) >= minimum_delta:\n",
    "    if (val_loss < best_val_loss) and \\\n",
    "    (np.abs(val_loss - best_val_loss) >= minimum_delta):\n",
    "\n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "        \n",
    "        # reset 'loc_patience' variable-\n",
    "        loc_patience = 0\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"ResNet34_best_model.pth\")\n",
    "        \n",
    "    else:  # there is no improvement in monitored metric 'val_loss'\n",
    "        loc_patience += 1  # number of epochs without any improvement\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HW6eI7f-4W9R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3dcgzOwii1g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXesVlcAtj_U",
    "outputId": "fa906693-19de-4aa6-fe1c-b4d197346f26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COrZUx-_P6Zx",
    "outputId": "66e63461-5f0b-436b-b4fd-5615ef5c769b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history[2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0ZrNvFoP_fZ",
    "outputId": "d1441b8f-507c-4044-93ae-c4a775c61fb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(57.96, dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history[2]['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loPQquhpQC9Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yJkajjh9QGKK"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "0G1TaNnnQHDI"
   },
   "outputs": [],
   "source": [
    "with open(\"ResNet34_earlystopping_training_history.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiAv9vgBQigh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MuBmbE6CQuPO"
   },
   "outputs": [],
   "source": [
    "# Save trained weights-\n",
    "# torch.save(model.state_dict(), 'ResNet34_trained_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSOrFC5gQz9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0Fbk-V3Q0H8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WC2enWfbT5wt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with _learning rate scheduler_\n",
    "\n",
    "- Training dataset = 50000, batch size = 128, number of training steps/iterations = 50000 / 128 = 391\n",
    "\n",
    "- Initial learning rate warmup: 391 x 10 = 3910 steps or, 10 epochs at LR = 0.1\n",
    "\n",
    "- Until 25th epoch or, 9775 steps use LR = 0.1\n",
    "\n",
    "- From 26th epoch until 40th epoch or, 15640 steps use LR = 0.01\n",
    "\n",
    "- From 41st epoch until 50th epoch or, 19550 steps use LR = 0.001\n",
    "\n",
    "- From 51st epoch until 60th epoch use LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [9775, 15640, 19550]\n",
    "values = [0.1, 0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ResNet-34 model-\n",
    "model = create_resnet34()\n",
    "\n",
    "# Load randomly initialised weights-\n",
    "model.load_state_dict(torch.load('ResNet34_random_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (8): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU-\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OozQ7SF4st4U"
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer-\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0, momentum = 0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_function(step, boundaries = [9775, 15640, 19550], values = [0.1, 0.01, 0.001, 0.0001]):\n",
    "    '''\n",
    "    1 epoch has 391 steps/iterations using batch size used above.\n",
    "    \n",
    "    Until 25th epochs, or 25 x 391 = 9775 steps, use lr = 0.1\n",
    "    From 26th epoch until 40th epoch, or 15640 steps use LR = 0.01\n",
    "    From 41st epoch until 50th epoch or, 19550 steps use LR = 0.001\n",
    "    From 51st epoch until 60th epoch use LR = 0.0001\n",
    "    '''\n",
    "    \n",
    "    for idx, bound in enumerate(boundaries):\n",
    "        if step < bound:\n",
    "            return values[idx]\n",
    "\n",
    "    return values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def decay_function(step, boundaries = [15640, 19550], values = [0.01, 0.001, 0.0001]):\n",
    "    '''\n",
    "    1 epoch has 391 steps/iterations using batch size used above.\n",
    "    \n",
    "    Until 40 epochs, or 40 x 391 = 15640 steps, use lr = 0.01\n",
    "    Until 50 epochs, or 50 x 391 = 19550 steps, use lr = 0.001\n",
    "    \n",
    "    For any remaining steps, use lr = 0.0001\n",
    "    '''\n",
    "    \n",
    "    for idx, bound in enumerate(boundaries):\n",
    "        if step < bound:\n",
    "            return values[idx]\n",
    "\n",
    "    return values[-1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decay_function(step = 2, boundaries = [0, 2, 4, 6, 8, 10], values = [10, 15, 20, 30, 40, 50, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class schedule():\n",
    "\n",
    "    def __init__(self, initial_learning_rate = 0.1, warmup_steps = 1000, decay_func = None):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_func = decay_func\n",
    "        self.warmup_step_size = initial_learning_rate/warmup_steps\n",
    "        self.current_lr = 0\n",
    "\n",
    "    def get_lr(self, step):\n",
    "        if step == 0:\n",
    "            return self.current_lr\n",
    "        elif step <= self.warmup_steps:\n",
    "            self.current_lr+=self.warmup_step_size\n",
    "            return self.current_lr\n",
    "        elif step > self.warmup_steps:\n",
    "            if self.decay_func:\n",
    "                return self.decay_func(step)\n",
    "        else:\n",
    "            return self.current_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 391 x 10 = 3910 steps (or, 10 epochs) is learning rate warmup\n",
    "custom_lr_scheduler = schedule(\n",
    "    initial_learning_rate = 0.1, warmup_steps = 3910,\n",
    "    decay_func = decay_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0DyTwwRhcOeY"
   },
   "outputs": [],
   "source": [
    "def train_model_progress(model, train_loader):\n",
    "    '''\n",
    "    Function to perform one epoch of training by using 'train_loader'.\n",
    "    Returns loss and number of correct predictions for this epoch.\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Training: \")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions-\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss-\n",
    "            J = loss(outputs, labels)\n",
    "            \n",
    "            # Empty accumulated gradients-\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform backprop-\n",
    "            J.backward()\n",
    "            \n",
    "            # Update parameters-\n",
    "            optimizer.step()\n",
    "            \n",
    "            global step\n",
    "            optimizer.param_groups[0]['lr'] = custom_lr_scheduler.get_lr(step)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            # Compute model's performance statistics-\n",
    "            running_loss += J.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "            tepoch.set_postfix(\n",
    "                loss = running_loss / len(train_dataset),\n",
    "                accuracy = (running_corrects.double().cpu().numpy() / len(train_dataset)) * 100\n",
    "            )\n",
    "            \n",
    "    \n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "\n",
    "    # return running_loss, running_corrects\n",
    "    return train_loss, train_acc.cpu().numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCq8FAdOckD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YymBc1UtcnEA"
   },
   "outputs": [],
   "source": [
    "def test_model_progress(model, test_loader):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit = 'batch') as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                tepoch.set_description(f\"Validation: \")\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Set model to evaluation mode-\n",
    "                model.eval()\n",
    "            \n",
    "                # Predict using trained model-\n",
    "                outputs = model(images)\n",
    "                _, y_pred = torch.max(outputs, 1)\n",
    "                \n",
    "                # Compute validation loss-\n",
    "                J_val = loss(outputs, labels)\n",
    "                \n",
    "                running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "                # Total number of labels-\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total number of correct predictions-\n",
    "                correct += (y_pred == labels).sum()\n",
    "                \n",
    "                tepoch.set_postfix(\n",
    "                    val_loss = running_loss_val / len(test_dataset),\n",
    "                    val_acc = 100 * (correct.cpu().numpy() / total)\n",
    "                )\n",
    "            \n",
    "        \n",
    "    # return (running_loss_val, correct, total)\n",
    "    val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = (correct / total) * 100\n",
    "\n",
    "    return val_loss, val_acc.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_lr_scheduler = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "NOytz_v9tPxV"
   },
   "outputs": [],
   "source": [
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.49batch/s, accuracy=31.7, loss=1.84]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.57batch/s, val_acc=44.6, val_loss=1.53] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 training loss = 1.8386, training accuracy = 31.68%, val_loss = 1.5302, val_accuracy = 44.62% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.5302\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.50batch/s, accuracy=48.4, loss=1.42]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.44batch/s, val_acc=49.7, val_loss=1.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 training loss = 1.4184, training accuracy = 48.38%, val_loss = 1.4618, val_accuracy = 49.68% & LR = 0.0200\n",
      "\n",
      "Saving model with lowest val_loss = 1.4618\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.48batch/s, accuracy=56.6, loss=1.22]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.99batch/s, val_acc=58.6, val_loss=1.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 training loss = 1.2212, training accuracy = 56.56%, val_loss = 1.1824, val_accuracy = 58.55% & LR = 0.0300\n",
      "\n",
      "Saving model with lowest val_loss = 1.1824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.20batch/s, accuracy=63.2, loss=1.06]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.74batch/s, val_acc=61.2, val_loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 training loss = 1.0556, training accuracy = 63.18%, val_loss = 1.1617, val_accuracy = 61.16% & LR = 0.0400\n",
      "\n",
      "Saving model with lowest val_loss = 1.1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.46batch/s, accuracy=67.9, loss=0.939] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.25batch/s, val_acc=65.4, val_loss=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5 training loss = 0.9389, training accuracy = 67.87%, val_loss = 0.9937, val_accuracy = 65.44% & LR = 0.0500\n",
      "\n",
      "Saving model with lowest val_loss = 0.9937\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=72.2, loss=0.822] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.81batch/s, val_acc=72.7, val_loss=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6 training loss = 0.8221, training accuracy = 72.16%, val_loss = 0.8452, val_accuracy = 72.66% & LR = 0.0600\n",
      "\n",
      "Saving model with lowest val_loss = 0.8452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.40batch/s, accuracy=74.2, loss=0.766] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 13.10batch/s, val_acc=74, val_loss=0.774]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7 training loss = 0.7658, training accuracy = 74.16%, val_loss = 0.7742, val_accuracy = 73.96% & LR = 0.0700\n",
      "\n",
      "Saving model with lowest val_loss = 0.7742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.17batch/s, accuracy=76, loss=0.713]   \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.05batch/s, val_acc=73.2, val_loss=0.794] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8 training loss = 0.7133, training accuracy = 75.98%, val_loss = 0.7936, val_accuracy = 73.25% & LR = 0.0800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.49batch/s, accuracy=77.4, loss=0.674] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.03batch/s, val_acc=71.1, val_loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9 training loss = 0.6737, training accuracy = 77.36%, val_loss = 0.9091, val_accuracy = 71.07% & LR = 0.0900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.25batch/s, accuracy=77.7, loss=0.661] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.83batch/s, val_acc=67.3, val_loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10 training loss = 0.6605, training accuracy = 77.72%, val_loss = 1.0867, val_accuracy = 67.31% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:13<00:00,  5.29batch/s, accuracy=78.6, loss=0.637] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.41batch/s, val_acc=78.1, val_loss=0.654] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 11 training loss = 0.6371, training accuracy = 78.61%, val_loss = 0.6537, val_accuracy = 78.10% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.6537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:10<00:00,  5.54batch/s, accuracy=80.1, loss=0.595] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.91batch/s, val_acc=73.7, val_loss=0.775] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 12 training loss = 0.5954, training accuracy = 80.06%, val_loss = 0.7752, val_accuracy = 73.70% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:07<00:00,  5.76batch/s, accuracy=80.6, loss=0.578] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.13batch/s, val_acc=77.8, val_loss=0.68]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 13 training loss = 0.5776, training accuracy = 80.63%, val_loss = 0.6800, val_accuracy = 77.81% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.24batch/s, accuracy=81, loss=0.565]   \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.14batch/s, val_acc=72.7, val_loss=0.856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 14 training loss = 0.5647, training accuracy = 80.95%, val_loss = 0.8562, val_accuracy = 72.66% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:10<00:00,  5.55batch/s, accuracy=81.5, loss=0.548] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.87batch/s, val_acc=78.9, val_loss=0.623] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 15 training loss = 0.5478, training accuracy = 81.52%, val_loss = 0.6226, val_accuracy = 78.91% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.6226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.17batch/s, accuracy=81.8, loss=0.538] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.90batch/s, val_acc=78.6, val_loss=0.62]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 16 training loss = 0.5379, training accuracy = 81.80%, val_loss = 0.6197, val_accuracy = 78.58% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.6197\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.45batch/s, accuracy=82, loss=0.533]   \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.91batch/s, val_acc=77, val_loss=0.729]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 17 training loss = 0.5332, training accuracy = 82.02%, val_loss = 0.7292, val_accuracy = 76.99% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.16batch/s, accuracy=82.5, loss=0.522] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.64batch/s, val_acc=78, val_loss=0.661]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 18 training loss = 0.5217, training accuracy = 82.48%, val_loss = 0.6605, val_accuracy = 78.04% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.45batch/s, accuracy=82.8, loss=0.509] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.45batch/s, val_acc=80.5, val_loss=0.607] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 19 training loss = 0.5089, training accuracy = 82.79%, val_loss = 0.6066, val_accuracy = 80.47% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.6066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.21batch/s, accuracy=83.1, loss=0.499] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.65batch/s, val_acc=80.4, val_loss=0.574] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20 training loss = 0.4990, training accuracy = 83.10%, val_loss = 0.5738, val_accuracy = 80.40% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.5738\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.20batch/s, accuracy=83.4, loss=0.495] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.97batch/s, val_acc=80.9, val_loss=0.562] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 training loss = 0.4948, training accuracy = 83.41%, val_loss = 0.5618, val_accuracy = 80.89% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.5618\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.42batch/s, accuracy=83.4, loss=0.49]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.15batch/s, val_acc=80, val_loss=0.614]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 22 training loss = 0.4899, training accuracy = 83.40%, val_loss = 0.6141, val_accuracy = 79.96% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:16<00:00,  5.13batch/s, accuracy=83.6, loss=0.494] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.16batch/s, val_acc=83, val_loss=0.513]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 23 training loss = 0.4939, training accuracy = 83.57%, val_loss = 0.5132, val_accuracy = 83.00% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.5132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:13<00:00,  5.35batch/s, accuracy=83.8, loss=0.483] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.57batch/s, val_acc=83.1, val_loss=0.509] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 24 training loss = 0.4832, training accuracy = 83.76%, val_loss = 0.5093, val_accuracy = 83.12% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.5093\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.24batch/s, accuracy=83.7, loss=0.486]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.90batch/s, val_acc=79.6, val_loss=0.622] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 25 training loss = 0.4859, training accuracy = 83.73%, val_loss = 0.6218, val_accuracy = 79.58% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:07<00:00,  5.75batch/s, accuracy=90.1, loss=0.291] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.76batch/s, val_acc=89.1, val_loss=0.32]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 26 training loss = 0.2907, training accuracy = 90.11%, val_loss = 0.3203, val_accuracy = 89.08% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.46batch/s, accuracy=91.9, loss=0.239]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.72batch/s, val_acc=89.9, val_loss=0.302] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 27 training loss = 0.2392, training accuracy = 91.89%, val_loss = 0.3018, val_accuracy = 89.86% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3018\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.47batch/s, accuracy=92.6, loss=0.217]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.62batch/s, val_acc=90.3, val_loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 28 training loss = 0.2167, training accuracy = 92.64%, val_loss = 0.2888, val_accuracy = 90.27% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.2888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.21batch/s, accuracy=93.1, loss=0.198]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.91batch/s, val_acc=90.5, val_loss=0.281] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 29 training loss = 0.1978, training accuracy = 93.15%, val_loss = 0.2807, val_accuracy = 90.55% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.2807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.46batch/s, accuracy=93.6, loss=0.184]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.95batch/s, val_acc=90.7, val_loss=0.275] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 30 training loss = 0.1844, training accuracy = 93.60%, val_loss = 0.2748, val_accuracy = 90.71% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.2748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.17batch/s, accuracy=94, loss=0.175]    \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.76batch/s, val_acc=90.6, val_loss=0.28]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 31 training loss = 0.1754, training accuracy = 93.95%, val_loss = 0.2800, val_accuracy = 90.65% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:16<00:00,  5.14batch/s, accuracy=94.5, loss=0.16]   \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.25batch/s, val_acc=90.8, val_loss=0.282] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 32 training loss = 0.1602, training accuracy = 94.52%, val_loss = 0.2818, val_accuracy = 90.82% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.44batch/s, accuracy=94.6, loss=0.154]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.37batch/s, val_acc=91.1, val_loss=0.281] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 33 training loss = 0.1545, training accuracy = 94.63%, val_loss = 0.2811, val_accuracy = 91.12% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.50batch/s, accuracy=94.9, loss=0.144]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.13batch/s, val_acc=91.1, val_loss=0.28]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 34 training loss = 0.1444, training accuracy = 94.95%, val_loss = 0.2804, val_accuracy = 91.06% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:08<00:00,  5.69batch/s, accuracy=95.2, loss=0.139]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.63batch/s, val_acc=90.8, val_loss=0.294] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 35 training loss = 0.1386, training accuracy = 95.21%, val_loss = 0.2938, val_accuracy = 90.75% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.22batch/s, accuracy=95.4, loss=0.134]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.45batch/s, val_acc=91.4, val_loss=0.275] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 36 training loss = 0.1340, training accuracy = 95.41%, val_loss = 0.2751, val_accuracy = 91.42% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.28batch/s, accuracy=95.5, loss=0.129]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.79batch/s, val_acc=90.1, val_loss=0.311] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 37 training loss = 0.1287, training accuracy = 95.50%, val_loss = 0.3113, val_accuracy = 90.08% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.41batch/s, accuracy=95.7, loss=0.124]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.94batch/s, val_acc=91.1, val_loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 38 training loss = 0.1240, training accuracy = 95.66%, val_loss = 0.2893, val_accuracy = 91.08% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.21batch/s, accuracy=95.9, loss=0.118]  \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.88batch/s, val_acc=91.3, val_loss=0.278] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 39 training loss = 0.1176, training accuracy = 95.89%, val_loss = 0.2781, val_accuracy = 91.31% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.21batch/s, accuracy=96, loss=0.117]    \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 13.72batch/s, val_acc=91, val_loss=0.296]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 40 training loss = 0.1172, training accuracy = 95.98%, val_loss = 0.2959, val_accuracy = 91.03% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:13<00:00,  5.32batch/s, accuracy=97.2, loss=0.0825] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.90batch/s, val_acc=92, val_loss=0.263]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 41 training loss = 0.0825, training accuracy = 97.22%, val_loss = 0.2632, val_accuracy = 92.05% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.2632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=97.8, loss=0.0694] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.04batch/s, val_acc=92.1, val_loss=0.266] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 42 training loss = 0.0694, training accuracy = 97.76%, val_loss = 0.2660, val_accuracy = 92.14% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.19batch/s, accuracy=98, loss=0.0622]   \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.08batch/s, val_acc=92.3, val_loss=0.268] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 43 training loss = 0.0622, training accuracy = 97.98%, val_loss = 0.2685, val_accuracy = 92.26% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.36batch/s, accuracy=98.1, loss=0.0577] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.30batch/s, val_acc=92.3, val_loss=0.273] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 44 training loss = 0.0577, training accuracy = 98.14%, val_loss = 0.2727, val_accuracy = 92.34% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:14<00:00,  5.25batch/s, accuracy=98.2, loss=0.0548] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.75batch/s, val_acc=92.5, val_loss=0.275] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 45 training loss = 0.0548, training accuracy = 98.16%, val_loss = 0.2755, val_accuracy = 92.47% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.41batch/s, accuracy=98.4, loss=0.0512] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.86batch/s, val_acc=92.2, val_loss=0.28]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 46 training loss = 0.0512, training accuracy = 98.36%, val_loss = 0.2804, val_accuracy = 92.16% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:09<00:00,  5.63batch/s, accuracy=98.4, loss=0.0492] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.84batch/s, val_acc=92.4, val_loss=0.281] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 47 training loss = 0.0492, training accuracy = 98.44%, val_loss = 0.2815, val_accuracy = 92.38% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.19batch/s, accuracy=98.4, loss=0.0489] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.00batch/s, val_acc=92.3, val_loss=0.284] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 48 training loss = 0.0489, training accuracy = 98.40%, val_loss = 0.2844, val_accuracy = 92.29% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.44batch/s, accuracy=98.5, loss=0.0451] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.95batch/s, val_acc=92.3, val_loss=0.288] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 49 training loss = 0.0451, training accuracy = 98.53%, val_loss = 0.2879, val_accuracy = 92.31% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=98.5, loss=0.0445] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.33batch/s, val_acc=92.2, val_loss=0.29]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 50 training loss = 0.0445, training accuracy = 98.50%, val_loss = 0.2901, val_accuracy = 92.21% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.42batch/s, accuracy=98.6, loss=0.0422] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.86batch/s, val_acc=92.4, val_loss=0.288] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 51 training loss = 0.0422, training accuracy = 98.56%, val_loss = 0.2883, val_accuracy = 92.38% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.17batch/s, accuracy=98.7, loss=0.0394] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.17batch/s, val_acc=92.3, val_loss=0.288] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 52 training loss = 0.0394, training accuracy = 98.75%, val_loss = 0.2882, val_accuracy = 92.32% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.16batch/s, accuracy=98.7, loss=0.0378] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.79batch/s, val_acc=92.4, val_loss=0.288] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 53 training loss = 0.0378, training accuracy = 98.73%, val_loss = 0.2881, val_accuracy = 92.41% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.19batch/s, accuracy=98.7, loss=0.04]   \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.85batch/s, val_acc=92.4, val_loss=0.288] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 54 training loss = 0.0400, training accuracy = 98.71%, val_loss = 0.2878, val_accuracy = 92.37% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.44batch/s, accuracy=98.8, loss=0.0374] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.70batch/s, val_acc=92.4, val_loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 55 training loss = 0.0374, training accuracy = 98.83%, val_loss = 0.2894, val_accuracy = 92.44% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=98.8, loss=0.0378] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.92batch/s, val_acc=92.5, val_loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 56 training loss = 0.0378, training accuracy = 98.80%, val_loss = 0.2887, val_accuracy = 92.46% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.16batch/s, accuracy=98.8, loss=0.0377] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.48batch/s, val_acc=92.4, val_loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 57 training loss = 0.0377, training accuracy = 98.75%, val_loss = 0.2888, val_accuracy = 92.41% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.45batch/s, accuracy=98.8, loss=0.0371] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.34batch/s, val_acc=92.4, val_loss=0.292] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 58 training loss = 0.0371, training accuracy = 98.75%, val_loss = 0.2916, val_accuracy = 92.37% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:16<00:00,  5.12batch/s, accuracy=98.7, loss=0.0375] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.14batch/s, val_acc=92.4, val_loss=0.289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 59 training loss = 0.0375, training accuracy = 98.73%, val_loss = 0.2894, val_accuracy = 92.40% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.40batch/s, accuracy=98.8, loss=0.0367] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.70batch/s, val_acc=92.4, val_loss=0.291] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 60 training loss = 0.0367, training accuracy = 98.82%, val_loss = 0.2915, val_accuracy = 92.37% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.18batch/s, accuracy=98.9, loss=0.0357] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.04batch/s, val_acc=92.4, val_loss=0.291] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 61 training loss = 0.0357, training accuracy = 98.87%, val_loss = 0.2907, val_accuracy = 92.44% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:07<00:00,  5.82batch/s, accuracy=98.9, loss=0.0363] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.42batch/s, val_acc=92.3, val_loss=0.292] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 62 training loss = 0.0363, training accuracy = 98.88%, val_loss = 0.2919, val_accuracy = 92.28% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:15<00:00,  5.19batch/s, accuracy=98.8, loss=0.0373] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 12.46batch/s, val_acc=92.3, val_loss=0.293] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 63 training loss = 0.0373, training accuracy = 98.81%, val_loss = 0.2932, val_accuracy = 92.34% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:12<00:00,  5.38batch/s, accuracy=98.8, loss=0.0357] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.78batch/s, val_acc=92.2, val_loss=0.291] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 64 training loss = 0.0357, training accuracy = 98.82%, val_loss = 0.2910, val_accuracy = 92.24% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [01:11<00:00,  5.44batch/s, accuracy=98.9, loss=0.0356] \n",
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.78batch/s, val_acc=92.4, val_loss=0.293] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 65 training loss = 0.0356, training accuracy = 98.87%, val_loss = 0.2929, val_accuracy = 92.41% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss, train_acc = train_model_progress(model, train_loader)\n",
    "    val_loss, val_acc = test_model_progress(model, test_loader)\n",
    "    \n",
    "    print(f\"\\nepoch: {epoch + 1} training loss = {train_loss:.4f}, \"\n",
    "          f\"training accuracy = {train_acc:.2f}%, val_loss = {val_loss:.4f}\"\n",
    "          f\", val_accuracy = {val_acc:.2f}% & \"\n",
    "          f\"LR = {optimizer.param_groups[0]['lr']:.4f}\\n\")\n",
    "    \n",
    "    training_history_lr_scheduler[epoch + 1] = {\n",
    "        'loss': train_loss, 'acc': train_acc,\n",
    "        'val_loss': val_loss, 'val_acc': val_acc,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Save best weights achieved until now-\n",
    "    if (val_loss < best_val_loss):    \n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"ResNet34_lr_scheduler_best_model.pth\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model from last training epoch-\n",
    "torch.save(model.state_dict(), \"ResNet34_lr_scheduler_last_epoch_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a 'best' ResNet-34 model-\n",
    "best_model = create_resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "best_model.load_state_dict(torch.load('ResNet34_lr_scheduler_last_epoch_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (8): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU (if available)-\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: : 100%|██████████| 79/79 [00:06<00:00, 11.85batch/s, val_acc=92.4, val_loss=0.293] \n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = test_model_progress(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-34 'best' model metrics: val_loss = 0.2929 & val_acc = 92.41%\n"
     ]
    }
   ],
   "source": [
    "print(f\"ResNet-34 'best' model metrics: val_loss = {val_loss:.4f} & val_acc = {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "For this particular experiment, it seems that using ```val_loss``` as the metric to save the _best_ model is not the optimum choice.\n",
    "\n",
    "_Highest validation accuracy_ achieved = 92.41%.\n",
    "\n",
    "_Dropout_ needs to be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "training_history_lr_scheduler.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history_lr_scheduler[12].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metrics as Python3 history for later analysis-\n",
    "with open(\"ResNet34_training_history_lr_scheduler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_history_lr_scheduler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['acc'] for k in training_history_lr_scheduler.keys()], label = 'training acc')\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['val_acc'] for k in training_history_lr_scheduler.keys()], label = 'val acc')\n",
    "plt.title(\"ResNet-34: Training Accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy (%)\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['loss'] for k in training_history_lr_scheduler.keys()], label = 'training loss')\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['val_loss'] for k in training_history_lr_scheduler.keys()], label = 'val loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.title(\"ResNet-34: Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['lr'] for k in training_history_lr_scheduler.keys()])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"lr\")\n",
    "plt.title(\"ResNet-34: Learning-Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG18_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
