{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZOD2mGIeyEJ"
   },
   "source": [
    "# ResNet-50 CNN: PyTorch & CIFAR-10\n",
    "\n",
    "End-to-end programming tutorial including:\n",
    "\n",
    "1. Dropout - combat _overfitting_ prevelant in ResNet-50 for CIFAR-10 dataset\n",
    "1. Progress bar - training model\n",
    "1. Learning rate scheduler - needed for deep learning architectures\n",
    "\n",
    "\n",
    "#### References \n",
    "- [Dive into Deep Learning - ResNet reference](https://d2l.ai/chapter_convolutional-modern/resnet.html)\n",
    "\n",
    "- [YouTube reference](https://www.youtube.com/watch?v=DkNIBBBvcPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to ResNet research paper: __Deep Residual Learning for Image Recognition__ by Kaiming He et al.\n",
    "\n",
    "In page 4, Figure 3. ResNet-34 architecture is shown. It can learn more complex and new features in these 2 layers. But it's also going to use the skip connection/identity mapping from it previously leanred/coputed. So the CNN can kind of choose what it wants to learn. Either a combination of what it has learned before (skip connection) and the new things it has learned using the 2 conv layers within a ResNet block. The argument here is that the CNN is going to learn new things but it's at least never going to forget what it learned before. So, in theory, it should never become worse as we increase the depth of the CNN. Hence, by increasing the depth of the CNN, it never worsens the performance.\n",
    "\n",
    "In page 5, Table 1, different architecture specific details are specified. In this tutorial, ResNet-50/101 and 152 will be implemented. The first conv layer: kernel size = (7, 7), stride = 2, number of kernels = 64, padding = 3; Max pool: kernel size = (3, 3), stride =2 \n",
    "\n",
    "ResNet-50 has Four ResNet layers. If we look at the first ResNet layer, it has a block here which is-\n",
    "- 1x1 filter with 64 channels\n",
    "- 3x3, 64\n",
    "- 1x1, 256\n",
    "\n",
    "it repeats/performs this block 3 times.\n",
    "\n",
    "Same convolutions - none of them change the size of input. Stride is used to reduce the spatial output in each of the conv layers.\n",
    "\n",
    "One more thing to note is that if we look at the input channels for the first ResNet layer/block, it is 64 and the number of channels at the end is 256. For ResNet layer/block 2, the number of input channels is 128 and the number of channels at the end is 512. For ResNet layer/block 3, the number of input channels is 256 and the number of channels at the end is 1024. The ResNet architecture follows the pattern that the output channel is going to be 4x the input channel for that particular ResNet layer/block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7hpnDY7Mfb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# Specify GPU to be used-\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cM6Ih3nVq0Gh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DvYMsqNezdm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha-v5IiWezqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_H9KbTonq0Q9",
    "outputId": "41b72a44-64e1-44c2-a917-615e9adafb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently available device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration-\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"currently available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "# Get number of GPUs-\n",
    "print(f\"Number of available GPUs = {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU = 0\n"
     ]
    }
   ],
   "source": [
    "# Check the current GPU-\n",
    "print(f\"Current GPU = {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of current GPU = Quadro M6000\n"
     ]
    }
   ],
   "source": [
    "# Get the name of the current GPU\n",
    "print(f\"Name of current GPU = {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch using a GPU? True\n"
     ]
    }
   ],
   "source": [
    "# Is PyTorch using a GPU?\n",
    "print(f\"PyTorch using a GPU? {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2CJ2XyNq9Nd",
    "outputId": "3e5961db-ccb3-4be4-9207-21d280f44beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6rTKbcZrBN0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uV1m3vD0rBee"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters-\n",
    "num_epochs = 65\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs for training = 65 with default LR = 0.01\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of epochs for training = {num_epochs} with default LR = {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QGc3oYHrDzL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9R6Sc5v6rD8M"
   },
   "outputs": [],
   "source": [
    "# Define transformations for training and test sets-\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomCrop(32, padding = 4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "4ddOxdkirHPN",
    "outputId": "764e40cc-2f3c-482f-bbb1-542c39d0d1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset-\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = True,\n",
    "        download = True, transform = transform_train\n",
    "        )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = False,\n",
    "        download = True, transform = transform_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW8h3ztJrU5_",
    "outputId": "643be603-0775-412b-9a3d-7dfbe5df1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) = 50000 & len(test_dataset) = 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_dataset) = {len(train_dataset)} & len(test_dataset) = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cydrwaW7rbnV"
   },
   "outputs": [],
   "source": [
    "# Create training and testing loaders-\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size = batch_size,\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size = batch_size,\n",
    "        shuffle = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62AgWl9jrfzW",
    "outputId": "0972fead-2556-4cea-9ff4-8f50eabf6cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 391 & len(test_loader) = 79\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_loader) = {len(train_loader)} & len(test_loader) = {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjGADCMfrhAl",
    "outputId": "e3bb3177-720d-48ce-ef5a-b0e61c5ac9bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390.625, 78.125)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "len(train_dataset) / batch_size, len(test_dataset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEBunYxErhh8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 32, 32]), torch.Size([128]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "images.size(), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlFoyg5Hruqn"
   },
   "source": [
    "### Define _ResNet-50_ architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic _ResNet_ block\n",
    "\n",
    "Note that a _conv_ layer followed by a _batch norm_ layer should __not__ have _bias_ term for each filter/kernel as it's redundant. For the mathematical proof, refer [here](https://github.com/arjun-majumdar/CNN_Classifications/blob/master/BatchNorm_bias_cancellation.pdf). \n",
    "\n",
    "```identity_downsample``` is a conv layer which we might need to use depending on if we have changed the input size or if we have changed the number of channels. Hence, we need to adapt the identity so that we can use it later on when we have used a few conv layers. We use ```identity_downsample``` layer if we need to change the shape in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_block(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, identity_downsample = None, stride = 1,\n",
    "                dropout = 0.2):\n",
    "        super(ResNet_block, self).__init__()\n",
    "\n",
    "        # number of channels after a block is 4x of what it entered/was passed-\n",
    "        self.expansion = 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = input_channels, out_channels = output_channels,\n",
    "            kernel_size = 1, stride = 1,\n",
    "            padding = 0, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = output_channels)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = output_channels, out_channels = output_channels,\n",
    "            kernel_size = 3, stride = stride,\n",
    "            padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features = output_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels = output_channels, out_channels = output_channels * self.expansion,\n",
    "            kernel_size = 1, stride = 1,\n",
    "            padding = 0, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features = output_channels * self.expansion)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # A conv layer-\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            # print(m)\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "\n",
    "                '''\n",
    "                # Do not initialize bias (due to batchnorm)-\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                '''\n",
    "            \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                # Standard initialization for batch normalization-\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-50/101/152 architecture is _slightly_ changed for CIFAR-10 dataset instead of ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "    layers - a Python3 list specifying the number of times to use 'ResNet_block'\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, ResNet_block, layers, image_channels = 3, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.input_channels = 64\n",
    "        \n",
    "        '''\n",
    "        # For ImageNet-\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = image_channels, out_channels = 64,\n",
    "            kernel_size = 7, stride = 2,\n",
    "            padding = 3, bias = False)\n",
    "        '''\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = image_channels, out_channels = 64,\n",
    "            kernel_size = 3, stride = 1,\n",
    "            padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        '''\n",
    "        # For ImageNet-\n",
    "        self.maxpool = nn.MaxPool2d(\n",
    "            kernel_size = 3, stride = 2,\n",
    "            padding = 1\n",
    "            )\n",
    "        '''\n",
    "        \n",
    "        # ResNet blocks-\n",
    "        self.layer1 = self._make_layer(ResNet_block, layers[0], output_channels = 64, stride = 1)\n",
    "        self.layer2 = self._make_layer(ResNet_block, layers[1], output_channels = 128, stride = 2)\n",
    "        self.layer3 = self._make_layer(ResNet_block, layers[2], output_channels = 256, stride = 2)\n",
    "        self.layer4 = self._make_layer(ResNet_block, layers[3], output_channels = 512, stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)  # For ImageNet\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        # Reshape before passing to dense layer-\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_layer(self, ResNet_block, num_residual_blocks, output_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        '''\n",
    "        We want to know when are we going to actually use/do an identity_downsample? When are we going to\n",
    "        have the conv layer change the identity?\n",
    "        1. Either we change the input size\n",
    "        2.\n",
    "        '''\n",
    "        if stride != 1 or self.input_channels != output_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels = self.input_channels, out_channels = 4 * output_channels,\n",
    "                    kernel_size = 1, stride = stride,\n",
    "                    bias = False),\n",
    "                nn.BatchNorm2d(num_features = output_channels * 4)\n",
    "                )\n",
    "        \n",
    "        # This is the layer that changes the number of channels-\n",
    "        layers.append(ResNet_block(self.input_channels, output_channels, identity_downsample, stride))\n",
    "        # After this first block, the number of channels is going to be changed\n",
    "        \n",
    "        self.input_channels = output_channels * 4       # 64 x 4 = 256\n",
    "        # At the end of the first block, the output = 256\n",
    "        \n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(ResNet_block(self.input_channels, output_channels, dropout = 0.2))\n",
    "        \n",
    "        \n",
    "        return (nn.Sequential(*layers))\n",
    "        # *layers unpacks the list so that PyTorch knows that each comes after the other\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(img_channels, op_neurons = 1000):\n",
    "    # Function to define ResNet-50 architecture\n",
    "    return ResNet(ResNet_block, [3, 4, 6, 3], img_channels, op_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet101(img_channels, op_neurons = 1000):\n",
    "    # Function to define ResNet-101 architecture\n",
    "    return ResNet(ResNet_block, [3, 4, 23, 3], img_channels, op_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet152(img_channels, op_neurons = 1000):\n",
    "    # Function to define ResNet-152 architecture\n",
    "    return ResNet(ResNet_block, [3, 8, 36, 3], img_channels, op_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    # Three images of (32, 32, 3). Number of in_channels = 3-\n",
    "    x = torch.randn(3, 3, 32, 32)\n",
    "    \n",
    "    y = model(x).to(device)\n",
    "    print(f\"Output.shape: {y.shape}\")\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a ResNet-50 model-\n",
    "model = ResNet50(img_channels = 3, op_neurons = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "model(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output.shape: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check-\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (layer1): Sequential(\n",
      "    (0): ResNet_block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResNet_block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResNet_block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResNet_block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResNet_block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResNet_block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResNet_block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResNet_block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): ResNet_block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): ResNet_block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResNet_block(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResNet_block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9aSBydxsD27",
    "outputId": "79ba1ecd-97d6-4c18-fea7-2acb2cbe66f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): ResNet_block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNet_block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResNet_block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResNet_block(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNet_block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResNet_block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResNet_block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResNet_block(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNet_block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResNet_block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResNet_block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): ResNet_block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): ResNet_block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResNet_block(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNet_block(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResNet_block(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU-\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SnL7fjksJLh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9A-AfIXwcE6u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8zux0jjsHq0",
    "outputId": "e986b7ad-171b-474c-cb60-2097fdecc112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.shape = torch.Size([64, 3, 3, 3]) has 1728 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 1, 1]) has 4096 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([256, 64, 1, 1]) has 16384 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 64, 1, 1]) has 16384 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([64, 256, 1, 1]) has 16384 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([256, 64, 1, 1]) has 16384 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([64, 256, 1, 1]) has 16384 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([256, 64, 1, 1]) has 16384 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([128, 256, 1, 1]) has 32768 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([512, 128, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 256, 1, 1]) has 131072 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([128, 512, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([512, 128, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([128, 512, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([512, 128, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([128, 512, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([512, 128, 1, 1]) has 65536 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([256, 512, 1, 1]) has 131072 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([1024, 256, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024, 512, 1, 1]) has 524288 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([256, 1024, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([1024, 256, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([256, 1024, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([1024, 256, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([256, 1024, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([1024, 256, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([256, 1024, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([1024, 256, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([256, 1024, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([1024, 256, 1, 1]) has 262144 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([1024]) has 1024 parameters\n",
      "layer.shape = torch.Size([512, 1024, 1, 1]) has 524288 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([2048, 512, 1, 1]) has 1048576 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([2048, 1024, 1, 1]) has 2097152 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([512, 2048, 1, 1]) has 1048576 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([2048, 512, 1, 1]) has 1048576 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([512, 2048, 1, 1]) has 1048576 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([2048, 512, 1, 1]) has 1048576 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([2048]) has 2048 parameters\n",
      "layer.shape = torch.Size([10, 2048]) has 20480 parameters\n",
      "layer.shape = torch.Size([10]) has 10 parameters\n"
     ]
    }
   ],
   "source": [
    "# Count number of layer-wise parameters and total parameters-\n",
    "tot_params = 0\n",
    "for param in model.parameters():\n",
    "    print(f\"layer.shape = {param.shape} has {param.nelement()} parameters\")\n",
    "    tot_params += param.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp9X8qnOsY1t",
    "outputId": "161ec2b1-37d8-4676-dcf8-aa96cf9bfc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in ResNet-50 CNN for CIFAR-10 = 23520842\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of parameters in ResNet-50 CNN for CIFAR-10 = {tot_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WdKiWsLsZYN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Print layer names-\n",
    "for layer in model.state_dict().keys():\n",
    "    print(f\"{layer} has dimension = {model.state_dict()[layer].shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1jFfuJiscmN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "O_WUBfzFscrc"
   },
   "outputs": [],
   "source": [
    "# Save random initial weights-\n",
    "torch.save(model.state_dict(), 'ResNet50_random_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gdgada5J5mIR",
    "outputId": "4ad9e79d-a499-4831-c030-219544802967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "# model.load_state_dict(torch.load('ResNet50_random_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGUR1m04stvU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with _learning rate scheduler_\n",
    "\n",
    "- Training dataset = 50000, batch size = 128, number of training steps/iterations = 50000 / 128 = 391\n",
    "\n",
    "- Initial learning rate warmup: 391 x 10 = 3910 steps or, 10 epochs at LR = 0.1\n",
    "\n",
    "- Until 25th epoch or, 9775 steps use LR = 0.1\n",
    "\n",
    "- From 26th epoch until 40th epoch or, 15640 steps use LR = 0.01\n",
    "\n",
    "- From 41st epoch until 50th epoch or, 19550 steps use LR = 0.001\n",
    "\n",
    "- From 51st epoch until 60th epoch use LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [9775, 15640, 19550]\n",
    "values = [0.1, 0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "OozQ7SF4st4U"
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer-\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0, momentum = 0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_function(step, boundaries = [9775, 15640, 19550], values = [0.1, 0.01, 0.001, 0.0001]):\n",
    "    '''\n",
    "    1 epoch has 391 steps/iterations using batch size used above.\n",
    "    \n",
    "    Until 25th epochs, or 25 x 391 = 9775 steps, use lr = 0.1\n",
    "    From 26th epoch until 40th epoch, or 15640 steps use LR = 0.01\n",
    "    From 41st epoch until 50th epoch or, 19550 steps use LR = 0.001\n",
    "    From 51st epoch until 60th epoch use LR = 0.0001\n",
    "    '''\n",
    "    \n",
    "    for idx, bound in enumerate(boundaries):\n",
    "        if step < bound:\n",
    "            return values[idx]\n",
    "\n",
    "    return values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class schedule():\n",
    "\n",
    "    def __init__(self, initial_learning_rate = 0.1, warmup_steps = 1000, decay_func = None):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_func = decay_func\n",
    "        self.warmup_step_size = initial_learning_rate/warmup_steps\n",
    "        self.current_lr = 0\n",
    "\n",
    "    def get_lr(self, step):\n",
    "        if step == 0:\n",
    "            return self.current_lr\n",
    "        elif step <= self.warmup_steps:\n",
    "            self.current_lr+=self.warmup_step_size\n",
    "            return self.current_lr\n",
    "        elif step > self.warmup_steps:\n",
    "            if self.decay_func:\n",
    "                return self.decay_func(step)\n",
    "        else:\n",
    "            return self.current_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 391 x 10 = 3910 steps (or, 10 epochs) is learning rate warmup\n",
    "custom_lr_scheduler = schedule(\n",
    "    initial_learning_rate = 0.1, warmup_steps = 3910,\n",
    "    decay_func = decay_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0DyTwwRhcOeY"
   },
   "outputs": [],
   "source": [
    "def train_model_progress(model, train_loader):\n",
    "    '''\n",
    "    Function to perform one epoch of training by using 'train_loader'.\n",
    "    Returns loss and number of correct predictions for this epoch.\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Training: \")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions-\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss-\n",
    "            J = loss(outputs, labels)\n",
    "            \n",
    "            # Empty accumulated gradients-\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform backprop-\n",
    "            J.backward()\n",
    "            \n",
    "            # Update parameters-\n",
    "            optimizer.step()\n",
    "            \n",
    "            global step\n",
    "            optimizer.param_groups[0]['lr'] = custom_lr_scheduler.get_lr(step)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            # Compute model's performance statistics-\n",
    "            running_loss += J.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "            tepoch.set_postfix(\n",
    "                loss = running_loss / len(train_dataset),\n",
    "                accuracy = (running_corrects.double().cpu().numpy() / len(train_dataset)) * 100\n",
    "            )\n",
    "            \n",
    "    \n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "\n",
    "    # return running_loss, running_corrects\n",
    "    return train_loss, train_acc.cpu().numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCq8FAdOckD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "YymBc1UtcnEA"
   },
   "outputs": [],
   "source": [
    "def test_model_progress(model, test_loader):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit = 'batch') as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                tepoch.set_description(f\"Validation: \")\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Set model to evaluation mode-\n",
    "                model.eval()\n",
    "            \n",
    "                # Predict using trained model-\n",
    "                outputs = model(images)\n",
    "                _, y_pred = torch.max(outputs, 1)\n",
    "                \n",
    "                # Compute validation loss-\n",
    "                J_val = loss(outputs, labels)\n",
    "                \n",
    "                running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "                # Total number of labels-\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total number of correct predictions-\n",
    "                correct += (y_pred == labels).sum()\n",
    "                \n",
    "                tepoch.set_postfix(\n",
    "                    val_loss = running_loss_val / len(test_dataset),\n",
    "                    val_acc = 100 * (correct.cpu().numpy() / total)\n",
    "                )\n",
    "            \n",
    "        \n",
    "    # return (running_loss_val, correct, total)\n",
    "    val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = (correct / total) * 100\n",
    "\n",
    "    return val_loss, val_acc.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_lr_scheduler = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "NOytz_v9tPxV"
   },
   "outputs": [],
   "source": [
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=17.6, loss=2.27]  \n",
      "Validation: : 100%|██████████| 79/79 [00:14<00:00,  5.58batch/s, val_acc=11, val_loss=5.21]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 training loss = 2.2709, training accuracy = 17.58%, val_loss = 5.2072, val_accuracy = 10.99% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 5.2072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.62batch/s, accuracy=25.3, loss=1.96]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.94batch/s, val_acc=14.6, val_loss=3.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 training loss = 1.9647, training accuracy = 25.33%, val_loss = 3.2678, val_accuracy = 14.59% & LR = 0.0200\n",
      "\n",
      "Saving model with lowest val_loss = 3.2678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:56<00:00,  1.66batch/s, accuracy=36, loss=1.7]     \n",
      "Validation: : 100%|██████████| 79/79 [00:13<00:00,  5.99batch/s, val_acc=33.1, val_loss=2]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 training loss = 1.6968, training accuracy = 36.03%, val_loss = 2.0009, val_accuracy = 33.13% & LR = 0.0300\n",
      "\n",
      "Saving model with lowest val_loss = 2.0009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:05<00:00,  1.59batch/s, accuracy=45.7, loss=1.46]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.01batch/s, val_acc=47, val_loss=1.49]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 training loss = 1.4612, training accuracy = 45.71%, val_loss = 1.4885, val_accuracy = 46.99% & LR = 0.0400\n",
      "\n",
      "Saving model with lowest val_loss = 1.4885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.60batch/s, accuracy=52.6, loss=1.3]   \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.02batch/s, val_acc=41.9, val_loss=1.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5 training loss = 1.3035, training accuracy = 52.57%, val_loss = 1.7951, val_accuracy = 41.85% & LR = 0.0500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:48<00:00,  1.71batch/s, accuracy=58.4, loss=1.16]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.19batch/s, val_acc=61.3, val_loss=1.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6 training loss = 1.1556, training accuracy = 58.37%, val_loss = 1.1412, val_accuracy = 61.28% & LR = 0.0600\n",
      "\n",
      "Saving model with lowest val_loss = 1.1412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=61.1, loss=1.08]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.10batch/s, val_acc=58.4, val_loss=1.24] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7 training loss = 1.0770, training accuracy = 61.08%, val_loss = 1.2434, val_accuracy = 58.40% & LR = 0.0700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:55<00:00,  1.66batch/s, accuracy=63.9, loss=1.01]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.99batch/s, val_acc=65.2, val_loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8 training loss = 1.0135, training accuracy = 63.86%, val_loss = 1.0091, val_accuracy = 65.16% & LR = 0.0800\n",
      "\n",
      "Saving model with lowest val_loss = 1.0091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=65.8, loss=0.965] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.24batch/s, val_acc=65.5, val_loss=0.995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9 training loss = 0.9653, training accuracy = 65.81%, val_loss = 0.9949, val_accuracy = 65.49% & LR = 0.0900\n",
      "\n",
      "Saving model with lowest val_loss = 0.9949\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:56<00:00,  1.65batch/s, accuracy=66.9, loss=0.931] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.14batch/s, val_acc=62.5, val_loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10 training loss = 0.9309, training accuracy = 66.95%, val_loss = 1.0925, val_accuracy = 62.47% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.60batch/s, accuracy=68.6, loss=0.893] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.03batch/s, val_acc=67.7, val_loss=0.934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 11 training loss = 0.8933, training accuracy = 68.60%, val_loss = 0.9335, val_accuracy = 67.68% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.9335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.61batch/s, accuracy=70.2, loss=0.851] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.01batch/s, val_acc=69.3, val_loss=0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 12 training loss = 0.8506, training accuracy = 70.19%, val_loss = 0.9280, val_accuracy = 69.31% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.9280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:01<00:00,  1.62batch/s, accuracy=71.3, loss=0.825] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.10batch/s, val_acc=68.2, val_loss=0.988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 13 training loss = 0.8252, training accuracy = 71.30%, val_loss = 0.9880, val_accuracy = 68.15% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.61batch/s, accuracy=72.4, loss=0.789] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.04batch/s, val_acc=68.1, val_loss=0.929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 14 training loss = 0.7893, training accuracy = 72.40%, val_loss = 0.9287, val_accuracy = 68.10% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=73.1, loss=0.767] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.09batch/s, val_acc=70.7, val_loss=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 15 training loss = 0.7672, training accuracy = 73.08%, val_loss = 0.8673, val_accuracy = 70.65% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.8673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:53<00:00,  1.67batch/s, accuracy=74.1, loss=0.743] \n",
      "Validation: : 100%|██████████| 79/79 [00:11<00:00,  6.90batch/s, val_acc=75.1, val_loss=0.727] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 16 training loss = 0.7430, training accuracy = 74.07%, val_loss = 0.7271, val_accuracy = 75.11% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.7271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=74.9, loss=0.728] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.22batch/s, val_acc=63.8, val_loss=1.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 17 training loss = 0.7285, training accuracy = 74.88%, val_loss = 1.1993, val_accuracy = 63.80% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:55<00:00,  1.66batch/s, accuracy=75.2, loss=0.713] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.05batch/s, val_acc=72.1, val_loss=0.797] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 18 training loss = 0.7132, training accuracy = 75.19%, val_loss = 0.7974, val_accuracy = 72.09% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=75.8, loss=0.698] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.96batch/s, val_acc=74, val_loss=0.76]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 19 training loss = 0.6977, training accuracy = 75.78%, val_loss = 0.7602, val_accuracy = 74.02% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:56<00:00,  1.65batch/s, accuracy=76.3, loss=0.685] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.97batch/s, val_acc=76.7, val_loss=0.669] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20 training loss = 0.6850, training accuracy = 76.33%, val_loss = 0.6694, val_accuracy = 76.71% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.6694\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:54<00:00,  1.67batch/s, accuracy=76.7, loss=0.672] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.10batch/s, val_acc=75.5, val_loss=0.726] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 training loss = 0.6720, training accuracy = 76.72%, val_loss = 0.7263, val_accuracy = 75.49% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.62batch/s, accuracy=77.2, loss=0.66]  \n",
      "Validation: : 100%|██████████| 79/79 [00:12<00:00,  6.54batch/s, val_acc=72.3, val_loss=0.818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 22 training loss = 0.6601, training accuracy = 77.18%, val_loss = 0.8185, val_accuracy = 72.30% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=77.6, loss=0.65]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.11batch/s, val_acc=76.3, val_loss=0.699] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 23 training loss = 0.6498, training accuracy = 77.64%, val_loss = 0.6989, val_accuracy = 76.26% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:56<00:00,  1.65batch/s, accuracy=77.8, loss=0.643] \n",
      "Validation: : 100%|██████████| 79/79 [00:14<00:00,  5.49batch/s, val_acc=71.9, val_loss=0.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 24 training loss = 0.6427, training accuracy = 77.81%, val_loss = 0.8439, val_accuracy = 71.88% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:05<00:00,  1.59batch/s, accuracy=78, loss=0.639]   \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.02batch/s, val_acc=77.6, val_loss=0.673] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 25 training loss = 0.6394, training accuracy = 77.97%, val_loss = 0.6728, val_accuracy = 77.59% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:55<00:00,  1.66batch/s, accuracy=84.4, loss=0.456] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.94batch/s, val_acc=87, val_loss=0.378]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 26 training loss = 0.4561, training accuracy = 84.43%, val_loss = 0.3778, val_accuracy = 86.98% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:56<00:00,  1.66batch/s, accuracy=86.1, loss=0.401]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.10batch/s, val_acc=87, val_loss=0.377]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 27 training loss = 0.4015, training accuracy = 86.09%, val_loss = 0.3767, val_accuracy = 87.00% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:07<00:00,  1.58batch/s, accuracy=86.8, loss=0.386]  \n",
      "Validation: : 100%|██████████| 79/79 [00:11<00:00,  6.60batch/s, val_acc=88, val_loss=0.354]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 28 training loss = 0.3863, training accuracy = 86.77%, val_loss = 0.3541, val_accuracy = 87.96% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3541\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:54<00:00,  1.67batch/s, accuracy=87.2, loss=0.37]  \n",
      "Validation: : 100%|██████████| 79/79 [00:11<00:00,  6.90batch/s, val_acc=88.5, val_loss=0.337] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 29 training loss = 0.3701, training accuracy = 87.17%, val_loss = 0.3368, val_accuracy = 88.47% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:11<00:00,  1.55batch/s, accuracy=87.5, loss=0.358]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.00batch/s, val_acc=88.6, val_loss=0.34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 30 training loss = 0.3576, training accuracy = 87.52%, val_loss = 0.3397, val_accuracy = 88.60% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=88, loss=0.346]    \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.24batch/s, val_acc=88.5, val_loss=0.34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 31 training loss = 0.3463, training accuracy = 88.05%, val_loss = 0.3404, val_accuracy = 88.47% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:53<00:00,  1.67batch/s, accuracy=88.1, loss=0.342] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.05batch/s, val_acc=88.7, val_loss=0.332] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 32 training loss = 0.3423, training accuracy = 88.14%, val_loss = 0.3322, val_accuracy = 88.67% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3322\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:12<00:00,  1.55batch/s, accuracy=88.4, loss=0.334]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.10batch/s, val_acc=88.6, val_loss=0.333] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 33 training loss = 0.3344, training accuracy = 88.45%, val_loss = 0.3326, val_accuracy = 88.60% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:55<00:00,  1.66batch/s, accuracy=88.7, loss=0.325]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.03batch/s, val_acc=88, val_loss=0.344]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 34 training loss = 0.3250, training accuracy = 88.69%, val_loss = 0.3442, val_accuracy = 88.05% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:53<00:00,  1.67batch/s, accuracy=88.9, loss=0.321]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.20batch/s, val_acc=89.3, val_loss=0.313] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 35 training loss = 0.3205, training accuracy = 88.92%, val_loss = 0.3132, val_accuracy = 89.33% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=89.1, loss=0.313] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.23batch/s, val_acc=89.2, val_loss=0.323] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 36 training loss = 0.3129, training accuracy = 89.08%, val_loss = 0.3228, val_accuracy = 89.20% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=89.3, loss=0.311]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.98batch/s, val_acc=89.3, val_loss=0.313] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 37 training loss = 0.3114, training accuracy = 89.26%, val_loss = 0.3133, val_accuracy = 89.31% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=89.4, loss=0.305] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.14batch/s, val_acc=89.6, val_loss=0.309] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 38 training loss = 0.3047, training accuracy = 89.35%, val_loss = 0.3089, val_accuracy = 89.63% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:48<00:00,  1.71batch/s, accuracy=89.5, loss=0.301]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.11batch/s, val_acc=89.6, val_loss=0.31]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 39 training loss = 0.3011, training accuracy = 89.47%, val_loss = 0.3095, val_accuracy = 89.63% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.61batch/s, accuracy=89.8, loss=0.294]  \n",
      "Validation: : 100%|██████████| 79/79 [00:11<00:00,  6.63batch/s, val_acc=89.6, val_loss=0.318] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 40 training loss = 0.2938, training accuracy = 89.81%, val_loss = 0.3177, val_accuracy = 89.58% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:01<00:00,  1.62batch/s, accuracy=91, loss=0.256]    \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.13batch/s, val_acc=91, val_loss=0.269]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 41 training loss = 0.2558, training accuracy = 91.04%, val_loss = 0.2693, val_accuracy = 90.98% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.2693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:12<00:00,  1.55batch/s, accuracy=91.6, loss=0.241]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.14batch/s, val_acc=91, val_loss=0.268]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 42 training loss = 0.2414, training accuracy = 91.65%, val_loss = 0.2677, val_accuracy = 91.02% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.2677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:46<00:00,  1.73batch/s, accuracy=91.8, loss=0.235] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.98batch/s, val_acc=91.1, val_loss=0.27]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 43 training loss = 0.2348, training accuracy = 91.78%, val_loss = 0.2700, val_accuracy = 91.09% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=91.9, loss=0.233]  \n",
      "Validation: : 100%|██████████| 79/79 [00:13<00:00,  5.92batch/s, val_acc=91.3, val_loss=0.263] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 44 training loss = 0.2335, training accuracy = 91.91%, val_loss = 0.2628, val_accuracy = 91.29% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.2628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:57<00:00,  1.65batch/s, accuracy=92, loss=0.23]     \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.05batch/s, val_acc=91.1, val_loss=0.267] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 45 training loss = 0.2302, training accuracy = 92.04%, val_loss = 0.2666, val_accuracy = 91.09% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.60batch/s, accuracy=92.2, loss=0.223] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.99batch/s, val_acc=91.3, val_loss=0.267] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 46 training loss = 0.2233, training accuracy = 92.25%, val_loss = 0.2667, val_accuracy = 91.27% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:48<00:00,  1.71batch/s, accuracy=92.4, loss=0.221] \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.03batch/s, val_acc=91.3, val_loss=0.264] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 47 training loss = 0.2214, training accuracy = 92.39%, val_loss = 0.2636, val_accuracy = 91.29% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:55<00:00,  1.66batch/s, accuracy=92.3, loss=0.221]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.07batch/s, val_acc=91.4, val_loss=0.264] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 48 training loss = 0.2208, training accuracy = 92.29%, val_loss = 0.2639, val_accuracy = 91.44% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.60batch/s, accuracy=92.3, loss=0.22]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.94batch/s, val_acc=91.3, val_loss=0.263] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 49 training loss = 0.2203, training accuracy = 92.28%, val_loss = 0.2634, val_accuracy = 91.27% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=92.5, loss=0.216]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.07batch/s, val_acc=91.3, val_loss=0.265] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 50 training loss = 0.2164, training accuracy = 92.50%, val_loss = 0.2651, val_accuracy = 91.26% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.61batch/s, accuracy=92.7, loss=0.211]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.06batch/s, val_acc=91.5, val_loss=0.259] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 51 training loss = 0.2108, training accuracy = 92.70%, val_loss = 0.2588, val_accuracy = 91.48% & LR = 0.0001\n",
      "\n",
      "Saving model with lowest val_loss = 0.2588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:54<00:00,  1.67batch/s, accuracy=92.7, loss=0.211]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.96batch/s, val_acc=91.5, val_loss=0.261] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 52 training loss = 0.2113, training accuracy = 92.65%, val_loss = 0.2608, val_accuracy = 91.52% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=92.7, loss=0.211] \n",
      "Validation: : 100%|██████████| 79/79 [00:13<00:00,  5.84batch/s, val_acc=91.5, val_loss=0.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 53 training loss = 0.2114, training accuracy = 92.72%, val_loss = 0.2600, val_accuracy = 91.53% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:57<00:00,  1.64batch/s, accuracy=92.6, loss=0.211]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.01batch/s, val_acc=91.5, val_loss=0.257] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 54 training loss = 0.2111, training accuracy = 92.62%, val_loss = 0.2568, val_accuracy = 91.50% & LR = 0.0001\n",
      "\n",
      "Saving model with lowest val_loss = 0.2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=92.9, loss=0.208]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.10batch/s, val_acc=91.5, val_loss=0.259] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 55 training loss = 0.2075, training accuracy = 92.85%, val_loss = 0.2588, val_accuracy = 91.52% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:49<00:00,  1.70batch/s, accuracy=92.8, loss=0.207]  \n",
      "Validation: : 100%|██████████| 79/79 [00:13<00:00,  5.81batch/s, val_acc=91.5, val_loss=0.261] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 56 training loss = 0.2067, training accuracy = 92.81%, val_loss = 0.2609, val_accuracy = 91.51% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=92.7, loss=0.209]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.98batch/s, val_acc=91.5, val_loss=0.264] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 57 training loss = 0.2089, training accuracy = 92.74%, val_loss = 0.2642, val_accuracy = 91.52% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.60batch/s, accuracy=92.8, loss=0.207]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.15batch/s, val_acc=91.6, val_loss=0.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 58 training loss = 0.2073, training accuracy = 92.82%, val_loss = 0.2596, val_accuracy = 91.57% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.61batch/s, accuracy=92.8, loss=0.207]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.06batch/s, val_acc=91.5, val_loss=0.262] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 59 training loss = 0.2072, training accuracy = 92.80%, val_loss = 0.2619, val_accuracy = 91.47% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:04<00:00,  1.60batch/s, accuracy=92.8, loss=0.205]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.96batch/s, val_acc=91.5, val_loss=0.261] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 60 training loss = 0.2051, training accuracy = 92.83%, val_loss = 0.2607, val_accuracy = 91.47% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.61batch/s, accuracy=92.9, loss=0.206]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.20batch/s, val_acc=91.5, val_loss=0.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 61 training loss = 0.2064, training accuracy = 92.88%, val_loss = 0.2597, val_accuracy = 91.54% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:01<00:00,  1.62batch/s, accuracy=92.8, loss=0.208] \n",
      "Validation: : 100%|██████████| 79/79 [00:11<00:00,  6.83batch/s, val_acc=91.7, val_loss=0.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 62 training loss = 0.2081, training accuracy = 92.84%, val_loss = 0.2598, val_accuracy = 91.69% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:02<00:00,  1.61batch/s, accuracy=92.9, loss=0.204]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.13batch/s, val_acc=91.5, val_loss=0.262] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 63 training loss = 0.2042, training accuracy = 92.94%, val_loss = 0.2624, val_accuracy = 91.54% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [03:54<00:00,  1.67batch/s, accuracy=92.9, loss=0.204]  \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  5.05batch/s, val_acc=91.5, val_loss=0.261] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 64 training loss = 0.2042, training accuracy = 92.91%, val_loss = 0.2609, val_accuracy = 91.53% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:03<00:00,  1.60batch/s, accuracy=93, loss=0.205]    \n",
      "Validation: : 100%|██████████| 79/79 [00:15<00:00,  4.96batch/s, val_acc=91.6, val_loss=0.26]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 65 training loss = 0.2048, training accuracy = 93.00%, val_loss = 0.2601, val_accuracy = 91.61% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss, train_acc = train_model_progress(model, train_loader)\n",
    "    val_loss, val_acc = test_model_progress(model, test_loader)\n",
    "    \n",
    "    print(f\"\\nepoch: {epoch + 1} training loss = {train_loss:.4f}, \"\n",
    "          f\"training accuracy = {train_acc:.2f}%, val_loss = {val_loss:.4f}\"\n",
    "          f\", val_accuracy = {val_acc:.2f}% & \"\n",
    "          f\"LR = {optimizer.param_groups[0]['lr']:.4f}\\n\")\n",
    "    \n",
    "    training_history_lr_scheduler[epoch + 1] = {\n",
    "        'loss': train_loss, 'acc': train_acc,\n",
    "        'val_loss': val_loss, 'val_acc': val_acc,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Save best weights achieved until now-\n",
    "    if (val_loss < best_val_loss):    \n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"ResNet50_lr_scheduler_best_model.pth\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model from last training epoch-\n",
    "torch.save(model.state_dict(), \"ResNet50_lr_scheduler_last_epoch_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new ResNet-50 model-\n",
    "best_model = ResNet50(img_channels = 3, num_channels = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "best_model.load_state_dict(torch.load('ResNet50_lr_scheduler_last_epoch_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place model on GPU (if available)-\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = test_model_progress(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-50 'best' (LR scheduler) model metrics: val_loss = 0.2255 & val_acc = 93.85%\n"
     ]
    }
   ],
   "source": [
    "print(f\"ResNet-50 'best' (LR scheduler) model metrics: val_loss = {val_loss:.4f} & val_acc = {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del best_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "For this particular experiment, it seems that using ```val_loss``` as the metric to save the _best_ model is not the optimum choice.\n",
    "\n",
    "_Highest validation accuracy_ achieved = 93.85%.\n",
    "\n",
    "Also, there seems to be _overfitting_ happening. _Dropout_ needs to be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "training_history_lr_scheduler.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_lr_scheduler[12].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metrics as Python3 history for later analysis-\n",
    "with open(\"ResNet50_training_history_lr_scheduler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_history_lr_scheduler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a1ed4f28045e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ResNet50_training_history_lr_scheduler.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtraining_history_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(\"ResNet50_training_history_lr_scheduler.pkl\", \"rb\") as file:\n",
    "    training_history_lr_scheduler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_history_lr_scheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d1cf7d957e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_history_lr_scheduler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_history_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_history_lr_scheduler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_history_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ResNet-50: Training Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_history_lr_scheduler' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['acc'] for k in training_history_lr_scheduler.keys()], label = 'training acc')\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['val_acc'] for k in training_history_lr_scheduler.keys()], label = 'val acc')\n",
    "plt.title(\"ResNet-50: Training Accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy (%)\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['loss'] for k in training_history_lr_scheduler.keys()], label = 'training loss')\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['val_loss'] for k in training_history_lr_scheduler.keys()], label = 'val loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.title(\"ResNet-50: Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['lr'] for k in training_history_lr_scheduler.keys()])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"lr\")\n",
    "plt.title(\"ResNet-50: Learning-Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG18_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
