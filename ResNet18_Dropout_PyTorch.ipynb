{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZOD2mGIeyEJ"
   },
   "source": [
    "# ResNet-18 CNN: PyTorch & CIFAR-10\n",
    "\n",
    "End-to-end programming tutorial including:\n",
    "\n",
    "1. Dropout (Vanilla ResNet-18 displays a high degree of overfitting)\n",
    "1. Progress bar - training model\n",
    "1. Train model with _early stopping criterion_\n",
    "1. Learning rate scheduler\n",
    "1. Compare between learning rate scheduler and early stopping criterion\n",
    "\n",
    "\n",
    "[Reference](https://d2l.ai/chapter_convolutional-modern/resnet.html#fig-residual-block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7hpnDY7Mfb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# Specify GPU to be used-\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cM6Ih3nVq0Gh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DvYMsqNezdm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha-v5IiWezqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_H9KbTonq0Q9",
    "outputId": "41b72a44-64e1-44c2-a917-615e9adafb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently available device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration-\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"currently available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of available GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "# Get number of multiple GPUs (if any)-\n",
    "print(f\"number of available GPUs = {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU = 0\n"
     ]
    }
   ],
   "source": [
    "# Get current GPU-\n",
    "print(f\"Current GPU = {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of current GPU being used = Quadro M6000\n"
     ]
    }
   ],
   "source": [
    "# Get name of current GPU-\n",
    "print(f\"Name of current GPU being used = {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2CJ2XyNq9Nd",
    "outputId": "3e5961db-ccb3-4be4-9207-21d280f44beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6rTKbcZrBN0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uV1m3vD0rBee"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters-\n",
    "num_epochs = 65\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QGc3oYHrDzL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9R6Sc5v6rD8M"
   },
   "outputs": [],
   "source": [
    "# Define transformations for training and test sets-\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomCrop(32, padding = 4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "4ddOxdkirHPN",
    "outputId": "764e40cc-2f3c-482f-bbb1-542c39d0d1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset-\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = True,\n",
    "        download = True, transform = transform_train\n",
    "        )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = False,\n",
    "        download = True, transform = transform_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW8h3ztJrU5_",
    "outputId": "643be603-0775-412b-9a3d-7dfbe5df1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) = 50000 & len(test_dataset) = 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_dataset) = {len(train_dataset)} & len(test_dataset) = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cydrwaW7rbnV"
   },
   "outputs": [],
   "source": [
    "# Create training and testing loaders-\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size = batch_size,\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size = batch_size,\n",
    "        shuffle = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62AgWl9jrfzW",
    "outputId": "0972fead-2556-4cea-9ff4-8f50eabf6cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 391 & len(test_loader) = 79\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_loader) = {len(train_loader)} & len(test_loader) = {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjGADCMfrhAl",
    "outputId": "e3bb3177-720d-48ce-ef5a-b0e61c5ac9bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390.625, 78.125)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "len(train_dataset) / batch_size, len(test_dataset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEBunYxErhh8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhwdHTu0rsf8",
    "outputId": "c84eaa78-265f-4af7-dbdf-f45370c2bb4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 32, 32]), torch.Size([128]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "len(train_dataset) / batch_size, len(test_dataset) / batch_size\n",
    "\n",
    "# Sanity check-\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "images.size(), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOgym6Ffrtds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ln5CjwJhrtqc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdWaY-5NruCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlFoyg5Hruqn"
   },
   "source": [
    "### Define _ResNet-18_ architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    '''\n",
    "    Residual Block within a ResNet CNN model\n",
    "    '''\n",
    "    def __init__(self, input_channels, num_channels, \n",
    "                 use_1x1_conv = False, strides = 1,\n",
    "                 dropout = 0.2):\n",
    "        # super(ResidualBlock, self).__init__()\n",
    "        super().__init__()\n",
    "     \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = input_channels, out_channels = num_channels,\n",
    "            kernel_size = 3, padding = 1, stride = strides,\n",
    "            bias = False\n",
    "            )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = num_channels, out_channels = num_channels,\n",
    "            kernel_size = 3, padding = 1, stride = 1,\n",
    "            bias = False\n",
    "            )\n",
    "        \n",
    "        if use_1x1_conv:\n",
    "            self.conv3 = nn.Conv2d(\n",
    "                in_channels = input_channels, out_channels = num_channels,\n",
    "                kernel_size = 1, stride = strides\n",
    "                )\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features = num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features = num_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = self.dropout(F.relu(self.bn1(self.conv1(X))))\n",
    "        # Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        # Y = self.dropout(F.relu(self.bn2(self.conv2(Y))))\n",
    "        \n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "            # print(f\"X.shape due to 1x1: {X.shape} & Y.shape = {Y.shape}\")\n",
    "        else:\n",
    "            # print(f\"X.shape without 1x1: {X.shape} & Y.shape = {Y.shape}\")\n",
    "            pass\n",
    "        \n",
    "        Y += X\n",
    "        # return F.relu(Y)\n",
    "        return self.dropout(F.relu(Y))\n",
    "    \n",
    "    \n",
    "    def shape_computation(self, X):\n",
    "        Y = self.conv1(X)\n",
    "        print(f\"self.conv1(X).shape: {Y.shape}\")\n",
    "        Y = self.conv2(Y)\n",
    "        print(f\"self.conv2(X).shape: {Y.shape}\")\n",
    "        \n",
    "        if self.conv3:\n",
    "            h = self.conv3(X)\n",
    "            print(f\"self.conv3(X).shape: {h.shape}\")\n",
    "    \n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            # print(m)\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "\n",
    "                '''\n",
    "                # Do not initialize bias (due to batchnorm)-\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                '''\n",
    "            \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                # Standard initialization for batch normalization-\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.BatchNorm2d(num_features = 64),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "b0(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet_block(input_filters, output_filters, num_residuals, first_block = False, dropout = 0.2):\n",
    "    # Python list to hold the created ResNet blocks-\n",
    "    resnet_blk = []\n",
    "    \n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and first_block:\n",
    "            resnet_blk.append(ResidualBlock(input_channels = input_filters, num_channels = output_filters, use_1x1_conv = True, strides = 2, dropout = dropout))\n",
    "        else:\n",
    "            resnet_blk.append(ResidualBlock(input_channels = output_filters, num_channels = output_filters, use_1x1_conv = False, strides = 1, dropout = dropout))\n",
    "    \n",
    "    return resnet_blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 64, num_residuals = 2, first_block = True, dropout = 0.2))\n",
    "b2 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 128, num_residuals = 2, first_block = True, dropout = 0.3))\n",
    "b3 = nn.Sequential(*create_resnet_block(input_filters = 128, output_filters = 256, num_residuals = 2, first_block = True, dropout = 0.3))\n",
    "b4 = nn.Sequential(*create_resnet_block(input_filters = 256, output_filters = 512, num_residuals = 2, first_block = True, dropout = 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet18():\n",
    "    # Initialize ResNet-18 model-\n",
    "    model = nn.Sequential(\n",
    "        b0, b1, b2, b3, b4,\n",
    "        nn.AdaptiveAvgPool2d(output_size = (1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features = 512, out_features = 10)\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "v_NeRxjgbOGE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "model(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9aSBydxsD27",
    "outputId": "79ba1ecd-97d6-4c18-fea7-2acb2cbe66f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU-\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SnL7fjksJLh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9A-AfIXwcE6u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8zux0jjsHq0",
    "outputId": "e986b7ad-171b-474c-cb60-2097fdecc112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.shape = torch.Size([64, 3, 3, 3]) has 1728 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 1, 1]) has 4096 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64, 64, 3, 3]) has 36864 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([64]) has 64 parameters\n",
      "layer.shape = torch.Size([128, 64, 3, 3]) has 73728 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128, 64, 1, 1]) has 8192 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128, 128, 3, 3]) has 147456 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([128]) has 128 parameters\n",
      "layer.shape = torch.Size([256, 128, 3, 3]) has 294912 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 128, 1, 1]) has 32768 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256, 256, 3, 3]) has 589824 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([256]) has 256 parameters\n",
      "layer.shape = torch.Size([512, 256, 3, 3]) has 1179648 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512, 256, 1, 1]) has 131072 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512, 512, 3, 3]) has 2359296 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([512]) has 512 parameters\n",
      "layer.shape = torch.Size([10, 512]) has 5120 parameters\n",
      "layer.shape = torch.Size([10]) has 10 parameters\n"
     ]
    }
   ],
   "source": [
    "# Count number of layer-wise parameters and total parameters-\n",
    "tot_params = 0\n",
    "for param in model.parameters():\n",
    "    print(f\"layer.shape = {param.shape} has {param.nelement()} parameters\")\n",
    "    tot_params += param.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp9X8qnOsY1t",
    "outputId": "161ec2b1-37d8-4676-dcf8-aa96cf9bfc3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in VGG-18 CNN = 11177290\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of parameters in VGG-18 CNN = {tot_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WdKiWsLsZYN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Print layer names-\n",
    "for layer in model.state_dict().keys():\n",
    "    print(f\"{layer} has dimension = {model.state_dict()[layer].shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1jFfuJiscmN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "O_WUBfzFscrc"
   },
   "outputs": [],
   "source": [
    "# Save random initial weights-\n",
    "torch.save(model.state_dict(), 'ResNet18_dropout_random_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gdgada5J5mIR",
    "outputId": "4ad9e79d-a499-4831-c030-219544802967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "# model.load_state_dict(torch.load('ResNet18_random_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGUR1m04stvU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OozQ7SF4st4U"
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer-\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NXRjN5is4eF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "stjVD5uus0xW"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def train_step(model, train_loader):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    for batch, (images, labels) in enumerate(train_loader):\n",
    "        # Attempt to push to GPU if available\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # print(f\"batch # = {batch}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass-\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss-\n",
    "        J = loss(outputs, labels)\n",
    "\n",
    "        # Backward pass-\n",
    "        optimizer.zero_grad()   # empty accumulated gradients\n",
    "\n",
    "        J.backward()    # perform backpropagation\n",
    "\n",
    "        # Updates parameters-\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute model's performance statistics-\n",
    "        running_loss += J.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "        '''\n",
    "        # Print information every 100 steps-\n",
    "        if (batch + 1) % 100 == 0:\n",
    "            print(f\"epoch {epoch + 1}/{num_epochs}, step {batch + 1}/{num_training_steps}, loss = {J.item():.4f}\")\n",
    "        '''\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "    return epoch_loss, epoch_acc.cpu().numpy()\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0DyTwwRhcOeY"
   },
   "outputs": [],
   "source": [
    "def train_model_progress(model, train_loader):\n",
    "    '''\n",
    "    Function to perform one epoch of training by using 'train_loader'.\n",
    "    Returns loss and number of correct predictions for this epoch.\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Training: \")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions-\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss-\n",
    "            J = loss(outputs, labels)\n",
    "            \n",
    "            # Empty accumulated gradients-\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform backprop-\n",
    "            J.backward()\n",
    "            \n",
    "            # Update parameters-\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute model's performance statistics-\n",
    "            running_loss += J.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "            tepoch.set_postfix(\n",
    "                loss = running_loss / len(train_dataset),\n",
    "                accuracy = (running_corrects.double().cpu().numpy() / len(train_dataset)) * 100\n",
    "            )\n",
    "            \n",
    "    \n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "\n",
    "    # return running_loss, running_corrects\n",
    "    return train_loss, train_acc.cpu().numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCq8FAdOckD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lHUDSkX8s8Od"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def validate_step(model, test_loader):\n",
    "    total, correct = 0, 0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            # Place features (images) and targets (labels) to GPU-\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Set model to evaluation mode-\n",
    "            model.eval()\n",
    "    \n",
    "            # Make predictions using trained model-\n",
    "            outputs = model(images)\n",
    "            _, y_pred = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute validation loss-\n",
    "            J_val = loss(outputs, labels)\n",
    "\n",
    "            running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "            # Total number of labels-\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Total number of correct predictions-\n",
    "            correct += (y_pred == labels).sum()\n",
    "\n",
    "    epoch_val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = 100 * (correct / total)\n",
    "\n",
    "    return epoch_val_loss, val_acc.cpu().numpy()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YymBc1UtcnEA"
   },
   "outputs": [],
   "source": [
    "def test_model_progress(model, test_loader):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit = 'batch') as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                tepoch.set_description(f\"Validation: \")\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Set model to evaluation mode-\n",
    "                model.eval()\n",
    "            \n",
    "                # Predict using trained model-\n",
    "                outputs = model(images)\n",
    "                _, y_pred = torch.max(outputs, 1)\n",
    "                \n",
    "                # Compute validation loss-\n",
    "                J_val = loss(outputs, labels)\n",
    "                \n",
    "                running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "                # Total number of labels-\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total number of correct predictions-\n",
    "                correct += (y_pred == labels).sum()\n",
    "                \n",
    "                tepoch.set_postfix(\n",
    "                    val_loss = running_loss_val / len(test_dataset),\n",
    "                    val_acc = 100 * (correct.cpu().numpy() / total)\n",
    "                )\n",
    "            \n",
    "        \n",
    "    # return (running_loss_val, correct, total)\n",
    "    val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = (correct / total) * 100\n",
    "\n",
    "    return val_loss, val_acc.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3BGHQY9YcuqJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5OVpgCicu1i",
    "outputId": "20d63dcf-26b5-4958-96f7-c134ef794420"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [04:08<00:00,  1.57batch/s, accuracy=45.5, loss=1.47]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check-\n",
    "train_loss, train_acc = train_model_progress(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AP1HjJC6c7nS",
    "outputId": "44c7dcd7-c693-4904-9328-d6cf916ab75f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: : 100%|██████████| 79/79 [00:08<00:00,  9.06batch/s, val_acc=56.6, val_loss=1.21]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check-\n",
    "val_loss, val_acc = test_model_progress(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgTblttjdFXu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gw4-9h2vibj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDIK4_3W8L95"
   },
   "source": [
    "### Train model _without_ learning rate scheduler, using early-stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NOytz_v9tPxV"
   },
   "outputs": [],
   "source": [
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "SbXa8wiR6OHv"
   },
   "outputs": [],
   "source": [
    "# User input parameters for Early Stopping in manual implementation-\n",
    "minimum_delta = 0.001\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "K1oqH6x25YFS"
   },
   "outputs": [],
   "source": [
    "training_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qYVpzJ0_h97Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "G7E2MwUJh-Dv",
    "outputId": "e29a407f-e25c-4b77-9ee2-3bd839eb7952"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:58<00:00,  6.65batch/s, accuracy=19.6, loss=2.3]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.19batch/s, val_acc=11, val_loss=2.96]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 training loss = 2.2996, training accuracy = 19.64%, val_loss = 2.9611, val_accuracy = 11.01% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 2.9611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.00batch/s, accuracy=26.6, loss=1.91]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.01batch/s, val_acc=15.9, val_loss=2.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 training loss = 1.9071, training accuracy = 26.61%, val_loss = 2.5747, val_accuracy = 15.92% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 2.5747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.43batch/s, accuracy=31.7, loss=1.77]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.23batch/s, val_acc=28.3, val_loss=2.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 training loss = 1.7700, training accuracy = 31.68%, val_loss = 2.1377, val_accuracy = 28.29% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 2.1377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.96batch/s, accuracy=36.4, loss=1.67]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.66batch/s, val_acc=33.9, val_loss=1.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 training loss = 1.6677, training accuracy = 36.37%, val_loss = 1.8625, val_accuracy = 33.94% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.8625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.12batch/s, accuracy=41, loss=1.57]    \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.82batch/s, val_acc=39.3, val_loss=1.71] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5 training loss = 1.5652, training accuracy = 41.00%, val_loss = 1.7129, val_accuracy = 39.34% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.7129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.08batch/s, accuracy=44.2, loss=1.49]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.54batch/s, val_acc=46.7, val_loss=1.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6 training loss = 1.4870, training accuracy = 44.19%, val_loss = 1.4775, val_accuracy = 46.69% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.4775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:51<00:00,  7.53batch/s, accuracy=47.8, loss=1.4]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.44batch/s, val_acc=47.7, val_loss=1.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7 training loss = 1.4029, training accuracy = 47.75%, val_loss = 1.5057, val_accuracy = 47.69% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.96batch/s, accuracy=51.1, loss=1.32]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.63batch/s, val_acc=49.3, val_loss=1.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8 training loss = 1.3243, training accuracy = 51.11%, val_loss = 1.4371, val_accuracy = 49.27% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.4371\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:51<00:00,  7.58batch/s, accuracy=53.7, loss=1.26]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.99batch/s, val_acc=55.6, val_loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9 training loss = 1.2603, training accuracy = 53.71%, val_loss = 1.2837, val_accuracy = 55.60% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.2837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.17batch/s, accuracy=56.7, loss=1.19]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.15batch/s, val_acc=58.1, val_loss=1.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10 training loss = 1.1910, training accuracy = 56.69%, val_loss = 1.2286, val_accuracy = 58.09% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.2286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=58.9, loss=1.14]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.01batch/s, val_acc=57.4, val_loss=1.24] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 11 training loss = 1.1359, training accuracy = 58.87%, val_loss = 1.2431, val_accuracy = 57.39% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.38batch/s, accuracy=61.1, loss=1.09]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.94batch/s, val_acc=62.8, val_loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 12 training loss = 1.0861, training accuracy = 61.06%, val_loss = 1.0513, val_accuracy = 62.80% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 1.0513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.01batch/s, accuracy=63, loss=1.04]    \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.25batch/s, val_acc=62.7, val_loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 13 training loss = 1.0379, training accuracy = 63.03%, val_loss = 1.0745, val_accuracy = 62.70% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.46batch/s, accuracy=64.5, loss=0.996] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.91batch/s, val_acc=66.1, val_loss=0.992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 14 training loss = 0.9958, training accuracy = 64.50%, val_loss = 0.9920, val_accuracy = 66.12% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.9920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.95batch/s, accuracy=65.8, loss=0.956] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 15.83batch/s, val_acc=66.9, val_loss=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 15 training loss = 0.9562, training accuracy = 65.85%, val_loss = 0.9451, val_accuracy = 66.89% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.9451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:53<00:00,  7.37batch/s, accuracy=67.1, loss=0.927] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.45batch/s, val_acc=67.7, val_loss=0.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 16 training loss = 0.9266, training accuracy = 67.12%, val_loss = 0.9406, val_accuracy = 67.68% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.9406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=67.9, loss=0.9]   \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.29batch/s, val_acc=65.2, val_loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 17 training loss = 0.9001, training accuracy = 67.94%, val_loss = 1.0485, val_accuracy = 65.20% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:53<00:00,  7.37batch/s, accuracy=69.2, loss=0.867] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.05batch/s, val_acc=70.5, val_loss=0.863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 18 training loss = 0.8674, training accuracy = 69.23%, val_loss = 0.8632, val_accuracy = 70.54% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.8632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.96batch/s, accuracy=70.4, loss=0.842] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.05batch/s, val_acc=71.1, val_loss=0.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 19 training loss = 0.8419, training accuracy = 70.39%, val_loss = 0.8597, val_accuracy = 71.10% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.8597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.08batch/s, accuracy=71.2, loss=0.818] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.67batch/s, val_acc=69.3, val_loss=0.932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20 training loss = 0.8176, training accuracy = 71.24%, val_loss = 0.9315, val_accuracy = 69.30% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.46batch/s, accuracy=72, loss=0.799]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.35batch/s, val_acc=74.8, val_loss=0.748] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 training loss = 0.7994, training accuracy = 72.03%, val_loss = 0.7476, val_accuracy = 74.76% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.7476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:49<00:00,  7.83batch/s, accuracy=72.8, loss=0.778] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.68batch/s, val_acc=74.7, val_loss=0.758] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 22 training loss = 0.7776, training accuracy = 72.79%, val_loss = 0.7582, val_accuracy = 74.65% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=73.7, loss=0.754] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.36batch/s, val_acc=75.8, val_loss=0.704] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 23 training loss = 0.7538, training accuracy = 73.69%, val_loss = 0.7037, val_accuracy = 75.81% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.7037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:51<00:00,  7.55batch/s, accuracy=74.7, loss=0.73]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.99batch/s, val_acc=77.4, val_loss=0.674] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 24 training loss = 0.7304, training accuracy = 74.72%, val_loss = 0.6745, val_accuracy = 77.39% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6745\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.07batch/s, accuracy=75.1, loss=0.717] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.58batch/s, val_acc=75.9, val_loss=0.707] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 25 training loss = 0.7171, training accuracy = 75.09%, val_loss = 0.7071, val_accuracy = 75.90% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=75.6, loss=0.696] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.30batch/s, val_acc=77.9, val_loss=0.66]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 26 training loss = 0.6962, training accuracy = 75.57%, val_loss = 0.6596, val_accuracy = 77.92% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=76.4, loss=0.685] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.42batch/s, val_acc=77.6, val_loss=0.678] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 27 training loss = 0.6853, training accuracy = 76.36%, val_loss = 0.6784, val_accuracy = 77.60% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.49batch/s, accuracy=77.1, loss=0.665] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.23batch/s, val_acc=78.8, val_loss=0.623] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 28 training loss = 0.6649, training accuracy = 77.07%, val_loss = 0.6232, val_accuracy = 78.82% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.92batch/s, accuracy=77.5, loss=0.653] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.57batch/s, val_acc=78.1, val_loss=0.648] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 29 training loss = 0.6532, training accuracy = 77.54%, val_loss = 0.6481, val_accuracy = 78.13% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:53<00:00,  7.28batch/s, accuracy=78, loss=0.642]   \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.24batch/s, val_acc=79.4, val_loss=0.608] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 30 training loss = 0.6424, training accuracy = 77.97%, val_loss = 0.6076, val_accuracy = 79.37% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.6076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.93batch/s, accuracy=78.2, loss=0.632] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.57batch/s, val_acc=80.7, val_loss=0.568] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 31 training loss = 0.6320, training accuracy = 78.19%, val_loss = 0.5680, val_accuracy = 80.69% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.5680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.00batch/s, accuracy=78.8, loss=0.622] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.04batch/s, val_acc=81.5, val_loss=0.546] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 32 training loss = 0.6221, training accuracy = 78.75%, val_loss = 0.5463, val_accuracy = 81.54% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.5463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.04batch/s, accuracy=79.2, loss=0.607] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.48batch/s, val_acc=80.3, val_loss=0.585] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 33 training loss = 0.6073, training accuracy = 79.17%, val_loss = 0.5846, val_accuracy = 80.31% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=79.4, loss=0.598] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.36batch/s, val_acc=83.3, val_loss=0.492] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 34 training loss = 0.5982, training accuracy = 79.40%, val_loss = 0.4915, val_accuracy = 83.29% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.03batch/s, accuracy=80, loss=0.589]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.07batch/s, val_acc=81, val_loss=0.571]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 35 training loss = 0.5894, training accuracy = 80.03%, val_loss = 0.5711, val_accuracy = 80.97% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.06batch/s, accuracy=80.4, loss=0.577] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.86batch/s, val_acc=81.7, val_loss=0.545] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 36 training loss = 0.5770, training accuracy = 80.36%, val_loss = 0.5446, val_accuracy = 81.71% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.20batch/s, accuracy=80.7, loss=0.569] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.46batch/s, val_acc=83, val_loss=0.512]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 37 training loss = 0.5687, training accuracy = 80.73%, val_loss = 0.5125, val_accuracy = 82.97% & LR = 0.0100\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    if loc_patience >= patience:\n",
    "        print(\"\\n'EarlyStopping' called!\\n\")\n",
    "        break\n",
    "\n",
    "    train_loss, train_acc = train_model_progress(model, train_loader)\n",
    "    val_loss, val_acc = test_model_progress(model, test_loader)\n",
    "    \n",
    "    print(f\"\\nepoch: {epoch + 1} training loss = {train_loss:.4f}, \"\n",
    "          f\"training accuracy = {train_acc:.2f}%, val_loss = {val_loss:.4f}\"\n",
    "          f\", val_accuracy = {val_acc:.2f}% & \"\n",
    "          f\"LR = {optimizer.param_groups[0]['lr']:.4f}\\n\")\n",
    "    \n",
    "    training_history[epoch + 1] = {\n",
    "        'loss': train_loss, 'acc': train_acc,\n",
    "        'val_loss': val_loss, 'val_acc': val_acc,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    # Save best weights achieved until now-\n",
    "    if (val_loss < best_val_loss):    \n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"VGG18_best_model.pth\")\n",
    "    '''\n",
    "\n",
    "    # Code for manual Early Stopping:\n",
    "    # if np.abs(val_loss < best_val_loss) >= minimum_delta:\n",
    "    if (val_loss < best_val_loss) and \\\n",
    "    (np.abs(val_loss - best_val_loss) >= minimum_delta):\n",
    "\n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "        \n",
    "        # reset 'loc_patience' variable-\n",
    "        loc_patience = 0\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"ResNet18_best_model.pth\")\n",
    "        \n",
    "    else:  # there is no improvement in monitored metric 'val_loss'\n",
    "        loc_patience += 1  # number of epochs without any improvement\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HW6eI7f-4W9R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "temp_model = create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_model.load_state_dict(torch.load('ResNet18_best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU-\n",
    "temp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.34batch/s, val_acc=83.3, val_loss=0.492] \n"
     ]
    }
   ],
   "source": [
    "# Compute performance of 'best' model on validation data-\n",
    "val_loss, val_acc = test_model_progress(temp_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-18 'best' model (dropout with early stopping) metrics: val_loss = 0.4915 & val_acc = 83.29%\n"
     ]
    }
   ],
   "source": [
    "print(f\"ResNet-18 'best' model (dropout with early stopping) metrics: val_loss = {val_loss:.4f} & val_acc = {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3dcgzOwii1g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXesVlcAtj_U",
    "outputId": "fa906693-19de-4aa6-fe1c-b4d197346f26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COrZUx-_P6Zx",
    "outputId": "66e63461-5f0b-436b-b4fd-5615ef5c769b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history[2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0ZrNvFoP_fZ",
    "outputId": "d1441b8f-507c-4044-93ae-c4a775c61fb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(15.92, dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history[2]['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loPQquhpQC9Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "yJkajjh9QGKK"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0G1TaNnnQHDI"
   },
   "outputs": [],
   "source": [
    "with open(\"ResNet18_dropout_early_stopping_training_history.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiAv9vgBQigh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "MuBmbE6CQuPO"
   },
   "outputs": [],
   "source": [
    "# Save trained weights-\n",
    "# torch.save(model.state_dict(), 'ResNet18_dropout_trained_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSOrFC5gQz9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "h0Fbk-V3Q0H8"
   },
   "outputs": [],
   "source": [
    "del temp_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WC2enWfbT5wt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with _learning rate scheduler_\n",
    "\n",
    "- Training dataset = 50000, batch size = 128, number of training steps/iterations = 50000 / 128 = 391\n",
    "\n",
    "- Initial learning rate warmup: 391 x 10 = 3910 steps or, 10 epochs at LR = 0.1\n",
    "\n",
    "- Until 25th epoch or, 9775 steps use LR = 0.1\n",
    "\n",
    "- From 26th epoch until 40th epoch or, 15640 steps use LR = 0.01\n",
    "\n",
    "- From 41st epoch until 50th epoch or, 19550 steps use LR = 0.001\n",
    "\n",
    "- From 51st epoch until 60th epoch use LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [9775, 15640, 19550]\n",
    "values = [0.1, 0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_function(step, boundaries = [9775, 15640, 19550], values = [0.1, 0.01, 0.001, 0.0001]):\n",
    "    '''\n",
    "    1 epoch has 391 steps/iterations using batch size used above.\n",
    "    \n",
    "    Until 25th epochs, or 25 x 391 = 9775 steps, use lr = 0.1\n",
    "    From 26th epoch until 40th epoch, or 15640 steps use LR = 0.01\n",
    "    From 41st epoch until 50th epoch or, 19550 steps use LR = 0.001\n",
    "    From 51st epoch until 60th epoch use LR = 0.0001\n",
    "    '''\n",
    "    \n",
    "    for idx, bound in enumerate(boundaries):\n",
    "        if step < bound:\n",
    "            return values[idx]\n",
    "\n",
    "    return values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def decay_function(step, boundaries = [15640, 19550], values = [0.01, 0.001, 0.0001]):\n",
    "    '''\n",
    "    1 epoch has 391 steps/iterations using batch size used above.\n",
    "    \n",
    "    Until 40 epochs, or 40 x 391 = 15640 steps, use lr = 0.01\n",
    "    Until 50 epochs, or 50 x 391 = 19550 steps, use lr = 0.001\n",
    "    \n",
    "    For any remaining steps, use lr = 0.0001\n",
    "    '''\n",
    "    \n",
    "    for idx, bound in enumerate(boundaries):\n",
    "        if step < bound:\n",
    "            return values[idx]\n",
    "\n",
    "    return values[-1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decay_function(step = 2, boundaries = [0, 2, 4, 6, 8, 10], values = [10, 15, 20, 30, 40, 50, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class schedule():\n",
    "\n",
    "    def __init__(self, initial_learning_rate = 0.1, warmup_steps = 1000, decay_func = None):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_func = decay_func\n",
    "        self.warmup_step_size = initial_learning_rate/warmup_steps\n",
    "        self.current_lr = 0\n",
    "\n",
    "    def get_lr(self, step):\n",
    "        if step == 0:\n",
    "            return self.current_lr\n",
    "        elif step <= self.warmup_steps:\n",
    "            self.current_lr+=self.warmup_step_size\n",
    "            return self.current_lr\n",
    "        elif step > self.warmup_steps:\n",
    "            if self.decay_func:\n",
    "                return self.decay_func(step)\n",
    "        else:\n",
    "            return self.current_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 391 x 10 = 3910 steps (or, 10 epochs) is learning rate warmup\n",
    "custom_lr_scheduler = schedule(\n",
    "    initial_learning_rate = 0.1, warmup_steps = 3910,\n",
    "    decay_func = decay_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0DyTwwRhcOeY"
   },
   "outputs": [],
   "source": [
    "def train_model_progress(model, train_loader):\n",
    "    '''\n",
    "    Function to perform one epoch of training by using 'train_loader'.\n",
    "    Returns loss and number of correct predictions for this epoch.\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Training: \")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions-\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss-\n",
    "            J = loss(outputs, labels)\n",
    "            \n",
    "            # Empty accumulated gradients-\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform backprop-\n",
    "            J.backward()\n",
    "            \n",
    "            # Update parameters-\n",
    "            optimizer.step()\n",
    "            \n",
    "            global step\n",
    "            optimizer.param_groups[0]['lr'] = custom_lr_scheduler.get_lr(step)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            # Compute model's performance statistics-\n",
    "            running_loss += J.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(predicted == labels.data)\n",
    "            \n",
    "            tepoch.set_postfix(\n",
    "                loss = running_loss / len(train_dataset),\n",
    "                accuracy = (running_corrects.double().cpu().numpy() / len(train_dataset)) * 100\n",
    "            )\n",
    "            \n",
    "    \n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = (running_corrects.double() / len(train_dataset)) * 100\n",
    "    \n",
    "\n",
    "    # return running_loss, running_corrects\n",
    "    return train_loss, train_acc.cpu().numpy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCq8FAdOckD6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "YymBc1UtcnEA"
   },
   "outputs": [],
   "source": [
    "def test_model_progress(model, test_loader):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit = 'batch') as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                tepoch.set_description(f\"Validation: \")\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Set model to evaluation mode-\n",
    "                model.eval()\n",
    "            \n",
    "                # Predict using trained model-\n",
    "                outputs = model(images)\n",
    "                _, y_pred = torch.max(outputs, 1)\n",
    "                \n",
    "                # Compute validation loss-\n",
    "                J_val = loss(outputs, labels)\n",
    "                \n",
    "                running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "                # Total number of labels-\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total number of correct predictions-\n",
    "                correct += (y_pred == labels).sum()\n",
    "                \n",
    "                tepoch.set_postfix(\n",
    "                    val_loss = running_loss_val / len(test_dataset),\n",
    "                    val_acc = 100 * (correct.cpu().numpy() / total)\n",
    "                )\n",
    "            \n",
    "        \n",
    "    # return (running_loss_val, correct, total)\n",
    "    val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = (correct / total) * 100\n",
    "\n",
    "    return val_loss, val_acc.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load random weights from before-\n",
    "model = create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "model.load_state_dict(torch.load('ResNet18_dropout_random_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU (if available)-\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "OozQ7SF4st4U"
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer-\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0, momentum = 0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_lr_scheduler = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "NOytz_v9tPxV"
   },
   "outputs": [],
   "source": [
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.21batch/s, accuracy=16.4, loss=2.36]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.14batch/s, val_acc=10.1, val_loss=3.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 training loss = 2.3634, training accuracy = 16.40%, val_loss = 3.5946, val_accuracy = 10.05% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 3.5946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.10batch/s, accuracy=25.6, loss=1.96]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.38batch/s, val_acc=17.5, val_loss=2.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 training loss = 1.9554, training accuracy = 25.55%, val_loss = 2.5627, val_accuracy = 17.52% & LR = 0.0200\n",
      "\n",
      "Saving model with lowest val_loss = 2.5627\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:51<00:00,  7.53batch/s, accuracy=34.3, loss=1.73]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 15.88batch/s, val_acc=31.4, val_loss=2.02] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 training loss = 1.7319, training accuracy = 34.33%, val_loss = 2.0238, val_accuracy = 31.42% & LR = 0.0300\n",
      "\n",
      "Saving model with lowest val_loss = 2.0238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.10batch/s, accuracy=40.7, loss=1.57]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.30batch/s, val_acc=45, val_loss=1.48]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 training loss = 1.5747, training accuracy = 40.70%, val_loss = 1.4767, val_accuracy = 44.97% & LR = 0.0400\n",
      "\n",
      "Saving model with lowest val_loss = 1.4767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.01batch/s, accuracy=47.5, loss=1.41]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.68batch/s, val_acc=45.8, val_loss=1.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5 training loss = 1.4150, training accuracy = 47.51%, val_loss = 1.6270, val_accuracy = 45.80% & LR = 0.0500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.98batch/s, accuracy=54.6, loss=1.27]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.56batch/s, val_acc=56.3, val_loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6 training loss = 1.2696, training accuracy = 54.58%, val_loss = 1.2789, val_accuracy = 56.28% & LR = 0.0600\n",
      "\n",
      "Saving model with lowest val_loss = 1.2789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:53<00:00,  7.37batch/s, accuracy=58.8, loss=1.16]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.16batch/s, val_acc=56.7, val_loss=1.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7 training loss = 1.1555, training accuracy = 58.84%, val_loss = 1.2665, val_accuracy = 56.70% & LR = 0.0700\n",
      "\n",
      "Saving model with lowest val_loss = 1.2665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.40batch/s, accuracy=62.5, loss=1.07]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.10batch/s, val_acc=64.3, val_loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8 training loss = 1.0656, training accuracy = 62.46%, val_loss = 1.0349, val_accuracy = 64.28% & LR = 0.0800\n",
      "\n",
      "Saving model with lowest val_loss = 1.0349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=64.3, loss=1.02]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.46batch/s, val_acc=58.5, val_loss=1.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9 training loss = 1.0219, training accuracy = 64.31%, val_loss = 1.2453, val_accuracy = 58.53% & LR = 0.0900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.96batch/s, accuracy=65.9, loss=0.984] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.39batch/s, val_acc=70.3, val_loss=0.873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10 training loss = 0.9835, training accuracy = 65.85%, val_loss = 0.8730, val_accuracy = 70.27% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.8730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.39batch/s, accuracy=67.7, loss=0.938] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.09batch/s, val_acc=69.5, val_loss=0.878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 11 training loss = 0.9376, training accuracy = 67.67%, val_loss = 0.8780, val_accuracy = 69.47% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.03batch/s, accuracy=69, loss=0.911]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.61batch/s, val_acc=70.5, val_loss=0.872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 12 training loss = 0.9108, training accuracy = 68.96%, val_loss = 0.8716, val_accuracy = 70.52% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.8716\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=70, loss=0.875]   \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.33batch/s, val_acc=71.1, val_loss=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 13 training loss = 0.8749, training accuracy = 70.05%, val_loss = 0.8448, val_accuracy = 71.11% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.8448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.44batch/s, accuracy=71.1, loss=0.846] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.90batch/s, val_acc=71.5, val_loss=0.854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 14 training loss = 0.8458, training accuracy = 71.11%, val_loss = 0.8540, val_accuracy = 71.55% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.98batch/s, accuracy=71.8, loss=0.826] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.16batch/s, val_acc=74.2, val_loss=0.755] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 15 training loss = 0.8264, training accuracy = 71.82%, val_loss = 0.7554, val_accuracy = 74.21% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.7554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.40batch/s, accuracy=72.2, loss=0.816] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.69batch/s, val_acc=74, val_loss=0.78]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 16 training loss = 0.8160, training accuracy = 72.22%, val_loss = 0.7795, val_accuracy = 73.98% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.95batch/s, accuracy=73, loss=0.792]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.88batch/s, val_acc=73.4, val_loss=0.797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 17 training loss = 0.7920, training accuracy = 73.04%, val_loss = 0.7971, val_accuracy = 73.44% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.98batch/s, accuracy=73.2, loss=0.79]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.34batch/s, val_acc=72.5, val_loss=0.832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 18 training loss = 0.7896, training accuracy = 73.22%, val_loss = 0.8317, val_accuracy = 72.52% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.04batch/s, accuracy=73.8, loss=0.775] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.60batch/s, val_acc=74.8, val_loss=0.733] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 19 training loss = 0.7753, training accuracy = 73.76%, val_loss = 0.7325, val_accuracy = 74.84% & LR = 0.1000\n",
      "\n",
      "Saving model with lowest val_loss = 0.7325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.46batch/s, accuracy=73.8, loss=0.771] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.42batch/s, val_acc=72.6, val_loss=0.803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20 training loss = 0.7708, training accuracy = 73.75%, val_loss = 0.8031, val_accuracy = 72.64% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=74.4, loss=0.763] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.45batch/s, val_acc=68.7, val_loss=1.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 training loss = 0.7626, training accuracy = 74.36%, val_loss = 1.0631, val_accuracy = 68.71% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.18batch/s, accuracy=74.5, loss=0.754] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.99batch/s, val_acc=75.1, val_loss=0.738] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 22 training loss = 0.7536, training accuracy = 74.50%, val_loss = 0.7383, val_accuracy = 75.12% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.10batch/s, accuracy=74.3, loss=0.756] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.12batch/s, val_acc=74.9, val_loss=0.771] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 23 training loss = 0.7561, training accuracy = 74.31%, val_loss = 0.7706, val_accuracy = 74.94% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  6.99batch/s, accuracy=74.7, loss=0.747] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.12batch/s, val_acc=73.9, val_loss=0.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 24 training loss = 0.7472, training accuracy = 74.69%, val_loss = 0.7841, val_accuracy = 73.86% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:53<00:00,  7.30batch/s, accuracy=74.9, loss=0.74]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.58batch/s, val_acc=74.4, val_loss=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 25 training loss = 0.7403, training accuracy = 74.93%, val_loss = 0.7929, val_accuracy = 74.41% & LR = 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.00batch/s, accuracy=80.9, loss=0.567] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.26batch/s, val_acc=85.2, val_loss=0.437] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 26 training loss = 0.5666, training accuracy = 80.92%, val_loss = 0.4370, val_accuracy = 85.15% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.38batch/s, accuracy=82.7, loss=0.512] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.58batch/s, val_acc=85.3, val_loss=0.438] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 27 training loss = 0.5119, training accuracy = 82.67%, val_loss = 0.4380, val_accuracy = 85.30% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.01batch/s, accuracy=83.3, loss=0.494] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.23batch/s, val_acc=86.1, val_loss=0.412] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 28 training loss = 0.4944, training accuracy = 83.29%, val_loss = 0.4120, val_accuracy = 86.12% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:50<00:00,  7.74batch/s, accuracy=83.5, loss=0.483] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.40batch/s, val_acc=86.2, val_loss=0.411] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 29 training loss = 0.4834, training accuracy = 83.50%, val_loss = 0.4112, val_accuracy = 86.20% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.96batch/s, accuracy=84.3, loss=0.464] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.10batch/s, val_acc=86.4, val_loss=0.405] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 30 training loss = 0.4642, training accuracy = 84.32%, val_loss = 0.4048, val_accuracy = 86.38% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  6.98batch/s, accuracy=84.4, loss=0.457]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.38batch/s, val_acc=86.2, val_loss=0.403] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 31 training loss = 0.4569, training accuracy = 84.42%, val_loss = 0.4028, val_accuracy = 86.17% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.4028\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.47batch/s, accuracy=84.7, loss=0.45]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.26batch/s, val_acc=86.9, val_loss=0.395] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 32 training loss = 0.4503, training accuracy = 84.73%, val_loss = 0.3945, val_accuracy = 86.88% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=84.8, loss=0.443] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.21batch/s, val_acc=87.1, val_loss=0.384] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 33 training loss = 0.4430, training accuracy = 84.79%, val_loss = 0.3839, val_accuracy = 87.09% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.98batch/s, accuracy=85.2, loss=0.436]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.14batch/s, val_acc=87.1, val_loss=0.383] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 34 training loss = 0.4361, training accuracy = 85.15%, val_loss = 0.3829, val_accuracy = 87.14% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3829\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.48batch/s, accuracy=85.3, loss=0.429] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.35batch/s, val_acc=87, val_loss=0.381]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 35 training loss = 0.4286, training accuracy = 85.31%, val_loss = 0.3807, val_accuracy = 86.97% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.07batch/s, accuracy=85.5, loss=0.424]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.51batch/s, val_acc=87.2, val_loss=0.382] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 36 training loss = 0.4242, training accuracy = 85.51%, val_loss = 0.3820, val_accuracy = 87.23% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:53<00:00,  7.31batch/s, accuracy=85.6, loss=0.422]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.15batch/s, val_acc=86.5, val_loss=0.401] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 37 training loss = 0.4221, training accuracy = 85.56%, val_loss = 0.4014, val_accuracy = 86.45% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  6.99batch/s, accuracy=85.9, loss=0.419] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.63batch/s, val_acc=88.3, val_loss=0.352] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 38 training loss = 0.4190, training accuracy = 85.85%, val_loss = 0.3522, val_accuracy = 88.29% & LR = 0.0100\n",
      "\n",
      "Saving model with lowest val_loss = 0.3522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.07batch/s, accuracy=86.1, loss=0.409] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.70batch/s, val_acc=87.7, val_loss=0.367] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 39 training loss = 0.4093, training accuracy = 86.11%, val_loss = 0.3665, val_accuracy = 87.70% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=86.3, loss=0.402] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.46batch/s, val_acc=87.4, val_loss=0.369] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 40 training loss = 0.4021, training accuracy = 86.25%, val_loss = 0.3695, val_accuracy = 87.36% & LR = 0.0100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=87.3, loss=0.37]   \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 14.74batch/s, val_acc=88.9, val_loss=0.333] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 41 training loss = 0.3703, training accuracy = 87.32%, val_loss = 0.3334, val_accuracy = 88.88% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.3334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.41batch/s, accuracy=87.5, loss=0.362]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.50batch/s, val_acc=88.8, val_loss=0.332] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 42 training loss = 0.3622, training accuracy = 87.53%, val_loss = 0.3318, val_accuracy = 88.80% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.3318\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.00batch/s, accuracy=87.8, loss=0.359]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.21batch/s, val_acc=89.1, val_loss=0.325] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 43 training loss = 0.3593, training accuracy = 87.76%, val_loss = 0.3254, val_accuracy = 89.09% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.3254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.22batch/s, accuracy=87.9, loss=0.354] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 18.01batch/s, val_acc=89, val_loss=0.326]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 44 training loss = 0.3540, training accuracy = 87.91%, val_loss = 0.3258, val_accuracy = 89.01% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:56<00:00,  6.97batch/s, accuracy=87.8, loss=0.355]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.38batch/s, val_acc=89.1, val_loss=0.324] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 45 training loss = 0.3549, training accuracy = 87.83%, val_loss = 0.3242, val_accuracy = 89.15% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.3242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:50<00:00,  7.68batch/s, accuracy=88, loss=0.349]    \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.64batch/s, val_acc=88.8, val_loss=0.33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 46 training loss = 0.3491, training accuracy = 88.05%, val_loss = 0.3304, val_accuracy = 88.77% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.08batch/s, accuracy=87.9, loss=0.352]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.04batch/s, val_acc=89, val_loss=0.332]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 47 training loss = 0.3524, training accuracy = 87.91%, val_loss = 0.3318, val_accuracy = 88.97% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.48batch/s, accuracy=88.2, loss=0.345] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.14batch/s, val_acc=89.4, val_loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 48 training loss = 0.3447, training accuracy = 88.16%, val_loss = 0.3216, val_accuracy = 89.39% & LR = 0.0010\n",
      "\n",
      "Saving model with lowest val_loss = 0.3216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.02batch/s, accuracy=88.3, loss=0.342]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.18batch/s, val_acc=89.2, val_loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 49 training loss = 0.3422, training accuracy = 88.32%, val_loss = 0.3216, val_accuracy = 89.22% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.09batch/s, accuracy=88.3, loss=0.344] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.58batch/s, val_acc=89.2, val_loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 50 training loss = 0.3436, training accuracy = 88.33%, val_loss = 0.3220, val_accuracy = 89.25% & LR = 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.44batch/s, accuracy=88.4, loss=0.342] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.25batch/s, val_acc=89.3, val_loss=0.316] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 51 training loss = 0.3420, training accuracy = 88.37%, val_loss = 0.3159, val_accuracy = 89.35% & LR = 0.0001\n",
      "\n",
      "Saving model with lowest val_loss = 0.3159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  6.98batch/s, accuracy=88.5, loss=0.336]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.42batch/s, val_acc=89.5, val_loss=0.319] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 52 training loss = 0.3365, training accuracy = 88.48%, val_loss = 0.3186, val_accuracy = 89.46% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=88.3, loss=0.338]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 15.85batch/s, val_acc=89.4, val_loss=0.318] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 53 training loss = 0.3377, training accuracy = 88.32%, val_loss = 0.3183, val_accuracy = 89.42% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.46batch/s, accuracy=88.4, loss=0.337] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.47batch/s, val_acc=89.3, val_loss=0.319] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 54 training loss = 0.3374, training accuracy = 88.44%, val_loss = 0.3187, val_accuracy = 89.34% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.05batch/s, accuracy=88.6, loss=0.333]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.44batch/s, val_acc=89.4, val_loss=0.317] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 55 training loss = 0.3331, training accuracy = 88.60%, val_loss = 0.3174, val_accuracy = 89.42% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.10batch/s, accuracy=88.7, loss=0.333] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 15.90batch/s, val_acc=89.4, val_loss=0.318] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 56 training loss = 0.3331, training accuracy = 88.66%, val_loss = 0.3181, val_accuracy = 89.37% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:51<00:00,  7.57batch/s, accuracy=88.5, loss=0.332] \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.76batch/s, val_acc=89.5, val_loss=0.32]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 57 training loss = 0.3322, training accuracy = 88.50%, val_loss = 0.3204, val_accuracy = 89.45% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:55<00:00,  7.09batch/s, accuracy=88.7, loss=0.331]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.46batch/s, val_acc=89.4, val_loss=0.318] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 58 training loss = 0.3309, training accuracy = 88.71%, val_loss = 0.3181, val_accuracy = 89.41% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.23batch/s, accuracy=88.5, loss=0.334]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 18.25batch/s, val_acc=89.5, val_loss=0.317] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 59 training loss = 0.3343, training accuracy = 88.49%, val_loss = 0.3173, val_accuracy = 89.49% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.21batch/s, accuracy=88.5, loss=0.336] \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 16.05batch/s, val_acc=89.4, val_loss=0.318] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 60 training loss = 0.3365, training accuracy = 88.54%, val_loss = 0.3182, val_accuracy = 89.38% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:50<00:00,  7.70batch/s, accuracy=88.6, loss=0.333]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 18.42batch/s, val_acc=89.3, val_loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 61 training loss = 0.3329, training accuracy = 88.62%, val_loss = 0.3217, val_accuracy = 89.35% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.16batch/s, accuracy=88.5, loss=0.333]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.11batch/s, val_acc=89.4, val_loss=0.319] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 62 training loss = 0.3330, training accuracy = 88.53%, val_loss = 0.3194, val_accuracy = 89.43% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.12batch/s, accuracy=88.6, loss=0.335]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 15.83batch/s, val_acc=89.5, val_loss=0.316] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 63 training loss = 0.3347, training accuracy = 88.56%, val_loss = 0.3164, val_accuracy = 89.45% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:54<00:00,  7.22batch/s, accuracy=88.4, loss=0.335]  \n",
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 17.86batch/s, val_acc=89.6, val_loss=0.316] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 64 training loss = 0.3348, training accuracy = 88.40%, val_loss = 0.3160, val_accuracy = 89.60% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: : 100%|██████████| 391/391 [00:52<00:00,  7.41batch/s, accuracy=88.4, loss=0.336]  \n",
      "Validation: : 100%|██████████| 79/79 [00:05<00:00, 15.57batch/s, val_acc=89.4, val_loss=0.319] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 65 training loss = 0.3361, training accuracy = 88.41%, val_loss = 0.3188, val_accuracy = 89.44% & LR = 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss, train_acc = train_model_progress(model, train_loader)\n",
    "    val_loss, val_acc = test_model_progress(model, test_loader)\n",
    "    \n",
    "    print(f\"\\nepoch: {epoch + 1} training loss = {train_loss:.4f}, \"\n",
    "          f\"training accuracy = {train_acc:.2f}%, val_loss = {val_loss:.4f}\"\n",
    "          f\", val_accuracy = {val_acc:.2f}% & \"\n",
    "          f\"LR = {optimizer.param_groups[0]['lr']:.4f}\\n\")\n",
    "    \n",
    "    training_history_lr_scheduler[epoch + 1] = {\n",
    "        'loss': train_loss, 'acc': train_acc,\n",
    "        'val_loss': val_loss, 'val_acc': val_acc,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Save best weights achieved until now-\n",
    "    if (val_loss < best_val_loss):    \n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        print(f\"Saving model with lowest val_loss = {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with 'best' validation accuracy-\n",
    "        torch.save(model.state_dict(), \"ResNet18_lr_schedule_best_model.pth\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model from last training epoch if it's better than 'best' model-\n",
    "# torch.save(model.state_dict(), \"ResNet18_last_epoch_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load 'best' model achieved so far-\n",
    "best_model = create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load randomly initialised weights-\n",
    "best_model.load_state_dict(torch.load('ResNet18_lr_schedule_best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU (if available)-\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: : 100%|██████████| 79/79 [00:04<00:00, 18.49batch/s, val_acc=89.3, val_loss=0.316] \n"
     ]
    }
   ],
   "source": [
    "# Compute performance of 'best' model on validation data-\n",
    "val_loss, val_acc = test_model_progress(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-18 'best' model (dropout) metrics: val_loss = 0.3159 & val_acc = 89.35%\n"
     ]
    }
   ],
   "source": [
    "print(f\"ResNet-18 'best' model (dropout) metrics: val_loss = {val_loss:.4f} & val_acc = {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "For this particular experiment, it seems that using ```val_loss``` as the metric to save the _best_ model is not the optimum choice.\n",
    "\n",
    "_Highest validation accuracy_ achieved = 90.29%.\n",
    "\n",
    "_Dropout_ controls the overfitting nicely as the difference training and validation metrics are quite close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "training_history_lr_scheduler.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history_lr_scheduler[12].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metrics as Python3 history for later analysis-\n",
    "with open(\"ResNet18_dropout_training_history_lr_scheduler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_history_lr_scheduler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['acc'] for k in training_history_lr_scheduler.keys()], label = 'training acc')\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['val_acc'] for k in training_history_lr_scheduler.keys()], label = 'val acc')\n",
    "plt.title(\"ResNet-18: (Dropout) Training Accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy (%)\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAG5CAYAAABLHaTAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABQzUlEQVR4nO3dd3hc5Z328e9vijTqsmVJrnLDBndjDJhmagidBAiBUPMmEBKSTTYbNm1DSHYTsumbACEQSGBTgKX3Gmx6sY0LYGMb9ybLRb3PPO8f58gay2q2NZqRdH+ua64zc84zZ545FujW04455xARERFJNYFkV0BERESkPQopIiIikpIUUkRERCQlKaSIiIhISlJIERERkZSkkCIiIiIpSSFFRPZhZjeb2TeSXY+eYmYPm9kZvfA5JWZWbWbBniwrMlAppMiAZWbrzKzO/0Wxzcz+YmbZB3nOq83MmdkNbfZvMrOTuvH+Mf77Q12U+08zW2ZmzWZ2UzvHv2Zma82s0swWmNnx+/EdCoErgT/6r08ys5h/nar97/KAmR3Z3XP2JjO7ycz+2mb3z4CfdFD+srjvVtfmu1bvz2c75zY457Kdc9GeLLu//J/l/+rp84r0NoUUGejOdc5lAzOBw4Hv9sA5dwHfNrPcHjhXR1YD/w481faAmR2N90v5IiAPuAt4ZD/+Yr8aeNo5Vxe3b4t/nXKAOcAK4FUzO7W9E3QVsnqbc+4dINfMZrdz7G9+WMgGzsT/rnH79lCrh0jvUkgRAZxz24Dn8MIKAGY2x8zeMLNyM1sS3xLit5isMbMqv8XisrjTLQfeBP61vc8ys4CZfcfMPjaznX6rxGD/8Cv+ttz/S/6YDup7j3PuGaCqncNjgA+ccwudt6T0vcAQoKjLC+E5E5jfwec659wm59yNwJ+A/477Xs7MrjezVcAqf981ZrbazHaZ2eNmNrxN+X/xr+MOM/uFmQXirtF/mNl6M9tuZveaWZ5/7CQz2xRfL79V7DS/S+d7wGf967ckrtg84OxuXoOW8/7FzP5gZk+bWQ1wspmdbWbv+a1UG+Nbstq2hJnZPL/V63X/Z+V5Mxuyv2X941f612Onmf2g5Tvvz/fxz9Puv4l5fuNf7wozW2pmU/1jZ5nZh369NpvZt/b3c0UOhEKKCGBmI/F+Oa/2X4/Aa6X4L2Aw8C3gITMrNLMs4HfAmc65HOBYYHGbU/4A+Ne48BHvX4BPAScCw4HdwK3+sbn+Nt//S/7NA/g6zwBBMzva/8v///n12+Z/t++Y2ZOdvH8a8FE3PudhYJZ/PVp8CjgamGxmpwA3AxcDw4D1wH1tzvFpYDYwCzjfryt4rTlXAycD44Bs4JauKuScexb4KXC/f/1mxB1eDsxo/52d+hxeV1EO8BpQg9cdlo8Xer5sZp/q4v2fxwuJaXg/S/tV1swmA7cBl+FdyzxgxP5+kS7+TU7H+/mb6H+3zwI7/WN3AV/yf96nAv/c388WORAKKTLQPWpmVcBGYDvwQ3//5XhdHk8752LOuReABcBZ/vEYMNXMMpxzW51zH8Sf1Dm3GHge+HY7n/kl4Pt+i0QDcBNwUQ92kVQBD+H9Qm3wv9O1fqsKzrmfOefO6eT9+bTfQtPWFsD88i1uds7t8ruKLgPuds4t8r/nd4FjzGxMXPn/9stvAH4LXOrvvwz4tXNujXOu2n/vJQd5jara1LW7HnPOve7/HNQ75+Y555b5r5cC/8ALnB35s3NupX9NHiCutW4/yl4EPOGce8051wjcCBzIjdc6+zdpwgtihwHmnFvunNvqv68JL3jmOud2O+cWHcBni+w3hRQZ6D7l/3V4Et7/nFua10cDn/G7esrNrBw4HhjmnKvB+yvzOmCrmT1lZoe1c+4b8f7KHtpm/2i8MSIt510ORIHi9ipoZh9Y60DOE7rxnb6I1yIxBe+v8cuBJ+O7WrqwG++XVVdG4P2iLI/btzHu+XC8v9QB8MPGTvZuAYgvv95/zz7v9Z+H6OAadVNOm7p2V3wd8VuoXjazMjOrwPs5GNL+WwG/BctXi9cqtL9lh8fXwzlXS2srx/7o8N/EOfdPvNaqW4FSM7vDWsdVXYgX0Neb2XzroBtSpKcppIgAzrn5wF+AX/q7NgL/65zLj3tkOed+5pd/zjn3Cbwm8xXAne2ccwVel8j32hzaiNdVFH/uiHNuM+38deycmxI3kPPVbnydGXh/da/0/9p/FtiK1y3VHUvxmvy78mlgkR/a9lQ37vkWvEAGgN8tVABsjiszKu55if+efd7rH2sGSvG6WzLjzhsECjuoQ7xJwJIOjnWm7fn+DjwOjHLO5QG347UoJdJWYGTLCzPLwLuW+6vTfxPn3O+cc0fgBdyJwA3+/nedc+fjdUM9itfKI5JwCikirX4LfMLMZgJ/Bc41s0+aWdDMIv6AzZFmVmxm5/n/g28AqvFaQtrzI7wxBvlx+24HfmJmo8Gb8mtm5/vHyvC6ksZ1VlEzC5tZBO+/4ZBfv5aZJ+8CZ5vZOH8w5CfwfuG8383r8DQddF/45xthZj/Ea7FpG8Di/R34vJnNNLN0vLEibzvn1sWVucHMBpnZKODrwP3+/n/gjekZa9608JZxJs3ASiBi3gDWMPAfQHrcOUuBMeYPwo1zIt54nYOVA+xyztWb2VF440gS7UG8n8djzSwN7+eqq2DU8nPb8kijk38TMzvSbyUK4wXBeiBqZmnmTdPOc841AZV0/PMu0qMUUkR8zrkyvJkwP3DObcQbyPk9vOCwEe+vyoD/+De8v0p34f3y+0oH51wL/C8QP7j0f/D+En/eHw/zFt5g05Zm/J8Ar/vdQXM6qO6dQB3eGI7v+8+v8I/dizcYch7eL5Tf4Q16XAFgZt8zs85+Wd8LnOX/td5iuHlrhlTjhaBpwEnOuec7Oolz7iW8AcQP4bUEjAcuaVPsMWAh3sDep/AGaALcjXfdXgHW4v3C/Jp/3gq86/0nvBaAGiB+ts//+dudZrbI/85HAjX+VOSD9RXgx/6/3Y30QquCP+bpa3j/rlvxxtdsxwvJHfkO3s9Fy+OfXfyb5OL9XO3G6xLaSWvL4hXAOjOrxOveurynvptIZ8wfSycisoeZ/RTY7pz7bQI/wwETnHOrE/UZcZ/1EHCXc+7pRH9Wb/Bbl8rxrt/aJFdHJGEUUkQkKXozpPQHZnYu8BJeN8+v8FrfZjn9T1z6MXX3iIj0DefjdTFuASYAlyigSH+nlhQRERFJSWpJERERkZSUUjcB644hQ4a4MWPGJLsaIiIi0gMWLly4wzlX2N6xPhdSxowZw4IFC5JdDREREekBZra+o2Pq7hEREZGUpJAiIiIiKUkhRURERFJSnxuTIiIiciCamprYtGkT9fX1ya7KgBSJRBg5ciThcLjb71FIERGRAWHTpk3k5OQwZswYzBJ942qJ55xj586dbNq0ibFjx3b7feruERGRAaG+vp6CggIFlCQwMwoKCva7FUshRUREBgwFlOQ5kGuvkCIiIiIpSSFFRESkF5SXl3Pbbbcd0HvPOussysvLOy1z44038uKLLx7Q+dsaM2YMO3bs6JFzHQyFFBERkV7QWUiJRqOdvvfpp58mPz+/0zI//vGPOe200w60eilJIUVERKQXfOc73+Hjjz9m5syZ3HDDDcybN4+TTz6Zz33uc0ybNg2AT33qUxxxxBFMmTKFO+64Y897W1o21q1bx6RJk7jmmmuYMmUKp59+OnV1dQBcffXVPPjgg3vK//CHP2TWrFlMmzaNFStWAFBWVsYnPvEJZs2axZe+9CVGjx7dZYvJr3/9a6ZOncrUqVP57W9/C0BNTQ1nn302M2bMYOrUqdx///17vuPkyZOZPn063/rWtw76mmkKsoiIDDg/euIDPtxS2aPnnDw8lx+eO6XD4z/72c94//33Wbx4MQDz5s3jnXfe4f33398zLffuu+9m8ODB1NXVceSRR3LhhRdSUFCw13lWrVrFP/7xD+68804uvvhiHnroIS6//PJ9Pm/IkCEsWrSI2267jV/+8pf86U9/4kc/+hGnnHIK3/3ud3n22Wf3CkLtWbhwIX/+8595++23cc5x9NFHc+KJJ7JmzRqGDx/OU089BUBFRQW7du3ikUceYcWKFZhZl91T3aGWFBERkSQ56qij9lo35He/+x0zZsxgzpw5bNy4kVWrVu3znrFjxzJz5kwAjjjiCNatW9fuuS+44IJ9yrz22mtccsklAJxxxhkMGjSo0/q99tprfPrTnyYrK4vs7GwuuOACXn31VaZNm8aLL77It7/9bV599VXy8vLIzc0lEonwxS9+kYcffpjMzMz9vBr7UkuKiIgMOJ21ePSmrKysPc/nzZvHiy++yJtvvklmZiYnnXRSu+uKpKen73keDAb3dPd0VC4YDNLc3Ax4i6rtj47KT5w4kYULF/L000/z3e9+l9NPP50bb7yRd955h5deeon77ruPW265hX/+85/79XltqSWlRflG2LE62bUQEZF+Kicnh6qqqg6PV1RUMGjQIDIzM1mxYgVvvfVWj9fh+OOP54EHHgDg+eefZ/fu3Z2Wnzt3Lo8++ii1tbXU1NTwyCOPcMIJJ7BlyxYyMzO5/PLL+da3vsWiRYuorq6moqKCs846i9/+9rd7urUOhlpSWjz+VWishS++kOyaiIhIP1RQUMBxxx3H1KlTOfPMMzn77LP3On7GGWdw++23M336dA499FDmzJnT43X44Q9/yKWXXsr999/PiSeeyLBhw8jJyemw/KxZs7j66qs56qijAPjiF7/I4YcfznPPPccNN9xAIBAgHA7zhz/8gaqqKs4//3zq6+txzvGb3/zmoOtr+9v0k2yzZ892CxYs6PkTP3AlbF8OX323588tIiJJt3z5ciZNmpTsaiRVQ0MDwWCQUCjEm2++yZe//OUeafHorvb+DcxsoXNudnvl1ZLSIpIPdeXJroWIiEjCbNiwgYsvvphYLEZaWhp33nlnsqvUKYWUFhn5UF+R7FqIiIgkzIQJE3jvvfeSXY1u08DZFpF8iDZAU/ujpEVERKR3KaS0iOR5W3X5iIiIpASFlBYZ+d62vjyZtRARERFfwkKKmUXM7B0zW2JmH5jZj9opc5KZVZjZYv9xY6Lq06VIvrfVuBQREZGUkMiBsw3AKc65ajMLA6+Z2TPOubar07zqnDsngfXonpaWFHX3iIhIisjOzqa6urrb+/ubhIUU5y3A0nIFw/4jdRdl2dOSUp7MWoiIiIgvoWNSzCxoZouB7cALzrm32yl2jN8l9IyZJe9mCi0hRS0pIiKSAN/+9re57bbb9ry+6aab+NWvfkV1dTWnnnoqs2bNYtq0aTz22GPdPqdzjhtuuIGpU6cybdo07r//fgC2bt3K3LlzmTlzJlOnTuXVV18lGo1y9dVX7ynbEyvCJlpC10lxzkWBmWaWDzxiZlOdc+/HFVkEjPa7hM4CHgUmtD2PmV0LXAtQUlKSmMq2zO7RmBQRkf7vme/AtmU9e86h0+DMn3V4+JJLLuEb3/gGX/nKVwB44IEHePbZZ4lEIjzyyCPk5uayY8cO5syZw3nnnYeZdfmRDz/8MIsXL2bJkiXs2LGDI488krlz5/L3v/+dT37yk3z/+98nGo1SW1vL4sWL2bx5M++/7/0aLi8v75GvnUi9MrvHOVcOzAPOaLO/0jlX7T9/Ggib2ZB23n+Hc262c252YWFhYioZDEFajrp7REQkIQ4//HC2b9/Oli1bWLJkCYMGDaKkpATnHN/73veYPn06p512Gps3b6a0tLRb53zttde49NJLCQaDFBcXc+KJJ/Luu+9y5JFH8uc//5mbbrqJZcuWkZOTw7hx41izZg1f+9rXePbZZ8nNzU3wNz54CWtJMbNCoMk5V25mGcBpwH+3KTMUKHXOOTM7Ci807UxUnbqUka/uHhGRgaCTFo9Euuiii3jwwQfZtm0bl1xyCQB/+9vfKCsrY+HChYTDYcaMGUN9fX23ztfR/ffmzp3LK6+8wlNPPcUVV1zBDTfcwJVXXsmSJUt47rnnuPXWW3nggQe4++67e+y7JUIiu3uGAfeYWRAvfDzgnHvSzK4DcM7dDlwEfNnMmoE64BKXzDseRvLUkiIiIglzySWXcM0117Bjxw7mz58PQEVFBUVFRYTDYV5++WXWr1/f7fPNnTuXP/7xj1x11VXs2rWLV155hV/84hesX7+eESNGcM0111BTU8OiRYs466yzSEtL48ILL2T8+PFcffXVCfqWPSeRs3uWAoe3s//2uOe3ALckqg77TTcZFBGRBJoyZQpVVVWMGDGCYcOGAXDZZZdx7rnnMnv2bGbOnMlhhx3W7fN9+tOf5s0332TGjBmYGT//+c8ZOnQo99xzD7/4xS8Ih8NkZ2dz7733snnzZj7/+c8Ti8UAuPnmmxPyHXuSJbPh4kDMnj3bLViwIDEnv+8y2LUWvvJGYs4vIiJJs3z5ciZNmpTsagxo7f0bmNlC59zs9sprWfx4kXx194iIiKQIhZR4kTx194iIiKQIhZR4GfnQVAPRpmTXREREEqCvDXHoTw7k2iukxNNNBkVE+q1IJMLOnTsVVJLAOcfOnTuJRCL79b6Erjjb58TfZDBrnzXlRESkDxs5ciSbNm2irKws2VUZkCKRCCNHjtyv9yikxNNNBkVE+q1wOMzYsWOTXQ3ZD+ruiddy/x4NnhUREUk6hZR4Ld09akkRERFJOoWUeOruERERSRkKKfHU3SMiIpIyFFLihSMQiqglRUREJAUopLSlmwyKiIikBIWUtjLytZibiIhIClBIaUs3GRQREUkJCilt6SaDIiIiKUEhpa2MfLWkiIiIpACFlLYi+RqTIiIikgIUUtrKyIf6SojFkl0TERGRAU0hpa1IPuCgQa0pIiIiyaSQ0pZWnRUREUkJCilt7bnJoFpSREREkkkhpS3dZFBERCQlKKS01dKSou4eERGRpFJIaatlTIpaUkRERJJKIaWtlu4etaSIiIgklUJKW2lZEAhp4KyIiEiSKaS0ZaabDIqIiKQAhZT2ZOSru0dERCTJFFLaE8lTS4qIiEiSKaS0RzcZFBERSTqFlPaou0dERCTpFFLao4GzIiIiSaeQ0p5InteS4lyyayIiIjJgKaS0JyMfXBQaa5JdExERkQFLIaU9usmgiIhI0imktEc3GRQREUk6hZT26CaDIiIiSaeQ0h7dZFBERCTpFFLa09LdowXdREREkkYhpT0aOCsiIpJ0CintSc8FTN09IiIiSaSQ0p5AACK5akkRERFJIoWUjugmgyIiIkmVsJBiZhEze8fMlpjZB2b2o3bKmJn9zsxWm9lSM5uVqPrsN91kUEREJKlCCTx3A3CKc67azMLAa2b2jHPurbgyZwIT/MfRwB/8bfLpJoMiIiJJlbCWFOep9l+G/UfbO/adD9zrl30LyDezYYmq035pucmgiIiIJEVCx6SYWdDMFgPbgRecc2+3KTIC2Bj3epO/r+15rjWzBWa2oKysLGH13UtGvlpSREREkiihIcU5F3XOzQRGAkeZ2dQ2Ray9t7Vznjucc7Odc7MLCwsTUNN2aOCsiIhIUvXK7B7nXDkwDzijzaFNwKi41yOBLb1Rpy5l5ENzPTTVJ7smIiIiA1IiZ/cUmlm+/zwDOA1Y0abY48CV/iyfOUCFc25rouq0X7TqrIiISFIlcnbPMOAeMwvihaEHnHNPmtl1AM6524GngbOA1UAt8PkE1mf/tNwJua4ccoYmtSoiIiIDUcJCinNuKXB4O/tvj3vugOsTVYeDopsMioiIJJVWnO1IZJC3VXePiIhIUiikdKSlJUVrpYiIiCSFQkpHWsakqCVFREQkKRRSOrInpGhMioiISDIopHQkGIa0bHX3iIiIJIlCSmd0k0EREZGkUUjpTEa+WlJERESSRCGlM5E8taSIiIgkiUJKZ3STQRERkaRRSOmMuntERESSRiGlMxo4KyIikjQKKZ2J5EFjNUSbkl0TERGRAUchpTN7bjJYmdRqiIiIDEQKKZ2J5HtbdfmIiIj0OoWUzugmgyIiIkmjkNKZPffv2Z3ceoiIiAxACimd2dPdo7VSREREeptCSmfU3SMiIpI0Cimd0cBZERGRpFFI6Uw4AqGIWlJERESSQCGlK7rJoIiISFIopHRFNxkUERFJCoWUrugmgyIiIkmhkNIV3WRQREQkKRRSuhLJU0uKiIhIEiikdCUjX2NSREREkkAhpSstA2djsWTXREREZEBRSOlKRj7goKEy2TUREREZUBRSuqJVZ0VERJJCIaUre+6ErHEpIiIivUkhpSu6yaCIiEhSKKR0Rd09IiIiSaGQ0hW1pIiIiCSFQkpX9oxJKU9qNURERAYahZSupGWDBTVwVkREpJcppHTFTDcZFBERSQKFlO7QTQZFRER6nUJKd+gmgyIiIr1OIaU7dJNBERGRXqeQ0h3q7hEREel1CindkTkYancmuxYiIiIDikJKd+SNhLrd0FCd7JqIiIgMGAop3ZFf4m3LNyS3HiIiIgOIQkp35I/2tgopIiIivSZhIcXMRpnZy2a23Mw+MLOvt1PmJDOrMLPF/uPGRNXnoKglRUREpNeFEnjuZuDfnHOLzCwHWGhmLzjnPmxT7lXn3DkJrMfByyqEUAaUr092TURERAaMhLWkOOe2OucW+c+rgOXAiER9XkKZea0pakkRERHpNb0yJsXMxgCHA2+3c/gYM1tiZs+Y2ZQO3n+tmS0wswVlZWWJrGrHFFJERER6VcJDipllAw8B33DOVbY5vAgY7ZybAfweeLS9czjn7nDOzXbOzS4sLExofTukkCIiItKrEhpSzCyMF1D+5px7uO1x51ylc67af/40EDazIYms0wHLL4G6XdBQleyaiIiIDAiJnN1jwF3AcufcrzsoM9Qvh5kd5dcnNZd21QwfERGRXpXI2T3HAVcAy8xssb/ve0AJgHPuduAi4Mtm1gzUAZc451wC63Tg4tdKKW536IyIiIj0oISFFOfca4B1UeYW4JZE1aFHqSVFRESkV2nF2e7KGgLhTIUUERGRXqKQ0l171krRgm4iIiK9QSFlf2gasoiISK9RSNkf+SWwWy0pIiIivUEhZX/kl0B9OdRXJLsmIiIi/Z5Cyv7YM8NnY3LrISIiMgAopOwPTUMWERHpNQopvhXbKlmwblfnheIXdBMREZGEUkjx/eeTH/KfT37YeaHMAq2VIiIi0ksUUnwTinJYtb2aWKyTVfm1VoqIiEivUUjxTSjOprYxypaKus4L5o9WS4qIiEgvUEjxTSzOAWBVaXXnBdWSIiIi0isUUnwTirIBWLW9qvOC+SXeOil15YmvlIiIyACmkOLLz0yjMCe9ey0pABVaK0VERCSRFFLiTCjKZuX2boYUjUsRERFJKIWUOBOKslldWoVznczw0VopIiIivUIhJc6E4hxqGqNsqajvuFDmYAhnKaSIiIgkmEJKnD2DZ0s7GTy7Z60UhRQREZFEUkiJ0+1pyINGaxqyiIhIgimkxBmUlcaQ7LTuTUPerZYUERGRRFJIaWNCUQ4ruzMNuUFrpYiIiCSSQkobE4qzWb29uosZPpqGLCIikmgKKW1MKMqmuqGZbZWdzPBRSBEREUk4hZQ2JviDZzvt8tFaKSIiIgmnkNJGt6YhZwyCtGyFFBERkQRSSGmjIDudgqy0zqcha60UERGRhFNIacchRdndmIastVJEREQSSSGlHROLc1hV2o0ZPuUboLMyIiIicsAUUtoxoTibqoZmSisbOi6UXwINlVBf3mv1EhERGUgUUtoxochfHr+zLh9NQxYREUkohZR2TCj2Zvh0Pg1ZIUVERCSRFFLaUZCVxqDMMKvVkiIiIpI0CintMDMmFHdxD5+MQZCWo5AiIiKSIAopHZhQlM2q0qqOZ/horRQREZGEUkjpwMTiHCrrm9le1cUMn91aK0VERCQRFFI60Lo8fiddPoNGa60UERGRBFFI6UDLjQa7nIbcWAV1u3upViIiIgOHQkoHhmSnkZ8Z1jRkERGRJFFI6YCZMaEoW9OQRUREkkQhpRMt05A7nOGjkCIiIpIwCimdmFCUTUVdE2XVHczwieRDeq5CioiISAIopHRiYsvg2Y7GpWitFBERkYRRSOlE6zTkLsallGutFBERkZ6mkNKJwpx08jLCrNre2QwfrZUiIiKSCAkLKWY2ysxeNrPlZvaBmX29nTJmZr8zs9VmttTMZiWqPgeiZYZPpwu65ZdAY7XWShEREelh3QopZvZ1M8v1Q8VdZrbIzE7v4m3NwL855yYBc4DrzWxymzJnAhP8x7XAH/az/gk3oTiblds7uYdP/ihvq3EpIiIiPaq7LSn/zzlXCZwOFAKfB37W2Rucc1udc4v851XAcmBEm2LnA/c6z1tAvpkN258vkGgTinIor21iR3Vj+wU0DVlERCQhuhtSzN+eBfzZObckbl/XbzYbAxwOvN3m0AhgY9zrTewbZDCza81sgZktKCsr6+7H9ogJxf7g2Y4WdctTS4qIiEgidDekLDSz5/FCynNmlgPEuvNGM8sGHgK+4bfG7HW4nbfs06/inLvDOTfbOTe7sLCwm1XuGV1OQ84YBGk5ULGx/eMiIiJyQELdLPcFYCawxjlXa2aD8bp8OmVmYbyA8jfn3MPtFNkEjIp7PRLY0s069YqinHRyIqGOW1K0VoqIiEhCdLcl5RjgI+dcuZldDvwHUNHZG8zMgLuA5c65X3dQ7HHgSn9A7hygwjm3tZt16hVmxsTinC5m+IxSSBEREelh3Q0pfwBqzWwG8O/AeuDeLt5zHHAFcIqZLfYfZ5nZdWZ2nV/maWANsBq4E/jKfn+DXjCxOJvlWytpjnbQw5VfAuXq7hEREelJ3e3uaXbOOTM7H/gf59xdZnZVZ29wzr1GF4NrnTev9/pu1iFpjj+kkH+8s5FFG8o5auzgfQvkl0BDBdSVQ0Z+b1dPRESkX+puS0qVmX0Xr2XkKTMLAuHEVSu1zJ04hHDQeHF5afsFNMNHRESkx3U3pHwWaMBbL2Ub3jThXySsVikmJxJmzriCjkNKy1opmuEjIiLSY7oVUvxg8jcgz8zOAeqdc12NSelXTj2siDVlNawpa2cArRZ0ExER6XHdXRb/YuAd4DPAxcDbZnZRIiuWak6dVAzAS8u373swswDCmRo8KyIi0oO6293zfeBI59xVzrkrgaOAHySuWqln1OBMDhua036Xz561Utb3fsVERET6qe6GlIBzLr4JYed+vLffOG1SMQvW76a8tp37+ORprRQREZGe1N2g8ayZPWdmV5vZ1cBTeGucDCinTioiGnPM+6id+wfll2jgrIiISA/q7sDZG4A7gOnADOAO59y3E1mxVDRjZD5DstN5ob0un/wSqNsN9W1vTyQiIiIHoruLueGcewjvPjwDViBgnHpYEU8v20pjc4y0UFzGy/fXSqnYCJEpyamgiIhIP9JpS4qZVZlZZTuPKjMbkE0Gp00upqqhmXfW7tr7QP5ob6sZPiIiIj2i05YU51xOb1Wkrzj+kCGkhwK8uLyU4ycMaT2gVWdFRER61ICboXOwMtKCHH/IEF5aUYp36yFfdhGEIlChkCIiItITFFIOwKmTitm4q46VpXGrz5ppGrKIiEgPUkg5AKdOKgLYd2G3fIUUERGRnqKQcgCKcyNMH5nXTkgp0cBZERGRHqKQcoBOm1TM4o3l7KhuaN2ZXwK1O6CxJnkVExER6ScUUg7QqZOKcA7+uSLubgF5LXdDVmuKiIjIwVJIOUCTh+UyPC/Cix/Gdfnk+yFFy+OLiIgcNIWUA2RmnDqpmFdX7aC+KertbAkpuhuyiIjIQVNIOQinTiqirinKmx/v9HZkF0MwTTN8REREeoBCykE4ZnwBWWnB1lk+gQDkjdSYFBERkR6gkHIQ0kNBTphQyEvLtxOL+avPakE3ERGRHqGQcpDOnDaUbZX1vLp6h7cjv0QDZ0VERHqAQspBOnPqMApz0vnL62u9HfmjoboUmuqSWzEREZE+TiHlIKWFAlx2dAkvf1TG2h013tL4ABWbklsxERGRPk4hpQd87ugSwkHjnjfWxU1D1rgUERGRg6GQ0gOKciKcM304Dy7cRHXGcG+nQoqIiMhBUUjpIVcfO4bqhmYeXNkMgZBCioiIyEFSSOkhM0blc3hJPn95cyMud4Rm+IiIiBwkhZQe9PnjxrJuZy3laUPVkiIiInKQFFJ60JlTh1Kcm86ymjytOisiInKQFFJ6UDgY4PKjR7OwPAdXtRWaG5JdJRERkT5LIaWHXXp0CdusEMN1vlZKcwO89huor+y9yomIiPQhCik9bEh2OqPHTwKgpmxdxwXf+1948Sb44JFeqZeIiEhfo5CSAKfMmQ3AoiVL2i8Qi8Gbt3nPty3tpVqJiIj0LQopCXDYxEOJEmDNqg+JttwdOd7KZ2DXxxDKgK0KKSIiIu1RSEmEYJiGjGKyG7by8ort+x5/4xbIK4FZV8C2ZRCL9n4dRUREUpxCSoJECscwLrSLv7yxbu8DmxbChjdgzpdhxBHQXAc7ViWljiIiIqlMISVBAvmjOSRtJ6+t3sGq0qrWA2/+HtLzvFaUYTO8fVs7GLsiIiIygCmkJEp+CdmNZWSGYtz75npv3+718OFjcMRVkJ4DBRMgFNHgWRERkXYopCRK/ijMxbjssBAPLdpEZX0TvH07WACOvs4rEwxB8VS1pIiIiLRDISVR8ksAuHSiUdsY5Ym3PoRF98KUCyBvRGu5YTO8GT6unVlAIiIiA5hCSqL4IWVceCeHl+RT/cZd0FgNx35173LDpkNDBexe1/t1FBERSWEJCylmdreZbTez9zs4fpKZVZjZYv9xY6LqkhS5IwGD8g1cffRwzmt4gvLiOa2DZVto8KyIiEi7EtmS8hfgjC7KvOqcm+k/fpzAuvS+UBrkDIOKjZwdeIthtot73Dn7liuaDIGQQoqIiEgbCQspzrlXgF2JOn+fkF8Cu9cTevtWdmaM5X82jmHDztq9y4TSoXCSQoqIiEgbyR6TcoyZLTGzZ8xsSpLr0vPyR8HGt2DbMkLHfZWABfnr2+v3LTdshhdSNHhWRERkj2SGlEXAaOfcDOD3wKMdFTSza81sgZktKCsr6636Hbz8Eog1Q1YheUdfzienDuX+dzdS19hmGfxhM6B2B1RtTU49RUREUlDSQopzrtI5V+0/fxoIm9mQDsre4Zyb7ZybXVhY2Kv1PCh5o7ztkddAOMJVx4yhoq6JxxZv3rucBs+KiIjsI2khxcyGmpn5z4/y67IzWfVJiPGnwOTz4ahrADhyzCAOG5rDX95Yh4vv2imeApjuiCwiIhInkVOQ/wG8CRxqZpvM7Atmdp2Z+cutchHwvpktAX4HXOJcPxuUMWg0XHwvZA4GwMy4+tgxrNhWxbvrdreWS8+GIRPUkiIiIhInlKgTO+cu7eL4LcAtifr8VHX+zBHc/MwK7nlzHUeNHdx6YNgMWP9m8iomIiKSYpI9u2fAyUgL8tkjR/Hs+9vYVlHfemDodKjcBDX9q8dLRETkQCmkJMHlR48m5hx/j5+O3DJ4dpu6fEREREAhJSlKCjI55dAi/v7OBhqa/enIw6Z7W41LERERARRSkuaqY8ewo7qRJ5f4a6NkDPLWVVFIERERARRSkuaECUM4bGgOf3zlY2Ixf1LTsBmahiwiIuJTSEkSM+NLJ45jZWk1L3+03ds5bAbs+hjqK5NbORERkRSgkJJE50wfzoj8DG6f/7G3Y9hMb7ttWdLqJCIikioUUpIoHAzwxRPG8u663Sxcv8ubhgwalyIiIoJCStJ99shRDMoM84d5ayCnGLKHwjaNSxEREVFISbLMtBBXHjOGF5eXsqq0yh88q5YUERERhZQUcNWxY4iEA9w+f423XkrZR9BUl+xqiYiIJJVCSgoYnJXGJUeW8NjizezKnQQuCqUfJrtaIiIiSaWQkiK+eMJYHPDX9fnejq2Lk1gbERGR5FNISREjB2Vy3ozh3L6kkVgkX+NSRERkwFNISSFfOnEctY0xNkcmKqSIiMiAp5CSQg4bmsvJhxbyz4phuO0fQrQp2VUSERFJGoWUFHPdieNZ2DAKizZC2YpkV0dERCRpFFJSzFFjBxP1V551T3wDXvghLHsQti+HaHNyKyciItKLQsmugOzNzDjvlBO4674zubBqDflv3goxv9snmA5Fh0HxVJjzZRg6LbmVFRERSSCFlBT0icnDOK/4eu6sauSlbx1DVtVa2PY+lC6D0g/g/Yehdhd87r5kV1VERCRh1N2TggIB40fnTWVbZT23vLIBiqfAjM/C6f8FVzwCh18Oa+dDU/3+nbhmJ+xen5hKi4iI9DCFlBR1xOhBXDhrJH96dQ1ryqr3Pjjxk9BUC+tf27+TPvYV+OuFPVdJERGRBFJISWHfPvNQIqEgP3riQ5xzrQfGHA+hDFj5fPdPVlcOq1+CnaugvrLH6yoiItLTFFJSWFFOhK+fNoH5K8t4cfn21gPhDBg7F1Y9B/HhpTOrnm8dgLtd9wUSEZHUp5CS4q46dgwTirL58ZMfUN8UbT0w8XTYvQ52ru7eiZY/Dmk53vPS93u8niIiIj1NISXFhYMBfnTeFDbuquOP89e0Hphwurdd+VzXJ2mshVUveoNvI/neTCEREZEUp5DSBxx7yBDOnj6M2+atZuOuWm9nfgkUTvK6fLqy+kVoroNJ53lrrJR+kNgKi4iI9ACFlD7i+2dNImDGT55a3rpz4umw/s2uB8IufwIyBsPo42CoH1JiscRWWERE5CAppPQRw/Mz+Ooph/DsB9t4ZWWZt3PCJ73BsGvmdfzG5kZY+SwcdhYEQ96aK001UL6uN6otIiJywBRS+pAvnjCWMQWZ3PTEBzQ2x2DUUZCe13mXz9r50FDpdfWA190DGpciIiIpTyGlD0kPBbnx3MmsKavhzlfXQDAMh5wCq17ouPumZVbP2BO910WTwAIalyIiIilPIaWPOeWwYs6eNoxfv7CShet3eV0+1aWwbem+hWNRWPGUN3YlHPH2hTOg4BBNQxYRkZSnkNIH3XzhNEbkZ/DVv79H+fC5gHmLtbW14U2o3dna1dOieIpCioiIpDyFlD4oNxLm1s/NYmd1I//61Gbc8Fntr5fy4eMQisAhp+29v3iqtxCclscXEZEUppDSR00bmcd/nDOJlz8qY0HakbB5IdTsaC0Qi3lTj8efCunZe7+5ZfDs9uWIiIikKoWUPuyKOaM5e9ow/mvVKMB5i7a12PIeVG2Byeft+8ahfkgpXdYr9RQRETkQCil9mJlx84XTqMibxA7yaVj+TOvB5Y9DIAQTP7nvG3NHQCRPM3xERCSlKaT0cbmRMLdcNpt5sZk0f/QiseYm787Iyx/37pScMWjfN5lB8TStlSIiIilNIaUfmDoij8JZ55LlqnnsyUdg+4ewaw1MOrfjNxVP8cppeXwREUlRCin9xNwzPkOUIKULn2Dj6/cDBoed0/EbiqdAY7WWx+8JsZjXeiUiIj1KIaWfsEgeruQYTg8voXrJI2zKnUljZEjHb9gzeFbjUg5KQxX88hBY+kCyayIi0u8opPQjocPOYFxsPZNsA3fvnMo5v3+V9zbsbr9wob88vsalHJx1r3sL5n38UrJrIiLS7yik9CcTWmfynHrBF6iqb+aCP7zBj5/4kNrG5r3LpmXC4PFaefZgrX3F225emNx6iIj0Qwop/cmQCTBoLAyfxXFHHM7z/zqXy48ezd2vr+X037zCq6vK9i6v5fEP3tr53nbnaqgrT2pVRET6m4SFFDO728y2m1m7vwXN8zszW21mS81sVqLqMmCYwaX3wUV3AZATCfOfn5rKA186hrRggCvueodv3r+Y0sp6r/xQf3n8hqrk1bkvq9nhhbwxJ3ivty5OanVERPqbRLak/AU4o5PjZwIT/Me1wB8SWJeBo+gwGDxur11HjR3M018/getPHs+TS7dy8i/n8buXVtFQMNkrUPphEiraD7R09Rz3dW+7eVHy6iIi0g8lLKQ4514BdnVS5HzgXud5C8g3s2GJqs9AFwkHueGTh/HCN+cyd0Ihv35hJZc85rWgOHX5HJi18yE9F8ad7HWzaVyKiEiPSuaYlBHAxrjXm/x9+zCza81sgZktKCsra6+IdNPogixuv+II7rt2Do1Zw6lwmTz70oss6mgWkHRs7Ssw+jgIhmDEEd79kkREpMckM6RYO/vaXRHLOXeHc262c252YWFhgqs1MMwZV8DjXzuBhoLJDG/4mAtue4Nv3Pceu2oak121vqF8o7eq79i53usRs6ByM1RtS269RET6kWSGlE3AqLjXI4EtSarLgBQMGEWHzGJ6eBPXnzSWp5Zt5fTfvMKLH5Ymu2qpr2U8yrgTve1wf9y3xqWIiPSYZIaUx4Er/Vk+c4AK59zWJNZnYCqeijXWcMNRGTx2/fEMyU7ji/cu4Fv/t4TK+qZk1y51rZ0PmUOgyB98PGw6WBC2KKSIiPSURE5B/gfwJnComW0ysy+Y2XVmdp1f5GlgDbAauBP4SqLqIp0oblke/30mD8/l8a8ez1dPPoSHF23ijN+8wuurdyS3fqnIOa8lZexcb9o3QFoWFE1SS4qISA8KJerEzrlLuzjugOsT9fnSTUWTAPPu4TPpXNJCAb71yUM5dVIR//Z/S7jsT29z5TGj+c6Zh5GZlrAfl75lxyqo2tra1dNi+OGw4kkvxFh7Q65ERGR/aMXZgS4tEwrGw7Zle+0+vGQQT//LCXzh+LH871vr+eRvX+FPr65htwbWtq4y2zJotsWIWVC3G3av7f06iYj0Qwop4nX5tHM35Eg4yA/Omcw/rpnDkOx0/uup5Rz905f42j/e442Pd+A1hg1Aa+dDXom3Nkq8EUd4W3X5iIj0CLXfixdSPnzUWx4/PWefw3PGFfDIV45jxbZK7ntnIw8v2sQTS7YwpiCTzx5ZwkVHjKQwJ733650MsSisfRUOO2ffLp2iyRCKeOulTLsoOfUTEelH1JIi3j18ALYv77TYYUNzuem8Kbzz/dP4zWdnUJQT4b+fXcGxP3uJGx97n+1V9b1Q2STbtgzqy/cdjwIQDMPQaWpJERHpIQop4t0NGfYZl9KRSDjIpw8fyQPXHcOL3zyRz8wexd/e3sCJP5/HL5/7qH9PXe5oPEqLEUd4NxqMNvdalURE+iuFFIG8UZCe1+64lK4cUpTNTz89jRe/eSKnTS7mlpdXM/fnL3PHKx9T3xRNQGWTbO0rMORQyBna/vHhs6CpFnZ81Lv1EhHphzQmRbyxFcVTYOsS2L0e6nZB7S5vpkrtLu91U623eFl2MeQUe9vsYsgYBGaMHZLF7y89nC/NHccvnvuInz69grtfW8fXT5vAhbNGkhbqB3m4uRHWvwGHX95xmRFxK8+2tFCJiMgBUUgRz9Bp8M4f4X+mt388mAbRdqYfB8KQOxwmnw+zrmLqiEO45/8dxVtrdvLzZ1fw3YeX8ZsXVnL5nNF87ugShmT34QG2mxd4Ya2jrh6AweO9OyNvXgizrui9uomI9EMKKeI57l9g0GjvF2zmYMgY3LrNyIdAyJv9U10a99ju3VCvbAW8eSu88TsYcwLMuoo5k87loS8fy7yVZfz59XX8+oWV3PLP1Zw7YzifP24MU0fk9b1Fz9a+AhaAMcd3XCYQ8BZ10/L4IiIHTSFFPHkj4ZguFgCO5HqPIRP2PVa1DRb/DRbdCw9/ETIGYTMu5eSZn+PkszLZOrmOJUvfY9cHK9m5bBtb03ZQ5MpwJ/w7oZP/PTHfqaetmQ/DZnhdXJ0ZMQve+D001UM40jt1ExHphxRSpGfkDIUT/g2O+1dvBsyie+CdO+Gt2wAY5j9iGfnsDA9jae1YNjTncsS8m/npqmGMnjGXkw4tYkR+RlK/Rocaa2DTu3BMN24xNXwWxJqh9H0YOTvxdRMR6acUUqRnBQIw/mTvUbMDPnoa0rJh0BgYPJZAxiAKgZNijtc/WEP142dw+dafcvqaLL5POhOLsznp0CJOmljIrNGDiISDPVOvWBTefxhKl8EpN0JwP3/0N7wJsSYY2876KG3tWXl2oUKKiMhBUEiRxMkaArOubPdQMGDMnTYesv5E/r3n8daRr/J/hV9j3srt/Pn1tdzxyhrMYHheBuOLshk3JIvxRdmM97dFOelYd8azxGKw/HGYd7M3dga80HTifnYxrZnvDRIumdN12dzh3swnLeomInJQFFIkucadCEdfR/7bt3PNledzzdyTqGlo5s2Pd/Lh1ko+LqtmTVkND6zbRW1j67orw/MinDtzOOfPGMGkYTn7Bhbn4KNn4OWfeq0nQw6Fi/4MK56C+f8NEz/pjS/prrWvwKijIC2r67JmXpePBs+KiBwUhRRJvlN/CKtfgkevh6+8QVYkj9MmF3Pa5OI9RZxzbKusZ01ZDau3VzN/ZRl3vbqWP85fw8TibM6fOYLzZw5nZH6Gd66Xf+KFhMHj4NN3ePfSCQRh3Emw7jV45Dq4dh6EujEluqrUW0PmpO90/zuNmAUrn4X6Cojk7fclERERsL52J9vZs2e7BQsWJLsa0tM2LYS7PgHTPwuf/kO33rKzuoGnl21l/sL3ydzyBscGPuDktOUUx0qpigzng0OuY+uY84mkpxMJB0kPB8jPSGNi5RuE7vssHPcN+MSPOv+QunK49zzYvgK+NB+KJnXv+6x+Ef56IVz5ePv3+dkfznlTvnevh93rvEfWEDjyCwd3XhGRFGBmC51z7Q7gU0uKpIaRR3izg175ORx2Nkw6p+Oy9ZWw9hUK1r7CFWvnc8WOFZAG9aEcFjCFXzacz6P1x9O0IAQL9l3qPz0U4PfZZ3Da67/jtcCRlMw4mdEFmft2GTVUw98+A6UfwiV/735AAa+7B7zWnO6GlFgMdq/17qK8dTGUrfQCSfkGaK7bt/zUC701bERE+imFFEkdc2/wukie+DqMOhqyC1uPNTfC6hdg6QPeWJNoA4QzoeQYmHEpjDuRyNDpHB8IMrspyn80xahvjlLXGG3dNsUoq25g2aZy/rr+WibXLWTU/G9y5gs3k5aRw5ThuRRkp5OXEaIgLcrFK/+NYeWLWDLnN9QHj2DYjhqG5UdID3VjxlHmYG9GU2eDZ6u2eV1PW97zupO2LoGGSu9YMM0bRzNkAkz4hHeuQWMgfzTsWAn3X+ZNce5sYTkRkT5OIUVSRygNLrgD/ngiPPkNuPh/YeNbXjD54BGoL/fuH3TE1d4y/COP9N7TRiQcJBIOkke43Y85b8ZwYDLNa/5M8N5zeezQ5/lz3vUs31rFlk3l1NbW8vPozxlmS/hm05d5dF4hzHsL8MbEFuWkM3JQJiPyMxg5KIMRgzIYNSiTksGZDM/PaL1P0YgjYMPb+1Zg58fw+m9h8T+8ac3BdO8+P9MugmEzYfhMKJzU7ncDWltPti5VSBGRfk0hRVJL0SQ45T/ghR/Arw6Fmu1ei8lh58D0i72Br8H2w8f+Co07AeZ8hYlv3crNV1wCF5wM0Wb4v6tgxWLqz/wNNxx6KdfWNlFe28jm8jo2l9exaXcdm3fX8d7G3Ty9bCvNsdZxXQGDYXkZjBqcwWWxoZxbuYl7X3iH3TaI7MqPOGrjX5iy+yWiFuL1nLNYVHAO4WHTGDEkh5LBmYwanElhdjqBQCfTq7OLvCnO25b1yHUQEUlVCimSeo653usCaajygsmhZ0F6dmI+69QfeN1Ij30VrnsVnvl3WPEknPEzIkf/P0ZAp6vgRmOO0sp6Nu6qZcOuWjbuqmXj7jo27Krl8R1DORfYPu8OZgTW8IngQmqI8NfAuTyc/ilqrYCqLc1sW7GG+PHr6aGA30KTydDcdIpzIxTlRijO8Z4X50YoGjqNwLalibkmIiIpQrN7RFpmFmUXQdVWOPVGbxDvwWqswd08EnMxXCQfm/NlOOpab7xKnIbmKJv9YLNxd50XeHbWsqWijtLKesqqGoi1+c/0x9kPcUXsMex7W7o3jVpEJEVpdo9IZ0YeASd8E175BZzwrZ4JKABpWdhpPwIz7IirIT2n3WLpoSDjCrMZV9h+a1E05thZ3UBpZQOllfUs2VTOW/NGcGVaM2xf7o1hERHphxRSRABO+h5M/pQ3gLUnHfcvB32KYMAo8rt8ppHHKYcVccmCw6AR2LZUIUVE+q1AsisgkhICARg61Zu+k+ICAePYI4+gymVQte69ZFdHRCRhFFJE+qDPHDmaFa6EyrULk10VEZGEUUgR6YNG5GewO3cS+VUfEY1Gu36DiEgfpJAi0kcNPfRIsqhnwXtqTRGR/kkhRaSPmnS4t9rs0ndfTXJNREQSQyFFpI8KD51M1EJEtyxmR3VDsqsjItLjFFJE+qpQGs2DJ3IY63lk0eZk10ZEpMcppIj0YemjDmdGeAP3vbuBvrZ6tIhIVxRSRPqyodMYFNtNZdlmFm3YnezaiIj0KIUUkb5s6HQAZqVt4L53Nia5MiIiPUshRaQvGzoVgAuG7+TJpVupqm9KcoVERHqOQopIXxbJg0FjOCqyhbqmKE8s2ZrsGomI9BiFFJG+buh08iuXc2hxDvcvUJePiPQfCikifd3Q6diuNVx++CCWbCxn+dbKZNdIRKRHKKSI9HXDvMGz5w/bTVowwP3vqjVFRPoHhRSRvs6f4ZNbvpzTpxTz6OLNlFbWJ7lSIiIHTyFFpK/LGQqZQ2DbUq6dO47G5hjn/v413tO6KSLSxymkiPR1Zl6Xz9alTB+Zz8NfOZZIOMhn//gWD2ggrYj0YQopIv3B0OmwfTk0N3LY0Fwe/+pxHDV2MP/+4FJuevwDmqKxZNdQRGS/KaSI9AdDp0GsCXZ8BEB+Zhp/+fyRfOH4sfzljXVcedc77KppTHIlRUT2T0JDipmdYWYfmdlqM/tOO8dPMrMKM1vsP25MZH1E+q1hM7zt1qV7doWCAX5wzmR+9ZkZLNywm/NueU3Tk0WkTwkl6sRmFgRuBT4BbALeNbPHnXMftin6qnPunETVQ2RAGDwOwpmwbSlw2V6HLjxiJIcUZfOl/13Ip259nbkTCzl2fAHHjh/CxOJszCw5dRYR6ULCQgpwFLDaObcGwMzuA84H2oYUETlYgSAUT4Vty9o9PGNUPo9/7Th+++IqXl+9gxc+LAVgSHYax4wfwrHjCzhmXAGjCzIVWkQkZSQypIwA4qcWbAKObqfcMWa2BNgCfMs590HbAmZ2LXAtQElJSQKqKtIPDJsOSx+AWAwC+/bkFuVE+OmnpwGwaXctb3y8kzc/3skbH+/giSVbAMhODzG+KJtDCrOZUNy6HTkok2BA4UVEelciQ0p7/0dzbV4vAkY756rN7CzgUWDCPm9y7g7gDoDZs2e3PYeIgDd49t0/Qfk6r/unEyMHZXLx7Ewunj0K5xxrdtTw9ppdrCytYvX2al5bXcZDizbtKZ8eCnB4ST4nHVrESYcWcmhxjlpcRCThEhlSNgGj4l6PxGst2cM5Vxn3/Gkzu83MhjjndiSwXiL9k7/yLNuWdRlS4pkZ4wuzGV+Yvdf+iromPi6rZnVpNR+VVvH66h387JkV/OyZFQzLi3DixEJOOrSQ4w4ZQk4k3JPfREQESGxIeReYYGZjgc3AJcDn4guY2VCg1DnnzOwovNlGOxNYJ5H+q2gyWNCb4TP5/IM+XV5GmFklg5hVMmjPvm0V9cxfuZ15H5Xx1NKt3PfuRkIBY+yQLIbmRRiaG/G2/vNi//XgzDQC6i4Skf2UsJDinGs2s68CzwFB4G7n3Admdp1//HbgIuDLZtYM1AGXOOfUnSNyIMIRKDy0w8GzPWFoXoTPHlnCZ48soSkaY9H63cxfWcaashq2VtazqnQH26vqibX5rzgUMIZkp1OUm05RTjqFORGKctIpzo0wLC7U5GeG1Y0kIntYX8sEs2fPdgsWLEh2NURS08NfgrXz4WsLIRaFWLO3df7zQMi7108CNUdj7KhuZGtFHdsq6imtrGd7VUPro7KesqoGdrazuFx6KLB3i0xuhKLcCMW5XqAZmhuhMCedSDiY0O8gIr3HzBY652a3dyyR3T0i0tuGTYel98FPh3dSZgYcfgVMuwgyBnVc7gCFgoE9XT6daYrG2F7VsCfIbI3bbquoY9GG3ZRWNtDYvO+S/vmZYYbmRhien8HQvAjDciMMy8/Y0yozKDONnEiIcFCLaov0ZWpJEelP6nbDe38FF/PGpwRC3hoqAf95Xbk3Tbl0GYQiMOlcOPxyGDO33WnLyeaco6KuiW2V9ZRWNnitMnGBZkt5Pdsq6ztc8j8rLUhuRpjcSJi8jDC5GSEy0kKkhwKkhwJEwkH/eZD0cIDMtCAZ4SBZ6SEy04JkpnnbrPQQQ7LTNEBYJAE6a0lRSBEZaJyDrUvgvf+Fpf8HDRWQXwIzPgf5o+LCTcB/7r+O5EN2EWQXQ3p2lx/Tm+qbomyr8FthKuuoqG2ioq6ZyvomKuqaqKzzt/XNNDRFaWiOUe9vG5qjNEW79//Bgqw0xgzJYnRBJmMLshg9JIuxBVmUDM4kNyOk8TQiB0AhRUTa11QHy5/0Asva+d1/X1p2a2DJLoL0HK9lJpgOobhHMB0y8r0QlDcKckdAMPV6maPRKI1bP6AuYzg1lkltY5SaxmZqG6LUNjZT09hMaWUD63fWsHZHDet21LKtsn6vc0TCgb3G0hT73VATinM4dnyBAoxIBzQmRUTaF86A6Z/xHjU7obHKH2gbixtw6w+6rdsN1duhepu/LfW2pR9CYzU0N0C0EZrrvfLtsSDkDm8NLYPGwJAJMGQiFBwCaZm9991rd8HH/4RVLxBc/SIZtTvIyBnO4AvvhDHHd/n2usYo63d5gWXT7lq2VdT73VL1LFi/m+2VDTRGvfE0hxbn8OWTxnPO9GGENE5GpNvUkiIiPS8W9UJLc70XbsrXQ/lGqNgI5Rtan1dsonUhavO6m4ZM9B75JRBM87ueQnHja/znoYjXWhPO8FtuIq2tNy4K0SYvLEWbINbkbZvqYP0bsOp52LzAC2MZg+GQ06BkDrx5K+xaA3NvgBO/fVCtPrGYY3dtI/NXlnH7/I9ZWVrNyEEZfGnuOD4ze5RmKIn41N0jIqmpqd4LBTs+gh2rYMdK/7EKmmoT97nDZ8GET8CE02H44V74AWiohqdvgCV/h1Fz4MI7vbB0kGIxx0srtnPbvNW8t6GcIdlpfP64sVxxzGhyNRhXBjiFFBHpW2IxrwUm1tzm0bL2S1NrS03Ltqne20YbvG6lYLi11SUYhkDYa5kZNt0bR9OZpQ/Ak9/0Bg+f9/v2V/CtK4ct78HmhbB7nReqGmuhqcbf1kJjjTfN+4RvwqTzcMDba3dx27yPeWVlGWnBAMPzI4wYlMHwvAxvm5/BSH9qdXYkRGZaiIxwUDd4lH5LIUVEZH/tWgMPfgG2LIIjPu9N1W4JJZsXei0+LbKLIS3Le4SzvLE14Uzv9Zb3vLLDZ8FpN8G4EwF4f3MFTyzdwubddWwur2NLeR3bqxro6H/J6aHWKdKZ6SHyM8IMykqjICutdZuZxuCsNIIBIxpzNMccUf/RHIsRc46McJCC7HSGZKdTkJ1GTnrns5KaojFqGpoxTDOYJCEUUkREDkRzI/zzP+GN37XuyyqCkbNhxCwYcYQXPjLyOz5HtNlbYO/lm6FyE4w/BU79IQyfuU/RhuYopRUNbCr3BuLWNEapa2ymtjFKXWOUuqYotY3ejKPy2iZ21TTueTS3vRdBN6UFAxRkp1GQnUZaMEBNQ5TqhmZvVlNDdM/gX4DMtCDD8rxF9Fq2w/MyKMxNJzMcJOI/MsJBIuEA6f46NNGYoykaoynqhaWmZkdTLEY05ggGjLRggLRQgLRggHAoQDjo7VMgGhgUUkREDsamBd4g3xFHQN5IOJBfnk318O6f4NVfQd0umHIBzP0W5AzzB/z6g4QP4NzOOaoamtlV3ciu2kaccwQDAYJmBANGKGgE/Oe1jc3sqG5kZ3UDO6sb2VHjb6sbaI46stK9xeuy0kJkpYfITvcWtYs5x5byerZW1LGlop6t5XWUVXfc8tMTciMhCrLTGZQZZnBWOgVZaQzO9lqNWlqLmqKO5miMZr+1qDnqcMCeq2hgGGbevvRQkNyM0J4F/vIyWxf7y0gLdnr5W65nMGCEArbfIco5R2M0Rk1DlJqGZqobmuPW64lbu8ffhgJGdqTl32HvR1qodZZY23+C1lDoBcJG/3ljc4zmWGzPv5mD1ufOu27NUS9ANvvXtSnmX9+o45jxBYwa3PMz8BRSRERSRX0FvHGLN5OoqWbf48G01vVmsobErUdT3Po8a4gXaJwDXNwWbxsI+ufxg0/L82DYGydTXQo1Za1TyVueN1R6s6D2zIhq9FqCoo3e7KmCcVAwwZs2XjCBxvzxlNoQttd4v2y9R4y6Pc+9lphQwAgFvBaScDBAKOg9bwkajc1eK0ujv7BeY9T7pV1Z18TOmkZ2+UFqV00ju2sbO1x8rzU8eK9d3CVxOJzjgFuc2mPm3TwzYN73CgaMcND7ri3PgwGjvilGdUMzNQ3NPfr5ve0Pl83izGnDevy8WidFRCRVRPLglO/DUdfAiqf8wb6N/sMPBs2N0FzXGh42vQtVpd6+nhaKeF1Y2UVe3VrCTDDNH2zsP2+sgZ2rYNmD3irFQBowKpjOqLwR3mDldvkhysW8R/xr8KaAZxf6dSj0QlhekRfEcP4g5DpvIHJTHa6plsb6GmLRZgKBAAELEPCDglnASw57Qlss7rO8bcxBgwvSEA1Q54LURQPURQPUNhsNUTAXI0AUczHvQQxzUcxFCTbXY7FGgs31BGINBKMNBGMNWKyJZsI0WZhGS6fRwjSQRiNpNJBGICNEOBQmFAoRDocJh8KEwyHSw2HCISNsMcLECAccIYsRIkrIHK6xlmh9JdG6KlxDFTRUE2isItBcA7Eo0WA6zYF0ooEIzcF0ooF0mgMRosF0XDiLWCgDF87CpWXuGStl4QywgPfAwLxuNWcBDEc41kA4Vkc4Wk8oVk84WkfQf4QHlQA9H1I6o5AiIpIM2UUw+/PdL++ct2he9XYvvMSifteQeduWXzrgrxPTJvhE/RlRaVneZ7cEk/Sc/eticg5qdniBZccqb1u5hU77fVp+KbaEiPgwUbsLarbDjtVeq060odOPNyDd/Fs27NWK5G/jPxPb+zMxAjgyok1kuCj53f/Wnj3r8/iPcATSMrwgF632QmRzgxeqmus7X9iwu5+XngNpOd6tKNKzIde/LYUF/VltLZ9VC027oLHO29cy08zte4PO/Wfez82hJwHTeuB83aeQIiLSF5h5v7DSc6BgfHLrkV3oPUYf27Pnds7rcqou84JYIOgt1hf2Z0u1PA+GD2xcULxYrHWRv1iT163loq33q7JA67blflYHsrhf1J8+37J6855VnP3nFvDHIgX2XrBwTz0O4ns65wWY+KnxzXV+CxN7tTDtCXnhjL1nqIUzva7HJA1iVkgREZHUYOZ1OUXyYMghif2sQAAC/tifRAoeYLjpCWZ+6MgACpJTh4Okm0iIiIhISlJIERERkZSkkCIiIiIpSSFFREREUpJCioiIiKQkhRQRERFJSQopIiIikpIUUkRERCQlKaSIiIhISlJIERERkZSkkCIiIiIpSSFFREREUpJCioiIiKQkhRQRERFJSQopIiIikpLMOZfsOuwXMysD1h/EKYYAO3qoOv2Nrk3ndH06pmvTMV2bzun6dGygXJvRzrnC9g70uZBysMxsgXNudrLrkYp0bTqn69MxXZuO6dp0TtenY7o26u4RERGRFKWQIiIiIilpIIaUO5JdgRSma9M5XZ+O6dp0TNemc7o+HRvw12bAjUkRERGRvmEgtqSIiIhIH6CQIiIiIilpwIQUMzvDzD4ys9Vm9p1k1yfZzOxuM9tuZu/H7RtsZi+Y2Sp/OyiZdUwWMxtlZi+b2XIz+8DMvu7vH/DXx8wiZvaOmS3xr82P/P0D/tq0MLOgmb1nZk/6r3VtfGa2zsyWmdliM1vg79P1Acws38weNLMV/v97jtG1GSAhxcyCwK3AmcBk4FIzm5zcWiXdX4Az2uz7DvCSc24C8JL/eiBqBv7NOTcJmANc7/+86PpAA3CKc24GMBM4w8zmoGsT7+vA8rjXujZ7O9k5NzNu/Q9dH8//AM865w4DZuD9DA34azMgQgpwFLDaObfGOdcI3Aecn+Q6JZVz7hVgV5vd5wP3+M/vAT7Vm3VKFc65rc65Rf7zKrz/WYxA1wfnqfZfhv2HQ9cGADMbCZwN/Clut65N5wb89TGzXGAucBeAc67ROVeOrs2ACSkjgI1xrzf5+2Rvxc65reD9ogaKklyfpDOzMcDhwNvo+gB7ujMWA9uBF5xzujatfgv8OxCL26dr08oBz5vZQjO71t+n6wPjgDLgz35X4Z/MLAtdmwETUqydfZp7LZ0ys2zgIeAbzrnKZNcnVTjnos65mcBI4Cgzm5rkKqUEMzsH2O6cW5jsuqSw45xzs/C63q83s7nJrlCKCAGzgD845w4HahiAXTvtGSghZRMwKu71SGBLkuqSykrNbBiAv92e5PokjZmF8QLK35xzD/u7dX3i+M3R8/DGNunawHHAeWa2Dq9L+RQz+yu6Nns457b42+3AI3hd8bo+3u+oTX6rJMCDeKFlwF+bgRJS3gUmmNlYM0sDLgEeT3KdUtHjwFX+86uAx5JYl6QxM8PrG17unPt13KEBf33MrNDM8v3nGcBpwAp0bXDOfdc5N9I5Nwbv/zH/dM5djq4NAGaWZWY5Lc+B04H30fXBObcN2Ghmh/q7TgU+RNdm4Kw4a2Zn4fUXB4G7nXM/SW6NksvM/gGchHcr8FLgh8CjwANACbAB+Ixzru3g2n7PzI4HXgWW0Tq24Ht441IG9PUxs+l4A/iCeH/kPOCc+7GZFTDAr008MzsJ+JZz7hxdG4+ZjcNrPQGve+Pvzrmf6Pp4zGwm3oDrNGAN8Hn8/8YYwNdmwIQUERER6VsGSnePiIiI9DEKKSIiIpKSFFJEREQkJSmkiIiISEpSSBEREZGUpJAiIn2KmZ3UcodhEenfFFJEREQkJSmkiEhCmNnlZvaOmS02sz/6NyasNrNfmdkiM3vJzAr9sjPN7C0zW2pmj5jZIH//IWb2opkt8d8z3j99tpk9aGYrzOxv/irBmNnPzOxD/zy/TNJXF5EeopAiIj3OzCYBn8W7odxMIApcBmQBi/ybzM3HW+kY4F7g28656Xgr/bbs/xtwq3NuBnAssNXffzjwDWAy3h1kjzOzwcCngSn+ef4rkd9RRBJPIUVEEuFU4AjgXTNb7L8eh3ebgfv9Mn8FjjezPCDfOTff338PMNe/z8sI59wjAM65eudcrV/mHefcJudcDFgMjAEqgXrgT2Z2AdBSVkT6KIUUEUkEA+5xzs30H4c6525qp1xn9+WwTo41xD2PAiHnXDPeXXUfAj4FPLt/VRaRVKOQIiKJ8BJwkZkVAZjZYDMbjff/nIv8Mp8DXnPOVQC7zewEf/8VwHznXCWwycw+5Z8j3cwyO/pAM8sG8pxzT+N1Bc3s8W8lIr0qlOwKiEj/45z70Mz+A3jezAJAE3A9UANMMbOFQAXeuBXwbkN/ux9CWu4AC15g+aOZ/dg/x2c6+dgc4DEzi+C1wvxrD38tEelluguyiPQaM6t2zmUnux4i0jeou0dERERSklpSREREJCWpJUVERERSkkKKiIiIpCSFFBEREUlJCikiIiKSkhRSREREJCX9f2fEucAkjc4VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['loss'] for k in training_history_lr_scheduler.keys()], label = 'training loss')\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['val_loss'] for k in training_history_lr_scheduler.keys()], label = 'val loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.title(\"ResNet-18: (Dropout) Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(list(training_history_lr_scheduler.keys()), [training_history_lr_scheduler[k]['lr'] for k in training_history_lr_scheduler.keys()])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"lr\")\n",
    "plt.title(\"ResNet-18: (Dropout) Learning-Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG18_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
